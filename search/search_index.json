{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Narwhals","text":"<p>-</p> <p> </p> <p>Extremely lightweight and extensible compatibility layer between dataframe libraries!</p> <ul> <li>Full API support: cuDF, Modin, pandas, Polars, PyArrow</li> <li>Lazy-only support: Dask</li> <li>Interchange-level support: DuckDB, Ibis, Vaex, anything which implements the DataFrame Interchange Protocol</li> </ul> <p>Seamlessly support all, without depending on any!</p> <ul> <li>\u2705 Just use a subset of the Polars API, no need to learn anything new</li> <li>\u2705 Zero dependencies, Narwhals only uses what   the user passes in so your library can stay lightweight</li> <li>\u2705 Separate lazy and eager APIs, use expressions</li> <li>\u2705 Support pandas' complicated type system and index, without   either getting in the way</li> <li>\u2705 100% branch coverage, tested against pandas and Polars nightly builds</li> <li>\u2705 Negligible overhead, see overhead</li> <li>\u2705 Let your IDE help you thanks to full static typing, see <code>narwhals.typing</code></li> <li>\u2705 Perfect backwards compatibility policy,   see stable api for how to opt-in</li> </ul>"},{"location":"#whos-this-for","title":"Who's this for?","text":"<p>Anyone wishing to write a library/application/service which consumes dataframes, and wishing to make it completely dataframe-agnostic.</p> <p>Let's get started!</p>"},{"location":"#roadmap","title":"Roadmap","text":"<p>See roadmap discussion on GitHub for an up-to-date plan of future work.</p>"},{"location":"backcompat/","title":"Perfect backwards compatibility policy","text":"<p>Narwhals is primarily aimed at library maintainers rather than end users. As such, we need to take stability and backwards compatibility extra-seriously. Our policy is:</p> <ul> <li>If you write code using <code>import narwhals.stable.v1 as nw</code>, then we promise to   never change or remove any public function you're using.</li> <li>If we need to make a backwards-incompatible change, it will be pushed into   <code>narwhals.stable.v2</code>, leaving <code>narwhals.stable.v1</code> unaffected.</li> <li>We will maintain <code>narwhals.stable.v1</code> indefinitely, even as <code>narwhals.stable.v2</code> and other   stable APIs come out. For example, Narwhals version 1.0.0 will offer   <code>narwhals.stable.v1</code>, whereas Narwhals 2.0.0 will offer both <code>narwhals.stable.v1</code> and   <code>narwhals.stable.v2</code>.</li> </ul> <p>Like this, we enable different packages to be on different Narwhals stable APIs, and for end-users to use all of them in the same project without conflicts nor incompatibilities.</p>"},{"location":"backcompat/#background","title":"Background","text":"<p>Ever upgraded a package, only to find that it breaks all your tests because of an intentional API change? Did you end up having to litter your code with statements such as the following?</p> <pre><code>if parse_version(pdx.__version__) &lt; parse_version(\"1.3.0\"):\n    df = df.brewbeer()\nelif parse_version(\"1.3.0\") &lt;= parse_version(pdx.__version__) &lt; parse_version(\"1.5.0\"):\n    df = df.brew_beer()\nelse:\n    df = df.brew_drink(\"beer\")\n</code></pre> <p>Now imagine multiplying that complexity over all the dataframe libraries you want to support...</p> <p>Narwhals offers a simple solution, inspired by Rust editions.</p>"},{"location":"backcompat/#narwhals-stable-api","title":"Narwhals' Stable API","text":"<p>Narwhals implements a subset of the Polars API. What will Narwhals do if/when Polars makes a backwards-incompatible change? Would you need to update your Narwhals code?</p> <p>To understand the solution, let's go through an example. Suppose that, hypothetically, in Polars 2.0, <code>polars.Expr.cum_sum</code> was renamed to <code>polars.Expr.cumulative_sum</code>. In Narwhals, we have <code>narwhals.Expr.cum_sum</code>. Does this mean that Narwhals will also rename its method, and deprecate the old one? The answer is...no!</p> <p>Narwhals offers a <code>stable</code> namespace, which allows you to write your code once and forget about it. That is to say, if you write your code like this:</p> from/to_native@narwhalify <pre><code>import narwhals.stable.v1 as nw\nfrom narwhals.typing import IntoFrameT\n\n\ndef func(df: IntoFrameT) -&gt; IntoFrameT:\n    return nw.from_native(df).with_columns(nw.col(\"a\").cum_sum()).to_native()\n</code></pre> <pre><code>import narwhals.stable.v1 as nw\nfrom narwhals.typing import FrameT\n\n\n@nw.narwhalify\ndef func(df: FrameT) -&gt; FrameT:\n    return df.with_columns(nw.col(\"a\").cum_sum())\n</code></pre> <p>then we, in Narwhals, promise that your code will keep working, even in newer versions of Polars after they have renamed their method.</p> <p>Concretely, we would do the following:</p> <ul> <li><code>narwhals.stable.v1</code>: you can keep using <code>Expr.cum_sum</code></li> <li><code>narwhals.stable.v2</code>: you can only use <code>Expr.cumulative_sum</code>, <code>Expr.cum_sum</code> will have been removed</li> <li><code>narwhals</code>:  you can only use <code>Expr.cumulative_sum</code>, <code>Expr.cum_sum</code> will have been removed</li> </ul> <p>So, although Narwhals' main API (and <code>narwhals.stable.v2</code>) will have introduced a breaking change, users of <code>narwhals.stable.v1</code> will have their code unaffected.</p>"},{"location":"backcompat/#import-narwhals-as-nw-or-import-narwhalsstablev1-as-nw","title":"<code>import narwhals as nw</code> or <code>import narwhals.stable.v1 as nw</code>?","text":"<p>Which should you use? In general we recommend:</p> <ul> <li>When prototyping, use <code>import narwhals as nw</code>, so you can iterate quickly.</li> <li>Once you're happy with what you've got and want to release something production-ready and stable,   then switch out your <code>import narwhals as nw</code> usage for <code>import narwhals.stable.v1 as nw</code>.</li> </ul>"},{"location":"backcompat/#exceptions","title":"Exceptions","text":"<p>Are we really promising perfect backwards compatibility in all cases, without exceptions? Not quite. There are some exceptions, which we'll now list. But we'll never intentionally break your code. Anything currently in <code>narwhals.stable.v1</code> will not be changed or removed in future Narwhals versions.</p> <p>Here are exceptions to our backwards compatibility policy:</p> <ul> <li>Unambiguous bugs. If a function contains what is unambiguously a bug, then we'll fix it, without   considering that to be a breaking change.</li> <li>Radical changes in backends. Suppose that Polars was to remove   expressions, or pandas were to remove support for categorical data. At that point, we might   need to rethink Narwhals. However, we expect such radical changes to be exceedingly unlikely.</li> <li>We may consider making some type hints more precise.</li> <li>Anything labelled \"unstable\".</li> </ul> <p>In general, decision are driven by use-cases, and we conduct a search of public GitHub repositories before making any change.</p>"},{"location":"backcompat/#breaking-changes-carried-out-so-far","title":"Breaking changes carried out so far","text":""},{"location":"backcompat/#after-stablev1","title":"After <code>stable.v1</code>","text":"<p>The following are differences between the main Narwhals namespace and <code>narwhals.stable.v1</code>:</p> <ul> <li> <p>Since Narwhals 1.23:</p> </li> <li> <p>Passing an <code>ibis.Table</code> to <code>from_native</code> returns a <code>LazyFrame</code>. In     <code>narwhals.stable.v1</code>, it returns a <code>DataFrame</code> with <code>level='interchange'</code>.</p> </li> <li><code>eager_or_interchange_only</code> has been removed from <code>from_native</code> and <code>narwhalify</code>.</li> <li>Order-dependent expressions can no longer be used with <code>narwhals.LazyFrame</code>.</li> <li> <p>The following expressions have been deprecated from the main namespace: <code>Expr.head</code>,     <code>Expr.tail</code>, <code>Expr.gather_every</code>, <code>Expr.sample</code>, <code>Expr.arg_true</code>, <code>Expr.sort</code>.</p> </li> <li> <p>Since Narwhals 1.21, passing a <code>DuckDBPyRelation</code> to <code>from_native</code> returns a <code>LazyFrame</code>. In   <code>narwhals.stable.v1</code>, it returns a <code>DataFrame</code> with <code>level='interchange'</code>.</p> </li> <li> <p>Since Narwhals 1.15, <code>Series</code> is generic in the native Series, meaning that you can   write:   <pre><code>import narwhals as nw\nimport polars as pl\n\ns_pl = pl.Series([1, 2, 3])\ns = nw.from_native(s, series_only=True)\n# mypy infers `s.to_native()` to be `polars.Series`\nreveal_type(s.to_native())\n</code></pre>   Previously, <code>Series</code> was not generic, so in the above example   <code>s.to_native()</code> would have been inferred as <code>Any</code>.</p> </li> <li> <p>Since Narwhals 1.13.0, the <code>strict</code> parameter in <code>from_native</code>, <code>to_native</code>, and <code>narwhalify</code>     has been deprecated in favour of <code>pass_through</code>. This is because several users expressed     confusion/surprise over what <code>strict=False</code> did.     <pre><code># v1 syntax:\nnw.from_native(df, strict=False)\n\n# main namespace (and, when we get there, v2) syntax:\nnw.from_native(df, pass_through=True)\n</code></pre>     If you are using Narwhals&gt;=1.13.0, then we recommend using <code>pass_through</code>, as that     works consistently across namespaces.</p> <p>In the future:</p> <ul> <li>in the main Narwhals namespace, <code>strict</code> will be removed in favour of <code>pass_through</code></li> <li>in <code>stable.v1</code>, we will keep both <code>strict</code> and <code>pass_through</code></li> </ul> </li> <li> <p>Since Narwhals 1.9.0, <code>Datetime</code> and <code>Duration</code> dtypes hash using both <code>time_unit</code> and     <code>time_zone</code>.     The effect of this can be seen when placing these dtypes in sets:</p> <pre><code>import narwhals.stable.v1 as nw_v1\nimport narwhals as nw\n\n# v1 behaviour:\nassert nw_v1.Datetime(\"us\") in {nw_v1.Datetime}\n\n# main namespace (and, when we get there, v2) behaviour:\nassert nw.Datetime(\"us\") not in {nw.Datetime}\nassert nw.Datetime(\"us\") in {nw.Datetime(\"us\")}\n</code></pre> <p>To check if a dtype is a datetime (regardless of <code>time_unit</code> or <code>time_zone</code>) we recommend using <code>==</code> instead, as that works consistently across namespaces:</p> <pre><code># Recommended\nassert nw.Datetime(\"us\") == nw.Datetime\nassert nw_v1.Datetime(\"us\") == nw_v1.Datetime\n</code></pre> </li> </ul>"},{"location":"ecosystem/","title":"Ecosystem","text":""},{"location":"ecosystem/#used-by","title":"Used by","text":"<p>The following is a non-exhaustive list of libraries and tools that choose to use Narwhals for their dataframe interoperability needs:</p> <ul> <li>altair</li> <li>hierarchicalforecast</li> <li>marimo</li> <li>panel-graphic-walker</li> <li>plotly</li> <li>pymarginaleffects</li> <li>py-shiny</li> <li>rio</li> <li>scikit-lego</li> <li>scikit-playtime</li> <li>tabmat</li> <li>tea-tasting</li> <li>timebasedcv</li> <li>tubular</li> <li>vegafusion</li> <li>wimsey</li> </ul> <p>If your project is missing from the list, feel free to open a PR to add it.</p> <p>If you would like to chat with us, or if you need any support, please join our Discord server.</p>"},{"location":"ecosystem/#related-projects","title":"Related projects","text":""},{"location":"ecosystem/#dataframe-interchange-protocol","title":"Dataframe Interchange Protocol","text":"<p>Standardised way of interchanging data between libraries, see here.</p> <p>Narwhals builds upon it by providing one level of support to libraries which implement it - this includes Ibis and Vaex. See extending for details.</p>"},{"location":"ecosystem/#array-api","title":"Array API","text":"<p>Array counterpart to the DataFrame API, see here.</p>"},{"location":"ecosystem/#pycapsule-interface","title":"PyCapsule Interface","text":"<p>Allows C extension modules to safely share pointers to C data structures with Python code and other C modules, encapsulating the pointer with a name and optional destructor to manage resources and ensure safe access, see here for details.</p> <p>Narwhals supports exporting a DataFrame via the Arrow PyCapsule Interface.</p>"},{"location":"ecosystem/#ibis","title":"Ibis","text":"<p>Pitched as \"The portable Dataframe library\", Ibis provides a Pythonic frontend to various SQL (as well as Polars LazyFrame) engines. Some differences with Narwhals are:</p> <ul> <li>Narwhals' main use case is for library maintainers wanting to support   different dataframe libraries without depending on any whilst keeping   things as lightweight as possible. Ibis is more targeted at end users   and aims to be thought of as a Dataframe library akin to   pandas / Polars / etc.</li> <li>Narwhals allows you to write a \"Dataframe X in, Dataframe X out\" function.   Ibis allows materialising to pandas, Polars (eager), and PyArrow, but has   no way to get back to the input type exactly (e.g. there's no way to   start with a Polars LazyFrame and get back a Polars LazyFrame)</li> <li>Narwhals respects input data types as much as possible, Ibis doesn't   support Categorical (nor does it distinguish between fixed-size-list and   list)</li> <li>Narwhals separates between lazy and eager APIs, with the eager API   provide very fine control over dataframe operations (slicing rows and   columns, iterating over rows, getting values out of the dataframe as   Python scalars). Ibis is more focused on lazy execution</li> <li>Ibis supports SQL engines (and can translate to SQL),   Narwhals is more focused traditional dataframes where row-order is defined   (although we are brainstorming a lazy-only level of support)</li> <li>Narwhals is extremely lightweight and comes with zero required dependencies,   Ibis requires pandas and PyArrow for all backends</li> <li>Narwhals supports Dask, whereas Ibis has deprecated support for it</li> </ul> <p>Although people often ask about the two tools, we consider them to be very different and not in competition. Further efforts to clarify the distinction are welcome \ud83d\ude4f!</p>"},{"location":"extending/","title":"Supported libraries and extending Narwhals","text":""},{"location":"extending/#list-of-supported-libraries-and-how-to-add-yours","title":"List of supported libraries (and how to add yours!)","text":"<p>Currently, Narwhals has full API support for the following libraries:</p> Library \ud83d\udd17 Link \ud83d\udd17 \ufe0fPolars \ud83d\udc3b\u200d\u2744\ufe0f github.com/pola-rs/polars pandas \ud83d\udc3c github.com/pandas-dev/pandas cuDF github.com/rapidsai/cudf Modin github.com/modin-project/modin PyArrow \u21f6 arrow.apache.org/docs/python <p>It also has lazy-only support for Dask, and interchange support for DuckDB and Ibis.</p> <p>We are working towards full \"lazy-only\" support for DuckDB, Ibis, and PySpark.</p>"},{"location":"extending/#levels-of-support","title":"Levels of support","text":"<p>Narwhals comes with three levels of support:</p> <ul> <li>Full API support: cuDF, Modin, pandas, Polars, PyArrow</li> <li>Lazy-only support: Dask. Work in progress: DuckDB, Ibis, PySpark.</li> <li>Interchange-level support: DuckDB, Ibis, Vaex, anything which implements the DataFrame Interchange Protocol</li> </ul> <p>Libraries for which we have full support can benefit from the whole Narwhals API.</p> <p>For example:</p> from/to_native@narwhalify <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\n\ndef func(df: IntoFrameT) -&gt; IntoFrameT:\n    return (\n        nw.from_native(df)\n        .group_by(\"a\")\n        .agg(\n            b_mean=nw.col(\"b\").mean(),\n            b_std=nw.col(\"b\").std(),\n        )\n        .to_native()\n    )\n</code></pre> <pre><code>import narwhals as nw\nfrom narwhals.typing import FrameT\n\n\n@nw.narwhalify\ndef func(df: FrameT) -&gt; FrameT:\n    return df.group_by(\"a\").agg(\n        b_mean=nw.col(\"b\").mean(),\n        b_std=nw.col(\"b\").std(),\n    )\n</code></pre> <p>will work for any of pandas, Polars, cuDF, Modin, and PyArrow.</p> <p>However, sometimes you don't need to do complex operations on dataframes - all you need is to inspect the schema a bit before making other decisions, such as which columns to select or whether to convert to another library. For that purpose, we also provide \"interchange\" level of support. If a library implements the Dataframe Interchange Protocol, then a call such as</p> <pre><code>from typing import Any\n\nimport narwhals as nw\nfrom narwhals.schema import Schema\n\n\ndef func(df: Any) -&gt; Schema:\n    df = nw.from_native(df, eager_or_interchange_only=True)\n    return df.schema\n</code></pre> <p>is also supported, meaning that, in addition to the libraries mentioned above, you can also pass Ibis, DuckDB, Vaex, and any library which implements the protocol.</p>"},{"location":"extending/#interchange-only-support","title":"Interchange-only support","text":"<p>While libraries for which we have full support can benefit from the whole Narwhals API, libraries which have interchange only support can access the following methods after  converting to Narwhals DataFrame:</p> <ul> <li><code>.schema</code>, hence column names via <code>.schema.names()</code> and column types via <code>.schema.dtypes()</code></li> <li><code>.columns</code></li> <li><code>.to_pandas()</code> and <code>.to_arrow()</code>, for converting to Pandas and Arrow, respectively.</li> <li><code>.select(names)</code> (Ibis and DuckDB), where <code>names</code> is a list of (string) column names. This is useful for   selecting columns before converting to another library.</li> </ul>"},{"location":"extending/#extending-narwhals","title":"Extending Narwhals","text":"<p>If you want your own library to be recognised too, you're welcome open a PR (with tests)!. Alternatively, if you can't do that (for example, if you library is closed-source), see the next section for what else you can do.</p> <p>We love open source, but we're not \"open source absolutists\". If you're unable to open source you library, then this is how you can make your library compatible with Narwhals.</p> <p>Make sure that you also define:</p> <ul> <li><code>DataFrame.__narwhals_dataframe__</code>: return an object which implements methods from the     <code>CompliantDataFrame</code> protocol in  <code>narwhals/typing.py</code>.</li> <li><code>DataFrame.__narwhals_namespace__</code>: return an object which implements methods from the     <code>CompliantNamespace</code> protocol in <code>narwhals/typing.py</code>.</li> <li><code>DataFrame.__native_namespace__</code>: return the object's native namespace.</li> <li><code>LazyFrame.__narwhals_lazyframe__</code>: return an object which implements methods from the     <code>CompliantLazyFrame</code> protocol in  <code>narwhals/typing.py</code>.</li> <li><code>LazyFrame.__narwhals_namespace__</code>: return an object which implements methods from the     <code>CompliantNamespace</code> protocol in <code>narwhals/typing.py</code>.</li> <li><code>LazyFrame.__native_namespace__</code>: return the object's native namespace.</li> <li><code>Series.__narwhals_series__</code>: return an object which implements methods from the     <code>CompliantSeries</code> protocol in <code>narwhals/typing.py</code>.</li> </ul> <p>If your library doesn't distinguish between lazy and eager, then it's OK for your dataframe   object to implement both <code>__narwhals_dataframe__</code> and <code>__narwhals_lazyframe__</code>. In fact,   that's currently what <code>narwhals._pandas_like.dataframe.PandasLikeDataFrame</code> does. So, if you're stuck,   take a look at the source code to see how it's done!</p> <p>Note that this \"extension\" mechanism is still experimental. If anything is not clear, or doesn't work, please do raise an issue or contact us on Discord (see the link on the README).</p>"},{"location":"how_it_works/","title":"How it works","text":""},{"location":"how_it_works/#theory","title":"Theory","text":"<p>You might think that Narwhals runs on underwater unicorn magic. However, this section exists to reassure you that there's no such thing. There's only one rule you need to understand in order to make sense of Narwhals:</p> <p>An expression is a function from a DataFrame to a sequence of Series.</p> <p>For example, <code>nw.col('a')</code> means \"given a dataframe <code>df</code>, give me the Series <code>'a'</code> from <code>df</code>\". Translating this to pandas syntax, we get:</p> <pre><code>def col_a(df):\n    return [df.loc[:, \"a\"]]\n</code></pre> <p>Let's step up the complexity. How about <code>nw.col('a')+1</code>? We already know what the <code>nw.col('a')</code> part looks like, so we just need to add <code>1</code> to each of its outputs:</p> <pre><code>def col_a(df):\n    return [df.loc[:, \"a\"]]\n\n\ndef col_a_plus_1(df):\n    return [x + 1 for x in col_a(df)]\n</code></pre> <p>Expressions can return multiple Series - for example, <code>nw.col('a', 'b')</code> translates to:</p> <pre><code>def col_a_b(df):\n    return [df.loc[:, \"a\"], df.loc[:, \"b\"]]\n</code></pre> <p>Expressions can also take multiple columns as input - for example, <code>nw.sum_horizontal('a', 'b')</code> translates to:</p> <pre><code>def sum_horizontal_a_b(df):\n    return [df.loc[:, \"a\"] + df.loc[:, \"b\"]]\n</code></pre> <p>Note that although an expression may have multiple columns as input, those columns must all have been derived from the same dataframe. This last sentence was quite important, you might want to re-read it to make sure it sunk in.</p> <p>By itself, an expression doesn't produce a value. It only produces a value once you give it to a DataFrame context. What happens to the value(s) it produces depends on which context you hand it to:</p> <ul> <li><code>DataFrame.select</code>: produce a DataFrame with only the result of the given expression</li> <li><code>DataFrame.with_columns</code>: produce a DataFrame like the current one, but also with the result of   the given expression</li> <li><code>DataFrame.filter</code>: evaluate the given expression, and if it only returns a single Series, then   only keep rows where the result is <code>True</code>.</li> </ul> <p>Now let's turn our attention to the implementation.</p>"},{"location":"how_it_works/#pandas-implementation","title":"pandas implementation","text":"<p>The pandas namespace (<code>pd</code>) isn't Narwhals-compliant, as the pandas API is very different from Polars'. So...Narwhals implements a <code>PandasLikeNamespace</code>, which includes the top-level Polars functions included in the Narwhals API:</p> <p><pre><code>import pandas as pd\nimport narwhals as nw\nfrom narwhals._pandas_like.namespace import PandasLikeNamespace\nfrom narwhals._pandas_like.utils import Implementation\nfrom narwhals.utils import parse_version, Version\n\npn = PandasLikeNamespace(\n    implementation=Implementation.PANDAS,\n    backend_version=parse_version(pd.__version__),\n    version=Version.MAIN,\n)\nprint(nw.col(\"a\")._to_compliant_expr(pn))\n</code></pre> <pre><code>PandasLikeExpr(depth=0, function_name=col, )\n</code></pre> The result from the last line above is the same as we'd get from <code>pn.col('a')</code>, and it's a <code>narwhals._pandas_like.expr.PandasLikeExpr</code> object, which we'll call <code>PandasLikeExpr</code> for short.</p> <p><code>PandasLikeExpr</code> has a <code>_call</code> method which expects a <code>PandasLikeDataFrame</code> as input. Recall from above that an expression is a function from a dataframe to a sequence of series. The <code>_call</code> method gives us that function! Let's see it in action.</p> <p>Note: the following examples use <code>PandasLikeDataFrame</code> and <code>PandasLikeSeries</code>. These are backed by actual <code>pandas.DataFrame</code>s and <code>pandas.Series</code> respectively and are Narwhals-compliant. We can access the  underlying pandas objects via <code>PandasLikeDataFrame._native_frame</code> and <code>PandasLikeSeries._native_series</code>.</p> <pre><code>import narwhals as nw\nfrom narwhals._pandas_like.namespace import PandasLikeNamespace\nfrom narwhals._pandas_like.utils import Implementation\nfrom narwhals._pandas_like.dataframe import PandasLikeDataFrame\nfrom narwhals.utils import parse_version, Version\nimport pandas as pd\n\npn = PandasLikeNamespace(\n    implementation=Implementation.PANDAS,\n    backend_version=parse_version(pd.__version__),\n    version=Version.MAIN,\n)\n\ndf_pd = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\ndf = PandasLikeDataFrame(\n    df_pd,\n    implementation=Implementation.PANDAS,\n    backend_version=parse_version(pd.__version__),\n    version=Version.MAIN,\n)\nexpression = pn.col(\"a\") + 1\nresult = expression._call(df)\nprint(f\"length of result: {len(result)}\\n\")\nprint(\"native series of first value of result: \")\nprint([x._native_series for x in result][0])\n</code></pre> <pre><code>length of result: 1\n\nnative series of first value of result: \n0    2\n1    3\n2    4\nName: a, dtype: int64\n</code></pre> <p>So indeed, our expression did what it said on the tin - it took some dataframe, took column 'a', and added 1 to it.</p> <p>If you search for <code>def reuse_series_implementation</code>, you'll see that that's all expressions do in Narwhals - they just keep rigorously applying the definition of expression.</p> <p>It may look like there should be significant overhead to doing it this way - but really, it's just a few Python calls which get unwinded. From timing tests I've done, there's no detectable difference - in fact, because the Narwhals API guards against misusing the pandas API, it's likely that running pandas via Narwhals will in general be more efficient than running pandas directly.</p> <p>Further attempts at demistifying Narwhals, refactoring code so it's clearer, and explaining this section better are 110% welcome.</p>"},{"location":"how_it_works/#polars-and-other-implementations","title":"Polars and other implementations","text":"<p>Other implementations are similar to the above: they define their own Narwhals-compliant objects. So, all-in-all, there are a couple of layers here:</p> <ul> <li><code>nw.DataFrame</code> is backed by a Narwhals-compliant Dataframe, such as:<ul> <li><code>narwhals._pandas_like.dataframe.PandasLikeDataFrame</code></li> <li><code>narwhals._arrow.dataframe.ArrowDataFrame</code></li> <li><code>narwhals._polars.dataframe.PolarsDataFrame</code></li> </ul> </li> <li>each Narwhals-compliant DataFrame is backed by a native Dataframe, for example:<ul> <li><code>narwhals._pandas_like.dataframe.PandasLikeDataFrame</code> is backed by a pandas DataFrame</li> <li><code>narwhals._arrow.dataframe.ArrowDataFrame</code> is backed by a PyArrow Table</li> <li><code>narwhals._polars.dataframe.PolarsDataFrame</code> is backed by a Polars DataFrame</li> </ul> </li> </ul> <p>Each implementation defines its own objects in subfolders such as <code>narwhals._pandas_like</code>, <code>narwhals._arrow</code>, <code>narwhals._polars</code>, whereas the top-level modules such as <code>narwhals.dataframe</code> and <code>narwhals.series</code> coordinate how to dispatch the Narwhals API to each backend.</p>"},{"location":"how_it_works/#mapping-from-api-to-implementations","title":"Mapping from API to implementations","text":"<p>If an end user executes some Narwhals code, such as</p> <p><pre><code>df.select(nw.col(\"a\") + 1)\n</code></pre> then how does that get mapped to the underlying dataframe's native API? Let's walk through this example to see.</p> <p>Things generally go through a couple of layers:</p> <ul> <li>The user calls some top-level Narwhals API.</li> <li>The Narwhals API forwards the call to a Narwhals-compliant dataframe wrapper, such as<ul> <li><code>PandasLikeDataFrame</code> / <code>ArrowDataFrame</code> / <code>PolarsDataFrame</code> / ...</li> <li><code>PandasLikeSeries</code> / <code>ArrowSeries</code> / <code>PolarsSeries</code> / ...</li> <li><code>PandasLikeExpr</code> / <code>ArrowExpr</code> / <code>PolarsExpr</code> / ...</li> </ul> </li> <li>The dataframe wrapper forwards the call to the underlying library, e.g.:<ul> <li><code>PandasLikeDataFrame</code> forwards the call to the underlying pandas/Modin/cuDF dataframe.</li> <li><code>ArrowDataFrame</code> forwards the call to the underlying PyArrow table.</li> <li><code>PolarsDataFrame</code> forwards the call to the underlying Polars DataFrame.</li> </ul> </li> </ul> <p>The way you access the Narwhals-compliant wrapper depends on the object:</p> <ul> <li><code>narwhals.DataFrame</code> and <code>narwhals.LazyFrame</code>: use the <code>._compliant_frame</code> attribute.</li> <li><code>narwhals.Series</code>: use the <code>._compliant_series</code> attribute.</li> <li><code>narwhals.Expr</code>: call the <code>._to_compliant_expr</code> method, and pass to it the Narwhals-compliant namespace associated with   the given backend.</li> </ul> <p>\ud83d\uded1 BUT WAIT! What's a Narwhals-compliant namespace?</p> <p>Each backend is expected to implement a Narwhals-compliant namespace (<code>PandasLikeNamespace</code>, <code>ArrowNamespace</code>, <code>PolarsNamespace</code>). These can be used to interact with the Narwhals-compliant Dataframe and Series objects described above - let's work through the motivating example to see how.</p> <pre><code>import narwhals as nw\nfrom narwhals._pandas_like.namespace import PandasLikeNamespace\nfrom narwhals._pandas_like.utils import Implementation\nfrom narwhals._pandas_like.dataframe import PandasLikeDataFrame\nfrom narwhals.utils import parse_version, Version\nimport pandas as pd\n\npn = PandasLikeNamespace(\n    implementation=Implementation.PANDAS,\n    backend_version=parse_version(pd.__version__),\n    version=Version.MAIN,\n)\n\ndf_pd = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\ndf = nw.from_native(df_pd)\ndf.select(nw.col(\"a\") + 1)\n</code></pre> <p>The first thing <code>narwhals.DataFrame.select</code> does is to parse each input expression to end up with a compliant expression for the given backend, and it does so by passing a Narwhals-compliant namespace to <code>nw.Expr._to_compliant_expr</code>:</p> <p><pre><code>pn = PandasLikeNamespace(\n    implementation=Implementation.PANDAS,\n    backend_version=parse_version(pd.__version__),\n    version=Version.MAIN,\n)\nexpr = (nw.col(\"a\") + 1)._to_compliant_expr(pn)\nprint(expr)\n</code></pre> <pre><code>PandasLikeExpr(depth=1, function_name=col-&gt;__add__, )\n</code></pre> If we then extract a Narwhals-compliant dataframe from <code>df</code> by calling <code>._compliant_frame</code>, we get a <code>PandasLikeDataFrame</code> - and that's an object which we can pass <code>expr</code> to!</p> <pre><code>df_compliant = df._compliant_frame\nresult = df_compliant.select(expr)\n</code></pre> <p>We can then view the underlying pandas Dataframe which was produced by calling <code>._native_frame</code>:</p> <p><pre><code>print(result._native_frame)\n</code></pre> <pre><code>   a\n0  2\n1  3\n2  4\n</code></pre> which is the same as we'd have obtained by just using the Narwhals API directly:</p> <pre><code>print(nw.to_native(df.select(nw.col(\"a\") + 1)))\n</code></pre> <pre><code>   a\n0  2\n1  3\n2  4\n</code></pre>"},{"location":"how_it_works/#group-by","title":"Group-by","text":"<p>Group-by is probably one of Polars' most significant innovations (on the syntax side) with respect to pandas. We can write something like <pre><code>df: pl.DataFrame\ndf.group_by(\"a\").agg((pl.col(\"c\") &gt; pl.col(\"b\").mean()).max())\n</code></pre> To do this in pandas, we need to either use <code>GroupBy.apply</code> (sloooow), or do some crazy manual optimisations to get it to work.</p> <p>In Narwhals, here's what we do:</p> <ul> <li>if somebody uses a simple group-by aggregation (e.g. <code>df.group_by('a').agg(nw.col('b').mean())</code>),   then on the pandas side we translate it to   <pre><code>df: pd.DataFrame\ndf.groupby(\"a\").agg({\"b\": [\"mean\"]})\n</code></pre></li> <li>if somebody passes a complex group-by aggregation, then we use <code>apply</code> and raise a <code>UserWarning</code>, warning   users of the performance penalty and advising them to refactor their code so that the aggregation they perform   ends up being a simple one.</li> </ul> <p>In order to tell whether an aggregation is simple, Narwhals uses the private <code>_depth</code> attribute of <code>PandasLikeExpr</code>:</p> <pre><code>print(pn.col(\"a\").mean())\nprint((pn.col(\"a\") + 1).mean())\n</code></pre> <pre><code>PandasLikeExpr(depth=1, function_name=col-&gt;mean, )\nPandasLikeExpr(depth=2, function_name=col-&gt;__add__-&gt;mean, )\n</code></pre> <p>For simple aggregations, Narwhals can just look at <code>_depth</code> and <code>function_name</code> and figure out which (efficient) elementary operation this corresponds to in pandas.</p>"},{"location":"installation/","title":"Installation and quick start","text":""},{"location":"installation/#installation","title":"Installation","text":"UVPython's venv <p>First, ensure you have installed UV, and make sure you have created and activated a Python 3.8+ virtual environment.</p> <p>If you haven't, you can follow our setting up your environment guide. Then, run:</p> <pre><code>uv pip install narwhals\n</code></pre> <p>First, ensure you have created and activated a Python 3.8+ virtual environment.</p> <p>Then, run:</p> <pre><code>python -m pip install narwhals\n</code></pre>"},{"location":"installation/#verifying-the-installation","title":"Verifying the Installation","text":"<p>To verify the installation, start the Python REPL and execute:</p> <pre><code>&gt;&gt;&gt; import narwhals\n&gt;&gt;&gt; narwhals.__version__\n'1.24.0'\n</code></pre> <p>If you see the version number, then the installation was successful!</p>"},{"location":"installation/#quick-start","title":"Quick start","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Please start by following the installation instructions.</p> <p>To follow along with the examples which follow, please install the following (though note that they are not required dependencies - Narwhals only ever uses what the user passes in):</p> <ul> <li>pandas</li> <li>Polars</li> <li>PyArrow</li> </ul>"},{"location":"installation/#simple-example","title":"Simple example","text":"<p>Create a Python file <code>t.py</code> with the following content:</p> <pre><code>from __future__ import annotations\n\nimport pandas as pd\nimport polars as pl\nimport pyarrow as pa\nimport narwhals as nw\nfrom narwhals.typing import IntoFrame\n\n\ndef agnostic_get_columns(df_native: IntoFrame) -&gt; list[str]:\n    df = nw.from_native(df_native)\n    column_names = df.columns\n    return column_names\n\n\ndata = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\ndf_pandas = pd.DataFrame(data)\ndf_polars = pl.DataFrame(data)\ntable_pa = pa.table(data)\n\nprint(\"pandas output\")\nprint(agnostic_get_columns(df_pandas))\n\nprint(\"Polars output\")\nprint(agnostic_get_columns(df_polars))\n\nprint(\"PyArrow output\")\nprint(agnostic_get_columns(table_pa))\n</code></pre> <pre><code>pandas output\n['a', 'b']\nPolars output\n['a', 'b']\nPyArrow output\n['a', 'b']\n</code></pre> <p>If you run <code>python t.py</code> then your output should look like the above. This is the simplest possible example of a dataframe-agnostic function - as we'll soon see, we can do much more advanced things.</p> <p>Let's learn about what you just did, and what Narwhals can do for you!</p> <p>Info</p> <p>These examples are using pandas, Polars, and PyArrow, however Narwhals supports other dataframe libraries (See supported libraries).</p>"},{"location":"overhead/","title":"Overhead","text":"<p>Narwhals converts Polars syntax to non-Polars dataframes.</p> <p>So, what's the overhead of running pandas vs pandas via Narwhals?</p> <p>Based on experiments we've done, the answer is: it's negligible. Here are timings from the TPC-H queries, comparing running pandas directly vs running pandas via Narwhals:</p> <p></p> <p>Here's the code to reproduce the plot above, check the input sources for notebooks which run each individual query, along with the data sources.</p> <p>On some runs, the Narwhals code makes things marginally faster, on others marginally slower. The overall picture is clear: with Narwhals, you can support both Polars and pandas APIs with little to no impact on either.</p>"},{"location":"resources/","title":"Resources","text":""},{"location":"resources/#sponsors-and-institutional-partners","title":"Sponsors and institutional partners","text":"<p>Narwhals is 100% independent, community-driven, and community-owned. We are extremely grateful to the following organisations for having provided some funding / development time:</p> <ul> <li>Quansight Labs</li> <li>Quansight Futures</li> <li>OpenTeams</li> <li>POSSEE initiative</li> <li>BYU-Idaho</li> </ul> <p>If you contribute to Narwhals on your organization's time, please let us know. We'd be happy to add your employer to this list!</p>"},{"location":"resources/#appears-on","title":"Appears on","text":"<p>Narwhals has been featured in several talks, podcasts, and blog posts:</p> <ul> <li> <p>Talk Python to me Podcast   Ahoy, Narwhals are bridging the data science APIs</p> </li> <li> <p>Python Bytes Podcast   Episode 402, topic #2</p> </li> <li> <p>Super Data Science: ML &amp; AI Podcast   Narwhals: For Pandas-to-Polars DataFrame Compatibility</p> </li> <li> <p>Sample Space Podcast | probabl   How Narwhals has many end users ... that never use it directly. - Marco Gorelli</p> </li> <li> <p>The Real Python Podcast   Narwhals: Expanding DataFrame Compatibility Between Libraries</p> </li> <li> <p>Pycon Lithuania   Marco Gorelli - DataFrame interoperatiblity - what's been achieved, and what comes next?</p> </li> <li> <p>Pycon Italy   How you can write a dataframe-agnostic library - Marco Gorelli</p> </li> <li> <p>Polars Blog Post   Polars has a new lightweight plotting backend</p> </li> <li> <p>Quansight Labs blog post (w/ Scikit-Lego)   How Narwhals and scikit-lego came together to achieve dataframe-agnosticism</p> </li> </ul>"},{"location":"security/","title":"Security","text":"<p>Given that Narwhals can only work if people trust it, we recognise the importance of following good security practices. Here are some practices we follow:</p> <ul> <li>We publish to PyPI via trusted publishing and are PEP740-compliant.</li> <li>We don't use <code>pull_request_target</code> in any CI job.</li> <li>The release CI job can only be triggered for tag pushes, and only   Narwhals members with release permissions (see below) can push tags.</li> <li>All members of <code>narwhals-dev</code> are required to have two-factor authentication   enabled.</li> <li>There are no binary or opaque files in the Narwhals repository.</li> <li> <p>Release permissions are only given to people who satisfy all of the following:</p> <ul> <li>Have met the original author in real life on multiple days.</li> <li>Have made significant contributions to Narwhals.</li> <li>Give off good vibes. This is hard to rigorously define, but it's there so we     can refuse anyone who, despite satisfying the above two criteria, we don't     feel like we can trust.</li> <li>There are fewer than 5 active people with release permissions. That is     to say, even if someone satisfies all of the above, if there are already 5     people with release permissions, then we will not be adding any more (though     you may still be added to <code>narwhals-dev</code> and get permission to merge pull     requests which you believe are ready). Note that we already meet that limit.</li> </ul> </li> </ul>"},{"location":"this/","title":"The Zen of Narwhals","text":"<p>The well famous Python easter egg <code>import this</code> will reveal The Zen of Python (PEP 20).</p> <p>Narwhals took inspiration from this and created its own Zen.</p> <pre><code>import narwhals.this\n</code></pre> <pre><code>\u28ff\u28ff\u28ff\u28ff\u28ff\u2818\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff THE ZEN OF NARWHALS\n\u28ff\u28ff\u28ff\u28ff\u28ff\u2820\u28b9\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff Keep it simple\n\u28ff\u28ff\u28ff\u28ff\u28ff\u2840\u2844\u28bf\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff Move slowly and keep things working\n\u28ff\u28ff\u28ff\u28ff\u28ff\u2847\u287c\u2858\u281b\u283f\u283f\u283f\u28bf\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff A good API is an honest one\n\u28ff\u28ff\u28ff\u287f\u28eb\u2844\u283e\u28e3\u2839\u28ff\u28ff\u28ff\u28f6\u28ee\u28d9\u283b\u28bf\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff Yes, that needs documenting\n\u28ff\u28ff\u288b\u28f4\u28ff\u28f7\u28ec\u28ed\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28e6\u2859\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff People learn better from examples\n\u28ff\u2883\u28fe\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28f7\u284c\u28bf\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff   than from explanations\u2800\n\u284f\u2800\u28b0\u2804\u28bb\u28ff\u28ff\u28ff\u28ff\u287f\u280b\u2889\u283b\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u285c\u28ff\u28ff\u287f\u2881\u28bb\u28ff\u28ff\u28ff\u28ff\u28ff If in doubt, better to say 'no'\n\u2847\u28cc\u28c0\u28e0\u28fe\u28ff\u28ff\u28ff\u28ff\u28c7\u2836\u2809\u2881\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28e7\u2879\u28ff\u2847\u28ff\u28e7\u283b\u283f\u283f\u283f\u283f   than to risk causing a commotion\u2800\n\u2867\u28b9\u28ff\u28ff\u28ff\u28dc\u28df\u28f8\u28ff\u28ff\u28f7\u28f6\u28ff\u287f\u28ff\u28ff\u28dd\u28bf\u28ff\u28ff\u28f7\u28ec\u28e5\u28ff\u28ff\u28ff\u28ff\u28ff\u285f\u28f0 Yes, we need a test for that\n\u28a1\u28c6\u28bb\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28e7\u2859\u28ff\u28ff\u2847\u28ff\u28ff\u28ff\u28ff\u281f\u28cb\u28ed\u28db\u283b\u28cb\u28f4\u28ff If you want users  \n\u28f6\u28e4\u28e4\u28d9\u283b\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28f7\u28e6\u28cd\u28e1\u28ff\u287f\u288b\u28f4\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff   you need good docs\u2800\n\u28ff\u28ff\u28ff\u28ff\u28ff\u28f6\u28ec\u28d9\u28db\u283b\u283f\u283f\u283f\u283f\u283f\u281f\u28db\u28e9\u28e5\u28f6\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff Our code is not irreplaceable\n</code></pre>"},{"location":"why/","title":"Why?","text":"<p>You may think that pandas, Polars, and all dataframe libraries are quite similar. But are they really?</p> <p>For example, do the following produce the same output?</p> <pre><code>import pandas as pd\nimport polars as pl\n\nprint(3 in pd.Series([1, 2, 3]))\nprint(3 in pl.Series([1, 2, 3]))\n</code></pre> <p>Try it out and see \ud83d\ude09</p> <p>Spoiler alert: they don't. pandas checks if <code>3</code> is in the index, Polars checks if it's in the values.</p> <p>For another example, try running the code below - note how the outputs have different column names after the join!</p> <pre><code>pd_df_left = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\npd_df_right = pd.DataFrame({\"a\": [1, 2, 3], \"c\": [4, 5, 6]})\npd_left_merge = pd_df_left.merge(pd_df_right, left_on=\"b\", right_on=\"c\", how=\"left\")\n\npl_df_left = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\npl_df_right = pl.DataFrame({\"a\": [1, 2, 3], \"c\": [4, 5, 6]})\npl_left_merge = pl_df_left.join(pl_df_right, left_on=\"b\", right_on=\"c\", how=\"left\")\n\nprint(pd_left_merge.columns)\nprint(pl_left_merge.columns)\n</code></pre> <p>There are several such subtle difference between the libraries. Writing dataframe-agnostic code is hard!</p> <p>But by having a unified, simple, and predictable API, you can focus on behaviour rather than on subtle implementation differences.</p> <p>Furthermore, both pandas and Polars frequently deprecate behaviour. Narwhals handles this for you by testing against nightly builds of both libraries and handling backwards compatibility internally (so you don't have to!).</p>"},{"location":"api-completeness/","title":"API Completeness","text":"<p>In the following section it is possible to check which method is implemented for which class and backend.</p> <p>Info</p> <ul> <li>By design, Polars supports all the methods of the Narwhals API.</li> <li>\"pandas-like\" means pandas, cuDF and Modin.</li> <li>\"spark-like\" means PySpark, but we may extend this to also cover SQLFrame.</li> </ul>"},{"location":"api-completeness/dataframe/","title":"DataFrame","text":"Method arrow pandas-like polars clone collect_schema columns drop drop_nulls estimated_size explode filter gather_every get_column group_by head implementation is_duplicated is_empty is_unique item iter_rows join join_asof lazy null_count pipe pivot rename row rows sample schema select shape sort tail to_arrow to_dict to_native to_numpy to_pandas to_polars unique unpivot with_columns with_row_index write_csv write_parquet"},{"location":"api-completeness/expr/","title":"Expr","text":"Method arrow dask duckdb pandas-like polars spark-like abs alias all any arg_max arg_min arg_true cast cat clip count cum_count cum_max cum_min cum_prod cum_sum diff drop_nulls dt ewm_mean fill_null filter gather_every head is_between is_duplicated is_finite is_first_distinct is_in is_last_distinct is_nan is_null is_unique len list map_batches max mean median min mode n_unique name null_count over pipe quantile rank replace_strict rolling_mean rolling_std rolling_sum rolling_var round sample shift skew sort std str sum tail unique var"},{"location":"api-completeness/expr_cat/","title":"Expr.cat","text":"Method arrow pandas-like polars get_categories"},{"location":"api-completeness/expr_dt/","title":"Expr.dt","text":"Method arrow dask duckdb pandas-like polars spark-like convert_time_zone date day hour microsecond millisecond minute month nanosecond ordinal_day replace_time_zone second timestamp to_string total_microseconds total_milliseconds total_minutes total_nanoseconds total_seconds weekday year"},{"location":"api-completeness/expr_list/","title":"Expr.list","text":"Method arrow duckdb pandas-like polars len"},{"location":"api-completeness/expr_name/","title":"Expr.name","text":"Method arrow dask duckdb pandas-like polars spark-like keep map prefix suffix to_lowercase to_uppercase"},{"location":"api-completeness/expr_str/","title":"Expr.str","text":"Method arrow dask duckdb pandas-like polars spark-like contains ends_with head len_chars replace replace_all slice starts_with strip_chars tail to_datetime to_lowercase to_uppercase"},{"location":"api-completeness/lazyframe/","title":"LazyFrame","text":"Method dask duckdb polars spark-like clone collect collect_schema columns drop drop_nulls explode filter gather_every group_by head implementation join join_asof lazy pipe rename schema select sort tail to_native unique unpivot with_columns with_row_index"},{"location":"api-completeness/series/","title":"Series","text":"Method arrow pandas-like polars abs alias all any arg_max arg_min arg_true cast cat clip count cum_count cum_max cum_min cum_prod cum_sum diff drop_nulls dt dtype ewm_mean fill_null filter gather_every head implementation is_between is_duplicated is_empty is_finite is_first_distinct is_in is_last_distinct is_nan is_null is_sorted is_unique item len list max mean median min mode n_unique name null_count pipe quantile rank rename replace_strict rolling_mean rolling_std rolling_sum rolling_var round sample scatter shape shift skew sort std str sum tail to_arrow to_dummies to_frame to_list to_native to_numpy to_pandas to_polars unique value_counts var zip_with"},{"location":"api-completeness/series_cat/","title":"Series.cat","text":"Method arrow pandas-like polars get_categories"},{"location":"api-completeness/series_dt/","title":"Series.dt","text":"Method arrow pandas-like polars convert_time_zone date day hour microsecond millisecond minute month nanosecond ordinal_day replace_time_zone second timestamp to_string total_microseconds total_milliseconds total_minutes total_nanoseconds total_seconds weekday year"},{"location":"api-completeness/series_list/","title":"Series.list","text":"Method arrow pandas-like polars len"},{"location":"api-completeness/series_str/","title":"Series.str","text":"Method arrow pandas-like polars contains ends_with head len_chars replace replace_all slice starts_with strip_chars tail to_datetime to_lowercase to_uppercase"},{"location":"api-reference/","title":"API Reference","text":"<ul> <li>Top-level functions</li> <li>narwhals.DataFrame</li> <li>narwhals.Expr</li> <li>narwhals.Expr.cat</li> <li>narwhals.Expr.dt</li> <li>narwhals.Expr.list</li> <li>narwhals.Expr.name</li> <li>narwhals.Expr.str</li> <li>narwhals.GroupBy</li> <li>narwhals.LazyGroupBy</li> <li>narwhals.LazyFrame</li> <li>narwhals.Schema</li> <li>narwhals.Series</li> <li>narwhals.Series.cat</li> <li>narwhals.Series.dt</li> <li>narwhals.Series.list</li> <li>narwhals.Series.str</li> <li>narwhals.dependencies</li> <li>narwhals.dtypes</li> <li>narwhals.exceptions</li> <li>narwhals.selectors</li> <li>narwhals.typing</li> </ul>"},{"location":"api-reference/dataframe/","title":"<code>narwhals.DataFrame</code>","text":"<p>Narwhals DataFrame, backed by a native eager dataframe.</p> <p>Warning</p> <p>This class is not meant to be instantiated directly - instead:</p> <ul> <li> <p>If the native object is a eager dataframe from one of the supported     backend (e.g. pandas.DataFrame, polars.DataFrame, pyarrow.Table),     you can use <code>narwhals.from_native</code>:     <pre><code>narwhals.from_native(native_dataframe)\nnarwhals.from_native(native_dataframe, eager_only=True)\n</code></pre></p> </li> <li> <p>If the object is a dictionary of column names and generic sequences mapping     (e.g. <code>dict[str, list]</code>), you can create a DataFrame via     <code>narwhals.from_dict</code>:     <pre><code>narwhals.from_dict(\n    data={\"a\": [1, 2, 3]},\n    native_namespace=narwhals.get_native_namespace(another_object),\n)\n</code></pre></p> </li> </ul>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get column names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>The column names stored in a list.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_columns(df_native: IntoFrame) -&gt; list[str]:\n...     df = nw.from_native(df_native)\n...     return df.columns\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_columns</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_columns(df_pd)\n['foo', 'bar', 'ham']\n&gt;&gt;&gt; agnostic_columns(df_pl)\n['foo', 'bar', 'ham']\n&gt;&gt;&gt; agnostic_columns(df_pa)\n['foo', 'bar', 'ham']\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.implementation","title":"<code>implementation</code>  <code>property</code>","text":"<p>Return implementation of native frame.</p> <p>This can be useful when you need to use special-casing for features outside of Narwhals' scope - for example, when dealing with pandas' Period Dtype.</p> <p>Returns:</p> Type Description <code>Implementation</code> <p>Implementation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df_native = pd.DataFrame({\"a\": [1, 2, 3]})\n&gt;&gt;&gt; df = nw.from_native(df_native)\n&gt;&gt;&gt; df.implementation\n&lt;Implementation.PANDAS: 1&gt;\n&gt;&gt;&gt; df.implementation.is_pandas()\nTrue\n&gt;&gt;&gt; df.implementation.is_pandas_like()\nTrue\n&gt;&gt;&gt; df.implementation.is_polars()\nFalse\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.schema","title":"<code>schema</code>  <code>property</code>","text":"<p>Get an ordered mapping of column names to their data type.</p> <p>Returns:</p> Type Description <code>Schema</code> <p>A Narwhals Schema object that displays the mapping of column names.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.schema import Schema\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6.0, 7.0, 8.0],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_schema(df_native: IntoFrame) -&gt; Schema:\n...     df = nw.from_native(df_native)\n...     return df.schema\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_schema</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_schema(df_pd)\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n&gt;&gt;&gt; agnostic_schema(df_pl)\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n&gt;&gt;&gt; agnostic_schema(df_pa)\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Get the shape of the DataFrame.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>The shape of the dataframe as a tuple.</p> <p>Examples:</p> <p>Construct pandas and polars DataFrames:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3, 4, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_shape(df_native: IntoDataFrame) -&gt; tuple[int, int]:\n...     df = nw.from_native(df_native)\n...     return df.shape\n</code></pre> <p>We can then pass either pandas, Polars or PyArrow to <code>agnostic_shape</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_shape(df_pd)\n(5, 1)\n&gt;&gt;&gt; agnostic_shape(df_pl)\n(5, 1)\n&gt;&gt;&gt; agnostic_shape(df_pa)\n(5, 1)\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.__arrow_c_stream__","title":"<code>__arrow_c_stream__(requested_schema=None)</code>","text":"<p>Export a DataFrame via the Arrow PyCapsule Interface.</p> <ul> <li>if the underlying dataframe implements the interface, it'll return that</li> <li>else, it'll call <code>to_arrow</code> and then defer to PyArrow's implementation</li> </ul> <p>See PyCapsule Interface for more.</p>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.__getitem__","title":"<code>__getitem__(item)</code>","text":"<p>Extract column or slice of DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>item</code> <code>str | slice | Sequence[int] | Sequence[str] | tuple[Sequence[int], str | int] | tuple[slice, str | int] | tuple[slice | Sequence[int], Sequence[int] | Sequence[str] | slice] | tuple[slice, slice]</code> <p>How to slice dataframe. What happens depends on what is passed. It's easiest to explain by example. Suppose we have a Dataframe <code>df</code>:</p> <ul> <li><code>df['a']</code> extracts column <code>'a'</code> and returns a <code>Series</code>.</li> <li><code>df[0:2]</code> extracts the first two rows and returns a <code>DataFrame</code>.</li> <li><code>df[0:2, 'a']</code> extracts the first two rows from column <code>'a'</code> and returns     a <code>Series</code>.</li> <li><code>df[0:2, 0]</code> extracts the first two rows from the first column and returns     a <code>Series</code>.</li> <li><code>df[[0, 1], [0, 1, 2]]</code> extracts the first two rows and the first three columns     and returns a <code>DataFrame</code></li> <li><code>df[:, [0, 1, 2]]</code> extracts all rows from the first three columns and returns a   <code>DataFrame</code>.</li> <li><code>df[:, ['a', 'c']]</code> extracts all rows and columns <code>'a'</code> and <code>'c'</code> and returns a   <code>DataFrame</code>.</li> <li><code>df[['a', 'c']]</code> extracts all rows and columns <code>'a'</code> and <code>'c'</code> and returns a   <code>DataFrame</code>.</li> <li><code>df[0: 2, ['a', 'c']]</code> extracts the first two rows and columns <code>'a'</code> and <code>'c'</code> and     returns a <code>DataFrame</code></li> <li><code>df[:, 0: 2]</code> extracts all rows from the first two columns and returns a <code>DataFrame</code></li> <li><code>df[:, 'a': 'c']</code> extracts all rows and all columns positioned between <code>'a'</code> and <code>'c'</code> inclusive and returns a <code>DataFrame</code>. For example, if the columns are     <code>'a', 'd', 'c', 'b'</code>, then that would extract columns <code>'a'</code>, <code>'d'</code>, and <code>'c'</code>.</li> </ul> required <p>Returns:</p> Type Description <code>Series[Any] | Self</code> <p>A Narwhals Series, backed by a native series.</p> Notes <ul> <li>Integers are always interpreted as positions</li> <li>Strings are always interpreted as column names.</li> </ul> <p>In contrast with Polars, pandas allows non-string column names. If you don't know whether the column name you're trying to extract is definitely a string (e.g. <code>df[df.columns[0]]</code>) then you should use <code>DataFrame.get_column</code> instead.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [3, 4]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_slice(df_native: IntoDataFrame) -&gt; IntoSeries:\n...     df = nw.from_native(df_native)\n...     return df[\"a\"].to_native()\n</code></pre> <p>We can then pass either pandas, Polars or PyArrow to <code>agnostic_slice</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_slice(df_pd)\n0    1\n1    2\nName: a, dtype: int64\n&gt;&gt;&gt; agnostic_slice(df_pl)\nshape: (2,)\nSeries: 'a' [i64]\n[\n    1\n    2\n]\n&gt;&gt;&gt; agnostic_slice(df_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    2\n  ]\n]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.clone","title":"<code>clone()</code>","text":"<p>Create a copy of this DataFrame.</p> <p>Returns:</p> Type Description <code>Self</code> <p>An identical copy of the original dataframe.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [3, 4]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we clone the DataFrame:</p> <pre><code>&gt;&gt;&gt; def agnostic_clone(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.clone().to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas or Polars to <code>agnostic_clone</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_clone(df_pd)\n   a  b\n0  1  3\n1  2  4\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_clone(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 3   \u2502\n\u2502 2   \u2506 4   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.collect_schema","title":"<code>collect_schema()</code>","text":"<p>Get an ordered mapping of column names to their data type.</p> <p>Returns:</p> Type Description <code>Schema</code> <p>A Narwhals Schema object that displays the mapping of column names.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.schema import Schema\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6.0, 7.0, 8.0],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_collect_schema(df_native: IntoFrame) -&gt; Schema:\n...     df = nw.from_native(df_native)\n...     return df.collect_schema()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_collect_schema</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_collect_schema(df_pd)\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n&gt;&gt;&gt; agnostic_collect_schema(df_pl)\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n&gt;&gt;&gt; agnostic_collect_schema(df_pa)\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.drop","title":"<code>drop(*columns, strict=True)</code>","text":"<p>Remove columns from the dataframe.</p> <p>Returns:</p> Type Description <code>Self</code> <p>The dataframe with the specified columns removed.</p> <p>Parameters:</p> Name Type Description Default <code>*columns</code> <code>str | Iterable[str]</code> <p>Names of the columns that should be removed from the dataframe.</p> <code>()</code> <code>strict</code> <code>bool</code> <p>Validate that all column names exist in the schema and throw an exception if a column name does not exist in the schema.</p> <code>True</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_drop(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return nw.from_native(df_native).drop(\"ham\").to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_drop</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_drop(df_pd)\n   foo  bar\n0    1  6.0\n1    2  7.0\n2    3  8.0\n&gt;&gt;&gt; agnostic_drop(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6.0 \u2502\n\u2502 2   \u2506 7.0 \u2502\n\u2502 3   \u2506 8.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_drop(df_pa)\npyarrow.Table\nfoo: int64\nbar: double\n----\nfoo: [[1,2,3]]\nbar: [[6,7,8]]\n</code></pre> <p>Use positional arguments to drop multiple columns.</p> <pre><code>&gt;&gt;&gt; def agnostic_drop_multi(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return nw.from_native(df_native).drop(\"foo\", \"ham\").to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_drop_multi(df_pd)\n   bar\n0  6.0\n1  7.0\n2  8.0\n&gt;&gt;&gt; agnostic_drop_multi(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 bar \u2502\n\u2502 --- \u2502\n\u2502 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 6.0 \u2502\n\u2502 7.0 \u2502\n\u2502 8.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_drop_multi(df_pa)\npyarrow.Table\nbar: double\n----\nbar: [[6,7,8]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.drop_nulls","title":"<code>drop_nulls(subset=None)</code>","text":"<p>Drop rows that contain null values.</p> <p>Parameters:</p> Name Type Description Default <code>subset</code> <code>str | list[str] | None</code> <p>Column name(s) for which null values are considered. If set to None (default), use all columns.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The original object with the rows removed that contained the null values.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"a\": [1.0, 2.0, None], \"ba\": [1.0, None, 2.0]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_drop_nulls(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.drop_nulls().to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_drop_nulls</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_drop_nulls(df_pd)\n     a   ba\n0  1.0  1.0\n&gt;&gt;&gt; agnostic_drop_nulls(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 ba  \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 f64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0 \u2506 1.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_drop_nulls(df_pa)\npyarrow.Table\na: double\nba: double\n----\na: [[1]]\nba: [[1]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.estimated_size","title":"<code>estimated_size(unit='b')</code>","text":"<p>Return an estimation of the total (heap) allocated size of the <code>DataFrame</code>.</p> <p>Estimated size is given in the specified unit (bytes by default).</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>SizeUnit</code> <p>'b', 'kb', 'mb', 'gb', 'tb', 'bytes', 'kilobytes', 'megabytes', 'gigabytes', or 'terabytes'.</p> <code>'b'</code> <p>Returns:</p> Type Description <code>int | float</code> <p>Integer or Float.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrameT\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6.0, 7.0, 8.0],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_estimated_size(df_native: IntoDataFrameT) -&gt; int | float:\n...     df = nw.from_native(df_native)\n...     return df.estimated_size()\n</code></pre> <p>We can then pass either pandas, Polars or PyArrow to <code>agnostic_estimated_size</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_estimated_size(df_pd)\nnp.int64(330)\n&gt;&gt;&gt; agnostic_estimated_size(df_pl)\n51\n&gt;&gt;&gt; agnostic_estimated_size(df_pa)\n63\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.explode","title":"<code>explode(columns, *more_columns)</code>","text":"<p>Explode the dataframe to long format by exploding the given columns.</p> Notes <p>It is possible to explode multiple columns only if these columns must have matching element counts.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str | Sequence[str]</code> <p>Column names. The underlying columns being exploded must be of the <code>List</code> data type.</p> required <code>*more_columns</code> <code>str</code> <p>Additional names of columns to explode, specified as positional arguments.</p> <code>()</code> <p>Returns:</p> Type Description <code>Self</code> <p>New DataFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"a\": [\"x\", \"y\", \"z\", \"w\"],\n...     \"lst1\": [[1, 2], None, [None], []],\n...     \"lst2\": [[3, None], None, [42], []],\n... }\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_explode(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return (\n...         nw.from_native(df_native)\n...         .with_columns(nw.col(\"lst1\", \"lst2\").cast(nw.List(nw.Int32())))\n...         .explode(\"lst1\", \"lst2\")\n...         .to_native()\n...     )\n</code></pre> <p>We can then pass any supported library such as pandas, Polars (eager), or PyArrow to <code>agnostic_explode</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_explode(pd.DataFrame(data))\n   a  lst1  lst2\n0  x     1     3\n0  x     2  &lt;NA&gt;\n1  y  &lt;NA&gt;  &lt;NA&gt;\n2  z  &lt;NA&gt;    42\n3  w  &lt;NA&gt;  &lt;NA&gt;\n&gt;&gt;&gt; agnostic_explode(pl.DataFrame(data))\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 lst1 \u2506 lst2 \u2502\n\u2502 --- \u2506 ---  \u2506 ---  \u2502\n\u2502 str \u2506 i32  \u2506 i32  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 x   \u2506 1    \u2506 3    \u2502\n\u2502 x   \u2506 2    \u2506 null \u2502\n\u2502 y   \u2506 null \u2506 null \u2502\n\u2502 z   \u2506 null \u2506 42   \u2502\n\u2502 w   \u2506 null \u2506 null \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.filter","title":"<code>filter(*predicates, **constraints)</code>","text":"<p>Filter the rows in the DataFrame based on one or more predicate expressions.</p> <p>The original order of the remaining rows is preserved.</p> <p>Parameters:</p> Name Type Description Default <code>*predicates</code> <code>IntoExpr | Iterable[IntoExpr] | list[bool]</code> <p>Expression(s) that evaluates to a boolean Series. Can also be a (single!) boolean list.</p> <code>()</code> <code>**constraints</code> <code>Any</code> <p>Column filters; use <code>name = value</code> to filter columns by the supplied value. Each constraint will behave the same as <code>nw.col(name).eq(value)</code>, and will be implicitly joined with the other filter conditions using &amp;.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The filtered dataframe.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6, 7, 8],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we filter on one condition.</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.filter(nw.col(\"foo\") &gt; 1).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_filter</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_filter(df_pd)\n   foo  bar ham\n1    2    7   b\n2    3    8   c\n&gt;&gt;&gt; agnostic_filter(df_pl)\nshape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 7   \u2506 b   \u2502\n\u2502 3   \u2506 8   \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\nham: string\n----\nfoo: [[2,3]]\nbar: [[7,8]]\nham: [[\"b\",\"c\"]]\n</code></pre> <p>Filter on multiple conditions, combined with and/or operators:</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.filter((nw.col(\"foo\") &lt; 3) &amp; (nw.col(\"ham\") == \"a\")).to_native()\n&gt;&gt;&gt; agnostic_filter(df_pd)\n   foo  bar ham\n0    1    6   a\n&gt;&gt;&gt; agnostic_filter(df_pl)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6   \u2506 a   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\nham: string\n----\nfoo: [[1]]\nbar: [[6]]\nham: [[\"a\"]]\n</code></pre> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     dframe = df.filter(\n...         (nw.col(\"foo\") == 1) | (nw.col(\"ham\") == \"c\")\n...     ).to_native()\n...     return dframe\n&gt;&gt;&gt; agnostic_filter(df_pd)\n   foo  bar ham\n0    1    6   a\n2    3    8   c\n&gt;&gt;&gt; agnostic_filter(df_pl)\nshape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6   \u2506 a   \u2502\n\u2502 3   \u2506 8   \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\nham: string\n----\nfoo: [[1,3]]\nbar: [[6,8]]\nham: [[\"a\",\"c\"]]\n</code></pre> <p>Provide multiple filters using <code>*args</code> syntax:</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     dframe = df.filter(\n...         nw.col(\"foo\") &lt;= 2,\n...         ~nw.col(\"ham\").is_in([\"b\", \"c\"]),\n...     ).to_native()\n...     return dframe\n&gt;&gt;&gt; agnostic_filter(df_pd)\n   foo  bar ham\n0    1    6   a\n&gt;&gt;&gt; agnostic_filter(df_pl)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6   \u2506 a   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\nham: string\n----\nfoo: [[1]]\nbar: [[6]]\nham: [[\"a\"]]\n</code></pre> <p>Provide multiple filters using <code>**kwargs</code> syntax:</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.filter(foo=2, ham=\"b\").to_native()\n&gt;&gt;&gt; agnostic_filter(df_pd)\n   foo  bar ham\n1    2    7   b\n&gt;&gt;&gt; agnostic_filter(df_pl)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 7   \u2506 b   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\nham: string\n----\nfoo: [[2]]\nbar: [[7]]\nham: [[\"b\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.gather_every","title":"<code>gather_every(n, offset=0)</code>","text":"<p>Take every nth row in the DataFrame and return as a new DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Gather every n-th row.</p> required <code>offset</code> <code>int</code> <p>Starting index.</p> <code>0</code> <p>Returns:</p> Type Description <code>Self</code> <p>The dataframe containing only the selected rows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 4], \"b\": [5, 6, 7, 8]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function in which gather every 2 rows, starting from a offset of 1:</p> <pre><code>&gt;&gt;&gt; def agnostic_gather_every(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.gather_every(n=2, offset=1).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_gather_every</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_gather_every(df_pd)\n   a  b\n1  2  6\n3  4  8\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_gather_every(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 6   \u2502\n\u2502 4   \u2506 8   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_gather_every(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[2,4]]\nb: [[6,8]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.get_column","title":"<code>get_column(name)</code>","text":"<p>Get a single column by name.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The column name as a string.</p> required <p>Returns:</p> Type Description <code>Series[Any]</code> <p>A Narwhals Series, backed by a native series.</p> Notes <p>Although <code>name</code> is typed as <code>str</code>, pandas does allow non-string column names, and they will work when passed to this function if the <code>narwhals.DataFrame</code> is backed by a pandas dataframe with non-string columns. This function can only be used to extract a column by name, so there is no risk of ambiguity.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [3, 4]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_get_column(df_native: IntoDataFrame) -&gt; IntoSeries:\n...     df = nw.from_native(df_native)\n...     name = df.columns[0]\n...     return df.get_column(name).to_native()\n</code></pre> <p>We can then pass either pandas, Polars or PyArrow to <code>agnostic_get_column</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_get_column(df_pd)\n0    1\n1    2\nName: a, dtype: int64\n&gt;&gt;&gt; agnostic_get_column(df_pl)\nshape: (2,)\nSeries: 'a' [i64]\n[\n    1\n    2\n]\n&gt;&gt;&gt; agnostic_get_column(df_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    2\n  ]\n]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.group_by","title":"<code>group_by(*keys, drop_null_keys=False)</code>","text":"<p>Start a group by operation.</p> <p>Parameters:</p> Name Type Description Default <code>*keys</code> <code>str | Iterable[str]</code> <p>Column(s) to group by. Accepts multiple columns names as a list.</p> <code>()</code> <code>drop_null_keys</code> <code>bool</code> <p>if True, then groups where any key is null won't be included in the result.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>GroupBy</code> <code>GroupBy[Self]</code> <p>Object which can be used to perform aggregations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrameT\n&gt;&gt;&gt; data = {\n...     \"a\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n...     \"b\": [1, 2, 1, 3, 3],\n...     \"c\": [5, 4, 3, 2, 1],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we group by one column and call <code>agg</code> to compute the grouped sum of another column.</p> <pre><code>&gt;&gt;&gt; def agnostic_group_by_agg(df_native: IntoDataFrameT) -&gt; IntoDataFrameT:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.group_by(\"a\").agg(nw.col(\"b\").sum()).sort(\"a\").to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_group_by_agg</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_group_by_agg(df_pd)\n   a  b\n0  a  2\n1  b  5\n2  c  3\n&gt;&gt;&gt; agnostic_group_by_agg(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 2   \u2502\n\u2502 b   \u2506 5   \u2502\n\u2502 c   \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_group_by_agg(df_pa)\npyarrow.Table\na: string\nb: int64\n----\na: [[\"a\",\"b\",\"c\"]]\nb: [[2,5,3]]\n</code></pre> <p>Group by multiple columns by passing a list of column names.</p> <pre><code>&gt;&gt;&gt; def agnostic_group_by_agg(df_native: IntoDataFrameT) -&gt; IntoDataFrameT:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.group_by([\"a\", \"b\"]).agg(nw.max(\"c\")).sort(\"a\", \"b\").to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_group_by_agg(df_pd)\n   a  b  c\n0  a  1  5\n1  b  2  4\n2  b  3  2\n3  c  3  1\n&gt;&gt;&gt; agnostic_group_by_agg(df_pl)\nshape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1   \u2506 5   \u2502\n\u2502 b   \u2506 2   \u2506 4   \u2502\n\u2502 b   \u2506 3   \u2506 2   \u2502\n\u2502 c   \u2506 3   \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_group_by_agg(df_pa)\npyarrow.Table\na: string\nb: int64\nc: int64\n----\na: [[\"a\",\"b\",\"b\",\"c\"]]\nb: [[1,2,3,3]]\nc: [[5,4,2,1]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.head","title":"<code>head(n=5)</code>","text":"<p>Get the first <code>n</code> rows.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to return. If a negative value is passed, return all rows except the last <code>abs(n)</code>.</p> <code>5</code> <p>Returns:</p> Type Description <code>Self</code> <p>A subset of the dataframe of shape (n, n_columns).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3, 4, 5],\n...     \"bar\": [6, 7, 8, 9, 10],\n...     \"ham\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function that gets the first 3 rows.</p> <pre><code>&gt;&gt;&gt; def agnostic_head(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return nw.from_native(df_native).head(3).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_head</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_head(df_pd)\n   foo  bar ham\n0    1    6   a\n1    2    7   b\n2    3    8   c\n&gt;&gt;&gt; agnostic_head(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6   \u2506 a   \u2502\n\u2502 2   \u2506 7   \u2506 b   \u2502\n\u2502 3   \u2506 8   \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_head(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\nham: string\n----\nfoo: [[1,2,3]]\nbar: [[6,7,8]]\nham: [[\"a\",\"b\",\"c\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.is_duplicated","title":"<code>is_duplicated()</code>","text":"<p>Get a mask of all duplicated rows in this DataFrame.</p> <p>Returns:</p> Type Description <code>Series[Any]</code> <p>A new Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 2, 3, 1],\n...     \"b\": [\"x\", \"y\", \"z\", \"x\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_duplicated(df_native: IntoDataFrame) -&gt; IntoSeries:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.is_duplicated().to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_is_duplicated</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_duplicated(df_pd)\n0     True\n1    False\n2    False\n3     True\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_duplicated(df_pl)\nshape: (4,)\nSeries: '' [bool]\n[\n    true\n    false\n    false\n    true\n]\n&gt;&gt;&gt; agnostic_is_duplicated(df_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    true,\n    false,\n    false,\n    true\n  ]\n]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.is_empty","title":"<code>is_empty()</code>","text":"<p>Check if the dataframe is empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>A boolean indicating whether the dataframe is empty (True) or not (False).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n</code></pre> <p>Let's define a dataframe-agnostic function that filters rows in which \"foo\" values are greater than 10, and then checks if the result is empty or not:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_empty(df_native: IntoDataFrame) -&gt; bool:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.filter(nw.col(\"foo\") &gt; 10).is_empty()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_is_empty</code>:</p> <pre><code>&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [4, 5, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n&gt;&gt;&gt; agnostic_is_empty(df_pd), agnostic_is_empty(df_pl), agnostic_is_empty(df_pa)\n(True, True, True)\n</code></pre> <pre><code>&gt;&gt;&gt; data = {\"foo\": [100, 2, 3], \"bar\": [4, 5, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n&gt;&gt;&gt; agnostic_is_empty(df_pd), agnostic_is_empty(df_pl), agnostic_is_empty(df_pa)\n(False, False, False)\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.is_unique","title":"<code>is_unique()</code>","text":"<p>Get a mask of all unique rows in this DataFrame.</p> <p>Returns:</p> Type Description <code>Series[Any]</code> <p>A new Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 2, 3, 1],\n...     \"b\": [\"x\", \"y\", \"z\", \"x\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_unique(df_native: IntoDataFrame) -&gt; IntoSeries:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.is_unique().to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_is_unique</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_unique(df_pd)\n0    False\n1     True\n2     True\n3    False\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_unique(df_pl)\nshape: (4,)\nSeries: '' [bool]\n[\n    false\n     true\n     true\n    false\n]\n&gt;&gt;&gt; agnostic_is_unique(df_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    false,\n    true,\n    true,\n    false\n  ]\n]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.item","title":"<code>item(row=None, column=None)</code>","text":"<p>Return the DataFrame as a scalar, or return the element at the given row/column.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int | None</code> <p>The n-th row.</p> <code>None</code> <code>column</code> <code>int | str | None</code> <p>The column selected via an integer or a string (column name).</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>A scalar or the specified element in the dataframe.</p> Notes <p>If row/col not provided, this is equivalent to df[0,0], with a check that the shape is (1,1). With row/col, this is equivalent to df[row,col].</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function that returns item at given row/column</p> <pre><code>&gt;&gt;&gt; def agnostic_item(\n...     df_native: IntoDataFrame, row: int | None, column: int | str | None\n... ):\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.item(row, column)\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_item</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_item(df_pd, 1, 1), agnostic_item(df_pd, 2, \"b\")\n(np.int64(5), np.int64(6))\n&gt;&gt;&gt; agnostic_item(df_pl, 1, 1), agnostic_item(df_pl, 2, \"b\")\n(5, 6)\n&gt;&gt;&gt; agnostic_item(df_pa, 1, 1), agnostic_item(df_pa, 2, \"b\")\n(5, 6)\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.iter_rows","title":"<code>iter_rows(*, named=False, buffer_size=512)</code>","text":"<p>Returns an iterator over the DataFrame of rows of python-native values.</p> <p>Parameters:</p> Name Type Description Default <code>named</code> <code>bool</code> <p>By default, each row is returned as a tuple of values given in the same order as the frame columns. Setting named=True will return rows of dictionaries instead.</p> <code>False</code> <code>buffer_size</code> <code>int</code> <p>Determines the number of rows that are buffered internally while iterating over the data. See https://docs.pola.rs/api/python/stable/reference/dataframe/api/polars.DataFrame.iter_rows.html</p> <code>512</code> <p>Returns:</p> Type Description <code>Iterator[tuple[Any, ...]] | Iterator[dict[str, Any]]</code> <p>An iterator over the DataFrame of rows.</p> Notes <p>cuDF doesn't support this method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_iter_rows(df_native: IntoDataFrame, *, named: bool):\n...     return nw.from_native(df_native, eager_only=True).iter_rows(named=named)\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_iter_rows</code>:</p> <pre><code>&gt;&gt;&gt; [row for row in agnostic_iter_rows(df_pd, named=False)]\n[(1, 6.0, 'a'), (2, 7.0, 'b'), (3, 8.0, 'c')]\n&gt;&gt;&gt; [row for row in agnostic_iter_rows(df_pd, named=True)]\n[{'foo': 1, 'bar': 6.0, 'ham': 'a'}, {'foo': 2, 'bar': 7.0, 'ham': 'b'}, {'foo': 3, 'bar': 8.0, 'ham': 'c'}]\n&gt;&gt;&gt; [row for row in agnostic_iter_rows(df_pl, named=False)]\n[(1, 6.0, 'a'), (2, 7.0, 'b'), (3, 8.0, 'c')]\n&gt;&gt;&gt; [row for row in agnostic_iter_rows(df_pl, named=True)]\n[{'foo': 1, 'bar': 6.0, 'ham': 'a'}, {'foo': 2, 'bar': 7.0, 'ham': 'b'}, {'foo': 3, 'bar': 8.0, 'ham': 'c'}]\n&gt;&gt;&gt; [row for row in agnostic_iter_rows(df_pa, named=False)]\n[(1, 6.0, 'a'), (2, 7.0, 'b'), (3, 8.0, 'c')]\n&gt;&gt;&gt; [row for row in agnostic_iter_rows(df_pa, named=True)]\n[{'foo': 1, 'bar': 6.0, 'ham': 'a'}, {'foo': 2, 'bar': 7.0, 'ham': 'b'}, {'foo': 3, 'bar': 8.0, 'ham': 'c'}]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.join","title":"<code>join(other, on=None, how='inner', *, left_on=None, right_on=None, suffix='_right')</code>","text":"<p>Join in SQL-like fashion.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Self</code> <p>DataFrame to join with.</p> required <code>on</code> <code>str | list[str] | None</code> <p>Name(s) of the join columns in both DataFrames. If set, <code>left_on</code> and <code>right_on</code> should be None.</p> <code>None</code> <code>how</code> <code>Literal['inner', 'left', 'cross', 'semi', 'anti']</code> <p>Join strategy.</p> <ul> <li>inner: Returns rows that have matching values in both tables.</li> <li>left: Returns all rows from the left table, and the matched rows from the right table.</li> <li>cross: Returns the Cartesian product of rows from both tables.</li> <li>semi: Filter rows that have a match in the right table.</li> <li>anti: Filter rows that do not have a match in the right table.</li> </ul> <code>'inner'</code> <code>left_on</code> <code>str | list[str] | None</code> <p>Join column of the left DataFrame.</p> <code>None</code> <code>right_on</code> <code>str | list[str] | None</code> <p>Join column of the right DataFrame.</p> <code>None</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <code>'_right'</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new joined DataFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6.0, 7.0, 8.0],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; data_other = {\n...     \"apple\": [\"x\", \"y\", \"z\"],\n...     \"ham\": [\"a\", \"b\", \"d\"],\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; other_pd = pd.DataFrame(data_other)\n</code></pre> <pre><code>&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; other_pl = pl.DataFrame(data_other)\n</code></pre> <pre><code>&gt;&gt;&gt; df_pa = pa.table(data)\n&gt;&gt;&gt; other_pa = pa.table(data_other)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we join over \"ham\" column:</p> <pre><code>&gt;&gt;&gt; def agnostic_join_on_ham(\n...     df_native: IntoFrameT, other_native: IntoFrameT\n... ) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     other = nw.from_native(other_native)\n...     return df.join(other, left_on=\"ham\", right_on=\"ham\").to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_join_on_ham</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_join_on_ham(df_pd, other_pd)\n   foo  bar ham apple\n0    1  6.0   a     x\n1    2  7.0   b     y\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_join_on_ham(df_pl, other_pl)\nshape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2506 apple \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2506 ---   \u2502\n\u2502 i64 \u2506 f64 \u2506 str \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6.0 \u2506 a   \u2506 x     \u2502\n\u2502 2   \u2506 7.0 \u2506 b   \u2506 y     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_join_on_ham(df_pa, other_pa)\npyarrow.Table\nfoo: int64\nbar: double\nham: string\napple: string\n----\nfoo: [[1,2]]\nbar: [[6,7]]\nham: [[\"a\",\"b\"]]\napple: [[\"x\",\"y\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.join_asof","title":"<code>join_asof(other, *, left_on=None, right_on=None, on=None, by_left=None, by_right=None, by=None, strategy='backward', suffix='_right')</code>","text":"<p>Perform an asof join.</p> <p>This is similar to a left-join except that we match on nearest key rather than equal keys.</p> <p>Both DataFrames must be sorted by the asof_join key.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Self</code> <p>DataFrame to join with.</p> required <code>left_on</code> <code>str | None</code> <p>Name(s) of the left join column(s).</p> <code>None</code> <code>right_on</code> <code>str | None</code> <p>Name(s) of the right join column(s).</p> <code>None</code> <code>on</code> <code>str | None</code> <p>Join column of both DataFrames. If set, left_on and right_on should be None.</p> <code>None</code> <code>by_left</code> <code>str | list[str] | None</code> <p>join on these columns before doing asof join.</p> <code>None</code> <code>by_right</code> <code>str | list[str] | None</code> <p>join on these columns before doing asof join.</p> <code>None</code> <code>by</code> <code>str | list[str] | None</code> <p>join on these columns before doing asof join.</p> <code>None</code> <code>strategy</code> <code>Literal['backward', 'forward', 'nearest']</code> <p>Join strategy. The default is \"backward\".</p> <code>'backward'</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <ul> <li>backward: selects the last row in the right DataFrame whose \"on\" key is less than or equal to the left's key.</li> <li>forward: selects the first row in the right DataFrame whose \"on\" key is greater than or equal to the left's key.</li> <li>nearest: search selects the last row in the right DataFrame whose value is nearest to the left's key.</li> </ul> <code>'_right'</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new joined DataFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; from typing import Literal\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data_gdp = {\n...     \"datetime\": [\n...         datetime(2016, 1, 1),\n...         datetime(2017, 1, 1),\n...         datetime(2018, 1, 1),\n...         datetime(2019, 1, 1),\n...         datetime(2020, 1, 1),\n...     ],\n...     \"gdp\": [4164, 4411, 4566, 4696, 4827],\n... }\n&gt;&gt;&gt; data_population = {\n...     \"datetime\": [\n...         datetime(2016, 3, 1),\n...         datetime(2018, 8, 1),\n...         datetime(2019, 1, 1),\n...     ],\n...     \"population\": [82.19, 82.66, 83.12],\n... }\n&gt;&gt;&gt; gdp_pd = pd.DataFrame(data_gdp)\n&gt;&gt;&gt; population_pd = pd.DataFrame(data_population)\n</code></pre> <pre><code>&gt;&gt;&gt; gdp_pl = pl.DataFrame(data_gdp).sort(\"datetime\")\n&gt;&gt;&gt; population_pl = pl.DataFrame(data_population).sort(\"datetime\")\n</code></pre> <p>Let's define a dataframe-agnostic function in which we join over \"datetime\" column:</p> <pre><code>&gt;&gt;&gt; def agnostic_join_asof_datetime(\n...     df_native: IntoFrameT,\n...     other_native: IntoFrameT,\n...     strategy: Literal[\"backward\", \"forward\", \"nearest\"],\n... ) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     other = nw.from_native(other_native)\n...     return df.join_asof(other, on=\"datetime\", strategy=strategy).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas or Polars to <code>agnostic_join_asof_datetime</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_join_asof_datetime(population_pd, gdp_pd, strategy=\"backward\")\n    datetime  population   gdp\n0 2016-03-01       82.19  4164\n1 2018-08-01       82.66  4566\n2 2019-01-01       83.12  4696\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_join_asof_datetime(population_pl, gdp_pl, strategy=\"backward\")\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime            \u2506 population \u2506 gdp  \u2502\n\u2502 ---                 \u2506 ---        \u2506 ---  \u2502\n\u2502 datetime[\u03bcs]        \u2506 f64        \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2016-03-01 00:00:00 \u2506 82.19      \u2506 4164 \u2502\n\u2502 2018-08-01 00:00:00 \u2506 82.66      \u2506 4566 \u2502\n\u2502 2019-01-01 00:00:00 \u2506 83.12      \u2506 4696 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Here is a real-world times-series example that uses <code>by</code> argument.</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; data_quotes = {\n...     \"datetime\": [\n...         datetime(2016, 5, 25, 13, 30, 0, 23),\n...         datetime(2016, 5, 25, 13, 30, 0, 23),\n...         datetime(2016, 5, 25, 13, 30, 0, 30),\n...         datetime(2016, 5, 25, 13, 30, 0, 41),\n...         datetime(2016, 5, 25, 13, 30, 0, 48),\n...         datetime(2016, 5, 25, 13, 30, 0, 49),\n...         datetime(2016, 5, 25, 13, 30, 0, 72),\n...         datetime(2016, 5, 25, 13, 30, 0, 75),\n...     ],\n...     \"ticker\": [\n...         \"GOOG\",\n...         \"MSFT\",\n...         \"MSFT\",\n...         \"MSFT\",\n...         \"GOOG\",\n...         \"AAPL\",\n...         \"GOOG\",\n...         \"MSFT\",\n...     ],\n...     \"bid\": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],\n...     \"ask\": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03],\n... }\n&gt;&gt;&gt; data_trades = {\n...     \"datetime\": [\n...         datetime(2016, 5, 25, 13, 30, 0, 23),\n...         datetime(2016, 5, 25, 13, 30, 0, 38),\n...         datetime(2016, 5, 25, 13, 30, 0, 48),\n...         datetime(2016, 5, 25, 13, 30, 0, 48),\n...         datetime(2016, 5, 25, 13, 30, 0, 48),\n...     ],\n...     \"ticker\": [\"MSFT\", \"MSFT\", \"GOOG\", \"GOOG\", \"AAPL\"],\n...     \"price\": [51.95, 51.95, 720.77, 720.92, 98.0],\n...     \"quantity\": [75, 155, 100, 100, 100],\n... }\n&gt;&gt;&gt; quotes_pd = pd.DataFrame(data_quotes)\n&gt;&gt;&gt; trades_pd = pd.DataFrame(data_trades)\n&gt;&gt;&gt; quotes_pl = pl.DataFrame(data_quotes).sort(\"datetime\")\n&gt;&gt;&gt; trades_pl = pl.DataFrame(data_trades).sort(\"datetime\")\n</code></pre> <p>Let's define a dataframe-agnostic function in which we join over \"datetime\" and by \"ticker\" columns:</p> <pre><code>&gt;&gt;&gt; def agnostic_join_asof_datetime_by_ticker(\n...     df_native: IntoFrameT, other_native: IntoFrameT\n... ) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     other = nw.from_native(other_native)\n...     return df.join_asof(other, on=\"datetime\", by=\"ticker\").to_native()\n</code></pre> <p>We can now pass either pandas or Polars to the function:</p> <pre><code>&gt;&gt;&gt; agnostic_join_asof_datetime_by_ticker(trades_pd, quotes_pd)\n                    datetime ticker   price  quantity     bid     ask\n0 2016-05-25 13:30:00.000023   MSFT   51.95        75   51.95   51.96\n1 2016-05-25 13:30:00.000038   MSFT   51.95       155   51.97   51.98\n2 2016-05-25 13:30:00.000048   GOOG  720.77       100  720.50  720.93\n3 2016-05-25 13:30:00.000048   GOOG  720.92       100  720.50  720.93\n4 2016-05-25 13:30:00.000048   AAPL   98.00       100     NaN     NaN\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_join_asof_datetime_by_ticker(trades_pl, quotes_pl)\nshape: (5, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime                   \u2506 ticker \u2506 price  \u2506 quantity \u2506 bid   \u2506 ask    \u2502\n\u2502 ---                        \u2506 ---    \u2506 ---    \u2506 ---      \u2506 ---   \u2506 ---    \u2502\n\u2502 datetime[\u03bcs]               \u2506 str    \u2506 f64    \u2506 i64      \u2506 f64   \u2506 f64    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2016-05-25 13:30:00.000023 \u2506 MSFT   \u2506 51.95  \u2506 75       \u2506 51.95 \u2506 51.96  \u2502\n\u2502 2016-05-25 13:30:00.000038 \u2506 MSFT   \u2506 51.95  \u2506 155      \u2506 51.97 \u2506 51.98  \u2502\n\u2502 2016-05-25 13:30:00.000048 \u2506 GOOG   \u2506 720.77 \u2506 100      \u2506 720.5 \u2506 720.93 \u2502\n\u2502 2016-05-25 13:30:00.000048 \u2506 GOOG   \u2506 720.92 \u2506 100      \u2506 720.5 \u2506 720.93 \u2502\n\u2502 2016-05-25 13:30:00.000048 \u2506 AAPL   \u2506 98.0   \u2506 100      \u2506 null  \u2506 null   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.lazy","title":"<code>lazy()</code>","text":"<p>Lazify the DataFrame (if possible).</p> <p>If a library does not support lazy execution, then this is a no-op.</p> <p>Returns:</p> Type Description <code>LazyFrame[Any]</code> <p>A new LazyFrame.</p> <p>Examples:</p> <p>Construct pandas, Polars and PyArrow DataFrames:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_lazy(df_native: IntoFrame) -&gt; IntoFrame:\n...     df = nw.from_native(df_native)\n...     return df.lazy().to_native()\n</code></pre> <p>Note that then, pandas and pyarrow dataframe stay eager, but Polars DataFrame becomes a Polars LazyFrame:</p> <pre><code>&gt;&gt;&gt; agnostic_lazy(df_pd)\n   foo  bar ham\n0    1  6.0   a\n1    2  7.0   b\n2    3  8.0   c\n&gt;&gt;&gt; agnostic_lazy(df_pl)\n&lt;LazyFrame ...&gt;\n&gt;&gt;&gt; agnostic_lazy(df_pa)\npyarrow.Table\nfoo: int64\nbar: double\nham: string\n----\nfoo: [[1,2,3]]\nbar: [[6,7,8]]\nham: [[\"a\",\"b\",\"c\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.null_count","title":"<code>null_count()</code>","text":"<p>Create a new DataFrame that shows the null counts per column.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A dataframe of shape (1, n_columns).</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, None, 3],\n...     \"bar\": [6, 7, None],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function that returns the null count of each columns:</p> <pre><code>&gt;&gt;&gt; def agnostic_null_count(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.null_count().to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_null_count</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_null_count(df_pd)\n   foo  bar  ham\n0    1    1    0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_null_count(df_pl)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 u32 \u2506 u32 \u2506 u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 1   \u2506 0   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_null_count(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\nham: int64\n----\nfoo: [[1]]\nbar: [[1]]\nham: [[0]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.pipe","title":"<code>pipe(function, *args, **kwargs)</code>","text":"<p>Pipe function call.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>Callable[Concatenate[Self, PS], R]</code> <p>Function to apply.</p> required <code>args</code> <code>args</code> <p>Positional arguments to pass to function.</p> <code>()</code> <code>kwargs</code> <code>kwargs</code> <p>Keyword arguments to pass to function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>R</code> <p>The original object with the function applied.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"ba\": [4, 5, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_pipe(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.pipe(\n...         lambda _df: _df.select(\n...             [x for x in _df.columns if len(x) == 1]\n...         ).to_native()\n...     )\n</code></pre> <p>We can then pass either pandas, Polars or PyArrow to <code>agnostic_pipe</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_pipe(df_pd)\n   a\n0  1\n1  2\n2  3\n&gt;&gt;&gt; agnostic_pipe(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2502 2   \u2502\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_pipe(df_pa)\npyarrow.Table\na: int64\n----\na: [[1,2,3]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.pivot","title":"<code>pivot(on, *, index=None, values=None, aggregate_function=None, maintain_order=None, sort_columns=False, separator='_')</code>","text":"<p>Create a spreadsheet-style pivot table as a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>on</code> <code>str | list[str]</code> <p>Name of the column(s) whose values will be used as the header of the output DataFrame.</p> required <code>index</code> <code>str | list[str] | None</code> <p>One or multiple keys to group by. If None, all remaining columns not specified on <code>on</code> and <code>values</code> will be used. At least one of <code>index</code> and <code>values</code> must be specified.</p> <code>None</code> <code>values</code> <code>str | list[str] | None</code> <p>One or multiple keys to group by. If None, all remaining columns not specified on <code>on</code> and <code>index</code> will be used. At least one of <code>index</code> and <code>values</code> must be specified.</p> <code>None</code> <code>aggregate_function</code> <code>Literal['min', 'max', 'first', 'last', 'sum', 'mean', 'median', 'len'] | None</code> <p>Choose from:</p> <ul> <li>None: no aggregation takes place, will raise error if multiple values     are in group.</li> <li>A predefined aggregate function string, one of     {'min', 'max', 'first', 'last', 'sum', 'mean', 'median', 'len'}</li> </ul> <code>None</code> <code>maintain_order</code> <code>bool | None</code> <p>Has no effect and is kept around only for backwards-compatibility.</p> <code>None</code> <code>sort_columns</code> <code>bool</code> <p>Sort the transposed columns by name. Default is by order of discovery.</p> <code>False</code> <code>separator</code> <code>str</code> <p>Used as separator/delimiter in generated column names in case of multiple <code>values</code> columns.</p> <code>'_'</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new dataframe.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrameT\n&gt;&gt;&gt; data = {\n...     \"ix\": [1, 1, 2, 2, 1, 2],\n...     \"col\": [\"a\", \"a\", \"a\", \"a\", \"b\", \"b\"],\n...     \"foo\": [0, 1, 2, 2, 7, 1],\n...     \"bar\": [0, 2, 0, 0, 9, 4],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_pivot(df_native: IntoDataFrameT) -&gt; IntoDataFrameT:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.pivot(\"col\", index=\"ix\", aggregate_function=\"sum\").to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas or Polars to <code>agnostic_pivot</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_pivot(df_pd)\n   ix  foo_a  foo_b  bar_a  bar_b\n0   1      1      7      2      9\n1   2      4      1      0      4\n&gt;&gt;&gt; agnostic_pivot(df_pl)\nshape: (2, 5)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 ix  \u2506 foo_a \u2506 foo_b \u2506 bar_a \u2506 bar_b \u2502\n\u2502 --- \u2506 ---   \u2506 ---   \u2506 ---   \u2506 ---   \u2502\n\u2502 i64 \u2506 i64   \u2506 i64   \u2506 i64   \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 1     \u2506 7     \u2506 2     \u2506 9     \u2502\n\u2502 2   \u2506 4     \u2506 1     \u2506 0     \u2506 4     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.rename","title":"<code>rename(mapping)</code>","text":"<p>Rename column names.</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <code>dict[str, str]</code> <p>Key value pairs that map from old name to new name.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The dataframe with the specified columns renamed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6, 7, 8], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rename(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return nw.from_native(df_native).rename({\"foo\": \"apple\"}).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_rename</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rename(df_pd)\n   apple  bar ham\n0      1    6   a\n1      2    7   b\n2      3    8   c\n&gt;&gt;&gt; agnostic_rename(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 apple \u2506 bar \u2506 ham \u2502\n\u2502 ---   \u2506 --- \u2506 --- \u2502\n\u2502 i64   \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1     \u2506 6   \u2506 a   \u2502\n\u2502 2     \u2506 7   \u2506 b   \u2502\n\u2502 3     \u2506 8   \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_rename(df_pa)\npyarrow.Table\napple: int64\nbar: int64\nham: string\n----\napple: [[1,2,3]]\nbar: [[6,7,8]]\nham: [[\"a\",\"b\",\"c\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.row","title":"<code>row(index)</code>","text":"<p>Get values at given row.</p> <p>Warning</p> <p>You should NEVER use this method to iterate over a DataFrame; if you require row-iteration you should strongly prefer use of iter_rows() instead.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>Row number.</p> required <p>Returns:</p> Type Description <code>tuple[Any, ...]</code> <p>A tuple of the values in the selected row.</p> Notes <p>cuDF doesn't support this method.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from typing import Any\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a library-agnostic function to get the second row.</p> <pre><code>&gt;&gt;&gt; def agnostic_row(df_native: IntoDataFrame) -&gt; tuple[Any, ...]:\n...     return nw.from_native(df_native).row(1)\n</code></pre> <p>We can then pass either pandas, Polars or PyArrow to <code>agnostic_row</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_row(df_pd)\n(2, 5)\n&gt;&gt;&gt; agnostic_row(df_pl)\n(2, 5)\n&gt;&gt;&gt; agnostic_row(df_pa)\n(&lt;pyarrow.Int64Scalar: 2&gt;, &lt;pyarrow.Int64Scalar: 5&gt;)\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.rows","title":"<code>rows(*, named=False)</code>","text":"<p>Returns all data in the DataFrame as a list of rows of python-native values.</p> <p>Parameters:</p> Name Type Description Default <code>named</code> <code>bool</code> <p>By default, each row is returned as a tuple of values given in the same order as the frame columns. Setting named=True will return rows of dictionaries instead.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[tuple[Any, ...]] | list[dict[str, Any]]</code> <p>The data as a list of rows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rows(df_native: IntoDataFrame, *, named: bool):\n...     return nw.from_native(df_native, eager_only=True).rows(named=named)\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_rows</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rows(df_pd, named=False)\n[(1, 6.0, 'a'), (2, 7.0, 'b'), (3, 8.0, 'c')]\n&gt;&gt;&gt; agnostic_rows(df_pd, named=True)\n[{'foo': 1, 'bar': 6.0, 'ham': 'a'}, {'foo': 2, 'bar': 7.0, 'ham': 'b'}, {'foo': 3, 'bar': 8.0, 'ham': 'c'}]\n&gt;&gt;&gt; agnostic_rows(df_pl, named=False)\n[(1, 6.0, 'a'), (2, 7.0, 'b'), (3, 8.0, 'c')]\n&gt;&gt;&gt; agnostic_rows(df_pl, named=True)\n[{'foo': 1, 'bar': 6.0, 'ham': 'a'}, {'foo': 2, 'bar': 7.0, 'ham': 'b'}, {'foo': 3, 'bar': 8.0, 'ham': 'c'}]\n&gt;&gt;&gt; agnostic_rows(df_pa, named=False)\n[(1, 6.0, 'a'), (2, 7.0, 'b'), (3, 8.0, 'c')]\n&gt;&gt;&gt; agnostic_rows(df_pa, named=True)\n[{'foo': 1, 'bar': 6.0, 'ham': 'a'}, {'foo': 2, 'bar': 7.0, 'ham': 'b'}, {'foo': 3, 'bar': 8.0, 'ham': 'c'}]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.sample","title":"<code>sample(n=None, *, fraction=None, with_replacement=False, seed=None)</code>","text":"<p>Sample from this DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | None</code> <p>Number of items to return. Cannot be used with fraction.</p> <code>None</code> <code>fraction</code> <code>float | None</code> <p>Fraction of items to return. Cannot be used with n.</p> <code>None</code> <code>with_replacement</code> <code>bool</code> <p>Allow values to be sampled more than once.</p> <code>False</code> <code>seed</code> <code>int | None</code> <p>Seed for the random number generator. If set to None (default), a random seed is generated for each sample operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new dataframe.</p> Notes <p>The results may not be consistent across libraries.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrameT\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 4], \"b\": [\"x\", \"y\", \"x\", \"y\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_sample(df_native: IntoDataFrameT) -&gt; IntoDataFrameT:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.sample(n=2, seed=123).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_sample</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_sample(df_pd)\n   a  b\n3  4  y\n0  1  x\n&gt;&gt;&gt; agnostic_sample(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 y   \u2502\n\u2502 3   \u2506 x   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_sample(df_pa)\npyarrow.Table\na: int64\nb: string\n----\na: [[1,3]]\nb: [[\"x\",\"x\"]]\n</code></pre> <p>As you can see, by using the same seed, the result will be consistent within the same backend, but not necessarely across different backends.</p>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.select","title":"<code>select(*exprs, **named_exprs)</code>","text":"<p>Select columns from this DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>*exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Column(s) to select, specified as positional arguments.      Accepts expression input. Strings are parsed as column names,      other non-expression inputs are parsed as literals.</p> <code>()</code> <code>**named_exprs</code> <code>IntoExpr</code> <p>Additional columns to select, specified as keyword arguments.             The columns will be renamed to the keyword used.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The dataframe containing only the selected columns.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6, 7, 8],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we pass the name of a column to select that column.</p> <pre><code>&gt;&gt;&gt; def agnostic_single_select(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return nw.from_native(df_native).select(\"foo\").to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_single_select</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_single_select(df_pd)\n   foo\n0    1\n1    2\n2    3\n&gt;&gt;&gt; agnostic_single_select(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2502 2   \u2502\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_single_select(df_pa)\npyarrow.Table\nfoo: int64\n----\nfoo: [[1,2,3]]\n</code></pre> <p>Multiple columns can be selected by passing a list of column names.</p> <pre><code>&gt;&gt;&gt; def agnostic_multi_select(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return nw.from_native(df_native).select([\"foo\", \"bar\"]).to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_multi_select(df_pd)\n   foo  bar\n0    1    6\n1    2    7\n2    3    8\n&gt;&gt;&gt; agnostic_multi_select(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6   \u2502\n\u2502 2   \u2506 7   \u2502\n\u2502 3   \u2506 8   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_multi_select(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\n----\nfoo: [[1,2,3]]\nbar: [[6,7,8]]\n</code></pre> <p>Multiple columns can also be selected using positional arguments instead of a list. Expressions are also accepted.</p> <pre><code>&gt;&gt;&gt; def agnostic_select(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return (\n...         nw.from_native(df_native)\n...         .select(nw.col(\"foo\"), nw.col(\"bar\") + 1)\n...         .to_native()\n...     )\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_select(df_pd)\n   foo  bar\n0    1    7\n1    2    8\n2    3    9\n&gt;&gt;&gt; agnostic_select(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 7   \u2502\n\u2502 2   \u2506 8   \u2502\n\u2502 3   \u2506 9   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_select(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\n----\nfoo: [[1,2,3]]\nbar: [[7,8,9]]\n</code></pre> <p>Use keyword arguments to easily name your expression inputs.</p> <pre><code>&gt;&gt;&gt; def agnostic_select_w_kwargs(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return (\n...         nw.from_native(df_native)\n...         .select(threshold=nw.col(\"foo\") * 2)\n...         .to_native()\n...     )\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_select_w_kwargs(df_pd)\n   threshold\n0          2\n1          4\n2          6\n&gt;&gt;&gt; agnostic_select_w_kwargs(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 threshold \u2502\n\u2502 ---       \u2502\n\u2502 i64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2         \u2502\n\u2502 4         \u2502\n\u2502 6         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_select_w_kwargs(df_pa)\npyarrow.Table\nthreshold: int64\n----\nthreshold: [[2,4,6]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.sort","title":"<code>sort(by, *more_by, descending=False, nulls_last=False)</code>","text":"<p>Sort the dataframe by the given columns.</p> <p>Parameters:</p> Name Type Description Default <code>by</code> <code>str | Iterable[str]</code> <p>Column(s) names to sort by.</p> required <code>*more_by</code> <code>str</code> <p>Additional columns to sort by, specified as positional arguments.</p> <code>()</code> <code>descending</code> <code>bool | Sequence[bool]</code> <p>Sort in descending order. When sorting by multiple columns, can be specified per column by passing a sequence of booleans.</p> <code>False</code> <code>nulls_last</code> <code>bool</code> <p>Place null values last.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The sorted dataframe.</p> Warning <p>Unlike Polars, it is not possible to specify a sequence of booleans for <code>nulls_last</code> in order to control per-column behaviour. Instead a single boolean is applied for all <code>by</code> columns.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 2, None],\n...     \"b\": [6.0, 5.0, 4.0],\n...     \"c\": [\"a\", \"c\", \"b\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we sort by multiple columns in different orders</p> <pre><code>&gt;&gt;&gt; def agnostic_sort(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.sort(\"c\", \"a\", descending=[False, True]).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_sort</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_sort(df_pd)\n     a    b  c\n0  1.0  6.0  a\n2  NaN  4.0  b\n1  2.0  5.0  c\n&gt;&gt;&gt; agnostic_sort(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b   \u2506 c   \u2502\n\u2502 ---  \u2506 --- \u2506 --- \u2502\n\u2502 i64  \u2506 f64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 6.0 \u2506 a   \u2502\n\u2502 null \u2506 4.0 \u2506 b   \u2502\n\u2502 2    \u2506 5.0 \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_sort(df_pa)\npyarrow.Table\na: int64\nb: double\nc: string\n----\na: [[1,null,2]]\nb: [[6,4,5]]\nc: [[\"a\",\"b\",\"c\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.tail","title":"<code>tail(n=5)</code>","text":"<p>Get the last <code>n</code> rows.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to return. If a negative value is passed, return all rows except the first <code>abs(n)</code>.</p> <code>5</code> <p>Returns:</p> Type Description <code>Self</code> <p>A subset of the dataframe of shape (n, n_columns).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3, 4, 5],\n...     \"bar\": [6, 7, 8, 9, 10],\n...     \"ham\": [\"a\", \"b\", \"c\", \"d\", \"e\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function that gets the last 3 rows.</p> <pre><code>&gt;&gt;&gt; def agnostic_tail(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return nw.from_native(df_native).tail(3).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_tail</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_tail(df_pd)\n   foo  bar ham\n2    3    8   c\n3    4    9   d\n4    5   10   e\n&gt;&gt;&gt; agnostic_tail(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 3   \u2506 8   \u2506 c   \u2502\n\u2502 4   \u2506 9   \u2506 d   \u2502\n\u2502 5   \u2506 10  \u2506 e   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_tail(df_pa)\npyarrow.Table\nfoo: int64\nbar: int64\nham: string\n----\nfoo: [[3,4,5]]\nbar: [[8,9,10]]\nham: [[\"c\",\"d\",\"e\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.to_arrow","title":"<code>to_arrow()</code>","text":"<p>Convert to arrow table.</p> <p>Returns:</p> Type Description <code>Table</code> <p>A new PyArrow table.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function that converts to arrow table:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_arrow(df_native: IntoDataFrame) -&gt; pa.Table:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.to_arrow()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_to_arrow</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_arrow(df_pd)\npyarrow.Table\nfoo: int64\nbar: string\n----\nfoo: [[1,2,3]]\nbar: [[\"a\",\"b\",\"c\"]]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_arrow(df_pl)\npyarrow.Table\nfoo: int64\nbar: large_string\n----\nfoo: [[1,2,3]]\nbar: [[\"a\",\"b\",\"c\"]]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_arrow(df_pa)\npyarrow.Table\nfoo: int64\nbar: string\n----\nfoo: [[1,2,3]]\nbar: [[\"a\",\"b\",\"c\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.to_dict","title":"<code>to_dict(*, as_series=True)</code>","text":"<p>Convert DataFrame to a dictionary mapping column name to values.</p> <p>Parameters:</p> Name Type Description Default <code>as_series</code> <code>bool</code> <p>If set to true <code>True</code>, then the values are Narwhals Series,     otherwise the values are Any.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, Series[Any]] | dict[str, list[Any]]</code> <p>A mapping from column name to values / Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\n...     \"A\": [1, 2, 3, 4, 5],\n...     \"fruits\": [\"banana\", \"banana\", \"apple\", \"apple\", \"banana\"],\n...     \"B\": [5, 4, 3, 2, 1],\n...     \"animals\": [\"beetle\", \"fly\", \"beetle\", \"beetle\", \"beetle\"],\n...     \"optional\": [28, 300, None, 2, -30],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_dict(\n...     df_native: IntoDataFrame,\n... ) -&gt; dict[str, list[int | str | float | None]]:\n...     df = nw.from_native(df_native)\n...     return df.to_dict(as_series=False)\n</code></pre> <p>We can then pass either pandas, Polars or PyArrow to <code>agnostic_to_dict</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_dict(df_pd)\n{'A': [1, 2, 3, 4, 5], 'fruits': ['banana', 'banana', 'apple', 'apple', 'banana'], 'B': [5, 4, 3, 2, 1], 'animals': ['beetle', 'fly', 'beetle', 'beetle', 'beetle'], 'optional': [28.0, 300.0, nan, 2.0, -30.0]}\n&gt;&gt;&gt; agnostic_to_dict(df_pl)\n{'A': [1, 2, 3, 4, 5], 'fruits': ['banana', 'banana', 'apple', 'apple', 'banana'], 'B': [5, 4, 3, 2, 1], 'animals': ['beetle', 'fly', 'beetle', 'beetle', 'beetle'], 'optional': [28, 300, None, 2, -30]}\n&gt;&gt;&gt; agnostic_to_dict(df_pa)\n{'A': [1, 2, 3, 4, 5], 'fruits': ['banana', 'banana', 'apple', 'apple', 'banana'], 'B': [5, 4, 3, 2, 1], 'animals': ['beetle', 'fly', 'beetle', 'beetle', 'beetle'], 'optional': [28, 300, None, 2, -30]}\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.to_native","title":"<code>to_native()</code>","text":"<p>Convert Narwhals DataFrame to native one.</p> <p>Returns:</p> Type Description <code>DataFrameT</code> <p>Object of class that user started with.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Calling <code>to_native</code> on a Narwhals DataFrame returns the native object:</p> <pre><code>&gt;&gt;&gt; nw.from_native(df_pd).to_native()\n   foo  bar ham\n0    1  6.0   a\n1    2  7.0   b\n2    3  8.0   c\n&gt;&gt;&gt; nw.from_native(df_pl).to_native()\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6.0 \u2506 a   \u2502\n\u2502 2   \u2506 7.0 \u2506 b   \u2502\n\u2502 3   \u2506 8.0 \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; nw.from_native(df_pa).to_native()\npyarrow.Table\nfoo: int64\nbar: double\nham: string\n----\nfoo: [[1,2,3]]\nbar: [[6,7,8]]\nham: [[\"a\",\"b\",\"c\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.to_numpy","title":"<code>to_numpy()</code>","text":"<p>Convert this DataFrame to a NumPy ndarray.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>A NumPy ndarray array.</p> <p>Examples:</p> <p>Construct pandas and polars DataFrames:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.5, 7.0, 8.5], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_numpy(df_native: IntoDataFrame) -&gt; np.ndarray:\n...     df = nw.from_native(df_native)\n...     return df.to_numpy()\n</code></pre> <p>We can then pass either pandas, Polars or PyArrow to <code>agnostic_to_numpy</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_numpy(df_pd)\narray([[1, 6.5, 'a'],\n       [2, 7.0, 'b'],\n       [3, 8.5, 'c']], dtype=object)\n&gt;&gt;&gt; agnostic_to_numpy(df_pl)\narray([[1, 6.5, 'a'],\n       [2, 7.0, 'b'],\n       [3, 8.5, 'c']], dtype=object)\n&gt;&gt;&gt; agnostic_to_numpy(df_pa)\narray([[1, 6.5, 'a'],\n       [2, 7.0, 'b'],\n       [3, 8.5, 'c']], dtype=object)\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert this DataFrame to a pandas DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame.</p> <p>Examples:</p> <p>Construct pandas, Polars (eager) and PyArrow DataFrames:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_pandas(df_native: IntoDataFrame) -&gt; pd.DataFrame:\n...     df = nw.from_native(df_native)\n...     return df.to_pandas()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars (eager), or PyArrow to <code>agnostic_to_pandas</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_pandas(df_pd)\n   foo  bar ham\n0    1  6.0   a\n1    2  7.0   b\n2    3  8.0   c\n&gt;&gt;&gt; agnostic_to_pandas(df_pl)\n   foo  bar ham\n0    1  6.0   a\n1    2  7.0   b\n2    3  8.0   c\n&gt;&gt;&gt; agnostic_to_pandas(df_pa)\n   foo  bar ham\n0    1  6.0   a\n1    2  7.0   b\n2    3  8.0   c\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert this DataFrame to a polars DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A polars DataFrame.</p> <p>Examples:</p> <p>Construct pandas, Polars (eager) and PyArrow DataFrames:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_polars(df_native: IntoDataFrame) -&gt; pl.DataFrame:\n...     df = nw.from_native(df_native)\n...     return df.to_polars()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars (eager), or PyArrow to <code>agnostic_to_polars</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_polars(df_pd)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6.0 \u2506 a   \u2502\n\u2502 2   \u2506 7.0 \u2506 b   \u2502\n\u2502 3   \u2506 8.0 \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_polars(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6.0 \u2506 a   \u2502\n\u2502 2   \u2506 7.0 \u2506 b   \u2502\n\u2502 3   \u2506 8.0 \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_polars(df_pa)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6.0 \u2506 a   \u2502\n\u2502 2   \u2506 7.0 \u2506 b   \u2502\n\u2502 3   \u2506 8.0 \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.unique","title":"<code>unique(subset=None, *, keep='any', maintain_order=False)</code>","text":"<p>Drop duplicate rows from this dataframe.</p> <p>Parameters:</p> Name Type Description Default <code>subset</code> <code>str | list[str] | None</code> <p>Column name(s) to consider when identifying duplicate rows.</p> <code>None</code> <code>keep</code> <code>Literal['any', 'first', 'last', 'none']</code> <p>{'first', 'last', 'any', 'none'} Which of the duplicate rows to keep.</p> <ul> <li>'any': Does not give any guarantee of which row is kept.         This allows more optimizations.</li> <li>'none': Don't keep duplicate rows.</li> <li>'first': Keep first unique row.</li> <li>'last': Keep last unique row.</li> </ul> <code>'any'</code> <code>maintain_order</code> <code>bool</code> <p>Keep the same order as the original DataFrame. This may be more expensive to compute.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The dataframe with the duplicate rows removed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3, 1],\n...     \"bar\": [\"a\", \"a\", \"a\", \"a\"],\n...     \"ham\": [\"b\", \"b\", \"b\", \"b\"],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_unique(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return nw.from_native(df_native).unique([\"bar\", \"ham\"]).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_unique</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_unique(df_pd)\n   foo bar ham\n0    1   a   b\n&gt;&gt;&gt; agnostic_unique(df_pl)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 str \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 a   \u2506 b   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_unique(df_pa)\npyarrow.Table\nfoo: int64\nbar: string\nham: string\n----\nfoo: [[1]]\nbar: [[\"a\"]]\nham: [[\"b\"]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.unpivot","title":"<code>unpivot(on=None, *, index=None, variable_name=None, value_name=None)</code>","text":"<p>Unpivot a DataFrame from wide to long format.</p> <p>Optionally leaves identifiers set.</p> <p>This function is useful to massage a DataFrame into a format where one or more columns are identifier variables (index) while all other columns, considered measured variables (on), are \"unpivoted\" to the row axis leaving just two non-identifier columns, 'variable' and 'value'.</p> <p>Parameters:</p> Name Type Description Default <code>on</code> <code>str | list[str] | None</code> <p>Column(s) to use as values variables; if <code>on</code> is empty all columns that are not in <code>index</code> will be used.</p> <code>None</code> <code>index</code> <code>str | list[str] | None</code> <p>Column(s) to use as identifier variables.</p> <code>None</code> <code>variable_name</code> <code>str | None</code> <p>Name to give to the <code>variable</code> column. Defaults to \"variable\".</p> <code>None</code> <code>value_name</code> <code>str | None</code> <p>Name to give to the <code>value</code> column. Defaults to \"value\".</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The unpivoted dataframe.</p> Notes <p>If you're coming from pandas, this is similar to <code>pandas.DataFrame.melt</code>, but with <code>index</code> replacing <code>id_vars</code> and <code>on</code> replacing <code>value_vars</code>. In other frameworks, you might know this operation as <code>pivot_longer</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"a\": [\"x\", \"y\", \"z\"],\n...     \"b\": [1, 3, 5],\n...     \"c\": [2, 4, 6],\n... }\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_unpivot(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.unpivot(on=[\"b\", \"c\"], index=\"a\").to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_unpivot</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_unpivot(pl.DataFrame(data))\nshape: (6, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 variable \u2506 value \u2502\n\u2502 --- \u2506 ---      \u2506 ---   \u2502\n\u2502 str \u2506 str      \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 x   \u2506 b        \u2506 1     \u2502\n\u2502 y   \u2506 b        \u2506 3     \u2502\n\u2502 z   \u2506 b        \u2506 5     \u2502\n\u2502 x   \u2506 c        \u2506 2     \u2502\n\u2502 y   \u2506 c        \u2506 4     \u2502\n\u2502 z   \u2506 c        \u2506 6     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_unpivot(pd.DataFrame(data))\n   a variable  value\n0  x        b      1\n1  y        b      3\n2  z        b      5\n3  x        c      2\n4  y        c      4\n5  z        c      6\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_unpivot(pa.table(data))\npyarrow.Table\na: string\nvariable: string\nvalue: int64\n----\na: [[\"x\",\"y\",\"z\"],[\"x\",\"y\",\"z\"]]\nvariable: [[\"b\",\"b\",\"b\"],[\"c\",\"c\",\"c\"]]\nvalue: [[1,3,5],[2,4,6]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.with_columns","title":"<code>with_columns(*exprs, **named_exprs)</code>","text":"<p>Add columns to this DataFrame.</p> <p>Added columns will replace existing columns with the same name.</p> <p>Parameters:</p> Name Type Description Default <code>*exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Column(s) to add, specified as positional arguments.      Accepts expression input. Strings are parsed as column names, other      non-expression inputs are parsed as literals.</p> <code>()</code> <code>**named_exprs</code> <code>IntoExpr</code> <p>Additional columns to add, specified as keyword arguments.             The columns will be renamed to the keyword used.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <code>Self</code> <p>A new DataFrame with the columns added.</p> Note <p>Creating a new DataFrame using this method does not create a new copy of existing data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 2, 3, 4],\n...     \"b\": [0.5, 4, 10, 13],\n...     \"c\": [True, True, False, True],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we pass an expression to add it as a new column:</p> <pre><code>&gt;&gt;&gt; def agnostic_with_columns(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return (\n...         nw.from_native(df_native)\n...         .with_columns((nw.col(\"a\") * 2).alias(\"a*2\"))\n...         .to_native()\n...     )\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_with_columns</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_with_columns(df_pd)\n   a     b      c  a*2\n0  1   0.5   True    2\n1  2   4.0   True    4\n2  3  10.0  False    6\n3  4  13.0   True    8\n&gt;&gt;&gt; agnostic_with_columns(df_pl)\nshape: (4, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b    \u2506 c     \u2506 a*2 \u2502\n\u2502 --- \u2506 ---  \u2506 ---   \u2506 --- \u2502\n\u2502 i64 \u2506 f64  \u2506 bool  \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 0.5  \u2506 true  \u2506 2   \u2502\n\u2502 2   \u2506 4.0  \u2506 true  \u2506 4   \u2502\n\u2502 3   \u2506 10.0 \u2506 false \u2506 6   \u2502\n\u2502 4   \u2506 13.0 \u2506 true  \u2506 8   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_with_columns(df_pa)\npyarrow.Table\na: int64\nb: double\nc: bool\na*2: int64\n----\na: [[1,2,3,4]]\nb: [[0.5,4,10,13]]\nc: [[true,true,false,true]]\na*2: [[2,4,6,8]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.with_row_index","title":"<code>with_row_index(name='index')</code>","text":"<p>Insert column which enumerates rows.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the column as a string. The default is \"index\".</p> <code>'index'</code> <p>Returns:</p> Type Description <code>Self</code> <p>The original object with the column added.</p> <p>Examples:</p> <p>Construct pandas as polars DataFrames:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_with_row_index(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_row_index().to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_with_row_index</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_with_row_index(df_pd)\n   index  a  b\n0      0  1  4\n1      1  2  5\n2      2  3  6\n&gt;&gt;&gt; agnostic_with_row_index(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 index \u2506 a   \u2506 b   \u2502\n\u2502 ---   \u2506 --- \u2506 --- \u2502\n\u2502 u32   \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0     \u2506 1   \u2506 4   \u2502\n\u2502 1     \u2506 2   \u2506 5   \u2502\n\u2502 2     \u2506 3   \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_with_row_index(df_pa)\npyarrow.Table\nindex: int64\na: int64\nb: int64\n----\nindex: [[0,1,2]]\na: [[1,2,3]]\nb: [[4,5,6]]\n</code></pre>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.write_csv","title":"<code>write_csv(file=None)</code>","text":"<p>Write dataframe to comma-separated values (CSV) file.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str | Path | BytesIO | None</code> <p>String, path object or file-like object to which the dataframe will be written. If None, the resulting csv format is returned as a string.</p> <code>None</code> <p>Returns:</p> Type Description <code>str | None</code> <p>String or None.</p> <p>Examples:</p> <p>Construct pandas, Polars (eager) and PyArrow DataFrames:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_write_csv(df_native: IntoDataFrame) -&gt; str:\n...     df = nw.from_native(df_native)\n...     return df.write_csv()\n</code></pre> <p>We can pass any supported library such as pandas, Polars or PyArrow to <code>agnostic_write_csv</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_write_csv(df_pd)\n'foo,bar,ham\\n1,6.0,a\\n2,7.0,b\\n3,8.0,c\\n'\n&gt;&gt;&gt; agnostic_write_csv(df_pl)\n'foo,bar,ham\\n1,6.0,a\\n2,7.0,b\\n3,8.0,c\\n'\n&gt;&gt;&gt; agnostic_write_csv(df_pa)\n'\"foo\",\"bar\",\"ham\"\\n1,6,\"a\"\\n2,7,\"b\"\\n3,8,\"c\"\\n'\n</code></pre> <p>If we had passed a file name to <code>write_csv</code>, it would have been written to that file.</p>"},{"location":"api-reference/dataframe/#narwhals.dataframe.DataFrame.write_parquet","title":"<code>write_parquet(file)</code>","text":"<p>Write dataframe to parquet file.</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str | Path | BytesIO</code> <p>String, path object or file-like object to which the dataframe will be written.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None.</p> <p>Examples:</p> <p>Construct pandas, Polars and PyArrow DataFrames:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_write_parquet(df_native: IntoDataFrame):\n...     df = nw.from_native(df_native)\n...     df.write_parquet(\"foo.parquet\")\n</code></pre> <p>We can then pass either pandas, Polars or PyArrow to <code>agnostic_write_parquet</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_write_parquet(df_pd)\n&gt;&gt;&gt; agnostic_write_parquet(df_pl)\n&gt;&gt;&gt; agnostic_write_parquet(df_pa)\n</code></pre>"},{"location":"api-reference/dependencies/","title":"<code>narwhals.dependencies</code>","text":""},{"location":"api-reference/dependencies/#narwhals.dependencies.get_cudf","title":"<code>get_cudf()</code>","text":"<p>Get cudf module (if already imported - else return None).</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.get_ibis","title":"<code>get_ibis()</code>","text":"<p>Get ibis module (if already imported - else return None).</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.get_modin","title":"<code>get_modin()</code>","text":"<p>Get modin.pandas module (if already imported - else return None).</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.get_pandas","title":"<code>get_pandas()</code>","text":"<p>Get pandas module (if already imported - else return None).</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.get_polars","title":"<code>get_polars()</code>","text":"<p>Get Polars module (if already imported - else return None).</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.get_pyarrow","title":"<code>get_pyarrow()</code>","text":"<p>Get pyarrow module (if already imported - else return None).</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_cudf_dataframe","title":"<code>is_cudf_dataframe(df)</code>","text":"<p>Check whether <code>df</code> is a cudf DataFrame without importing cudf.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_cudf_index","title":"<code>is_cudf_index(index)</code>","text":"<p>Check whether <code>index</code> is a cudf Index without importing cudf.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_cudf_series","title":"<code>is_cudf_series(ser)</code>","text":"<p>Check whether <code>ser</code> is a cudf Series without importing cudf.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_dask_dataframe","title":"<code>is_dask_dataframe(df)</code>","text":"<p>Check whether <code>df</code> is a Dask DataFrame without importing Dask.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_ibis_table","title":"<code>is_ibis_table(df)</code>","text":"<p>Check whether <code>df</code> is a Ibis Table without importing Ibis.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_into_dataframe","title":"<code>is_into_dataframe(native_dataframe)</code>","text":"<p>Check whether <code>native_dataframe</code> can be converted to a Narwhals DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>native_dataframe</code> <code>Any</code> <p>The object to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>native_dataframe</code> can be converted to a Narwhals DataFrame, <code>False</code> otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from narwhals.dependencies import is_into_dataframe\n</code></pre> <pre><code>&gt;&gt;&gt; df_pd = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n&gt;&gt;&gt; df_pl = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 6]})\n&gt;&gt;&gt; np_arr = np.array([[1, 4], [2, 5], [3, 6]])\n</code></pre> <pre><code>&gt;&gt;&gt; is_into_dataframe(df_pd)\nTrue\n&gt;&gt;&gt; is_into_dataframe(df_pl)\nTrue\n&gt;&gt;&gt; is_into_dataframe(np_arr)\nFalse\n</code></pre>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_into_series","title":"<code>is_into_series(native_series)</code>","text":"<p>Check whether <code>native_series</code> can be converted to a Narwhals Series.</p> <p>Parameters:</p> Name Type Description Default <code>native_series</code> <code>IntoSeries</code> <p>The object to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>native_series</code> can be converted to a Narwhals Series, <code>False</code> otherwise.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import narwhals as nw\n</code></pre> <pre><code>&gt;&gt;&gt; s_pd = pd.Series([1, 2, 3])\n&gt;&gt;&gt; s_pl = pl.Series([1, 2, 3])\n&gt;&gt;&gt; np_arr = np.array([1, 2, 3])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.dependencies.is_into_series(s_pd)\nTrue\n&gt;&gt;&gt; nw.dependencies.is_into_series(s_pl)\nTrue\n&gt;&gt;&gt; nw.dependencies.is_into_series(np_arr)\nFalse\n</code></pre>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_modin_dataframe","title":"<code>is_modin_dataframe(df)</code>","text":"<p>Check whether <code>df</code> is a modin DataFrame without importing modin.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_modin_index","title":"<code>is_modin_index(index)</code>","text":"<p>Check whether <code>index</code> is a modin Index without importing modin.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_modin_series","title":"<code>is_modin_series(ser)</code>","text":"<p>Check whether <code>ser</code> is a modin Series without importing modin.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_numpy_array","title":"<code>is_numpy_array(arr)</code>","text":"<p>Check whether <code>arr</code> is a NumPy Array without importing NumPy.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_pandas_dataframe","title":"<code>is_pandas_dataframe(df)</code>","text":"<p>Check whether <code>df</code> is a pandas DataFrame without importing pandas.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_pandas_index","title":"<code>is_pandas_index(index)</code>","text":"<p>Check whether <code>index</code> is a pandas Index without importing pandas.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_pandas_like_dataframe","title":"<code>is_pandas_like_dataframe(df)</code>","text":"<p>Check whether <code>df</code> is a pandas-like DataFrame without doing any imports.</p> <p>By \"pandas-like\", we mean: pandas, Modin, cuDF.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_pandas_like_index","title":"<code>is_pandas_like_index(index)</code>","text":"<p>Check whether <code>index</code> is a pandas-like Index without doing any imports.</p> <p>By \"pandas-like\", we mean: pandas, Modin, cuDF.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_pandas_like_series","title":"<code>is_pandas_like_series(ser)</code>","text":"<p>Check whether <code>ser</code> is a pandas-like Series without doing any imports.</p> <p>By \"pandas-like\", we mean: pandas, Modin, cuDF.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_pandas_series","title":"<code>is_pandas_series(ser)</code>","text":"<p>Check whether <code>ser</code> is a pandas Series without importing pandas.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_polars_dataframe","title":"<code>is_polars_dataframe(df)</code>","text":"<p>Check whether <code>df</code> is a Polars DataFrame without importing Polars.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_polars_lazyframe","title":"<code>is_polars_lazyframe(df)</code>","text":"<p>Check whether <code>df</code> is a Polars LazyFrame without importing Polars.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_polars_series","title":"<code>is_polars_series(ser)</code>","text":"<p>Check whether <code>ser</code> is a Polars Series without importing Polars.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_pyarrow_chunked_array","title":"<code>is_pyarrow_chunked_array(ser)</code>","text":"<p>Check whether <code>ser</code> is a PyArrow ChunkedArray without importing PyArrow.</p>"},{"location":"api-reference/dependencies/#narwhals.dependencies.is_pyarrow_table","title":"<code>is_pyarrow_table(df)</code>","text":"<p>Check whether <code>df</code> is a PyArrow Table without importing PyArrow.</p>"},{"location":"api-reference/dtypes/","title":"<code>narwhals.dtypes</code>","text":""},{"location":"api-reference/dtypes/#narwhals.dtypes.Array","title":"<code>Array</code>","text":"<p>Fixed length list type.</p> <p>Parameters:</p> Name Type Description Default <code>inner</code> <code>DType | type[DType]</code> <p>The datatype of the values within each array.</p> required <code>width</code> <code>int | None</code> <p>the length of each array.</p> <code>None</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [[1, 2], [3, 4], [5, 6]]\n&gt;&gt;&gt; ser_pd = pd.Series(data, dtype=pd.ArrowDtype(pa.list_(pa.int32(), 2)))\n&gt;&gt;&gt; ser_pl = pl.Series(data, dtype=pl.Array(pl.Int32, 2))\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data], type=pa.list_(pa.int32(), 2))\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nArray(Int32, 2)\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nArray(Int32, 2)\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nArray(Int32, 2)\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Decimal","title":"<code>Decimal</code>","text":"<p>Decimal type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; s = pl.Series([\"1.5\"], dtype=pl.Decimal)\n&gt;&gt;&gt; nw.from_native(s, series_only=True).dtype\nDecimal\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.List","title":"<code>List</code>","text":"<p>Variable length list type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [[\"narwhal\", \"orca\"], [\"beluga\", \"vaquita\"]]\n&gt;&gt;&gt; ser_pd = pd.Series(data, dtype=pd.ArrowDtype(pa.large_list(pa.large_string())))\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nList(String)\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nList(String)\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nList(String)\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Int128","title":"<code>Int128</code>","text":"<p>128-bit signed integer type.</p>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Int64","title":"<code>Int64</code>","text":"<p>64-bit signed integer type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [2, 1, 3, 7]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nInt64\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nInt64\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nInt64\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Int32","title":"<code>Int32</code>","text":"<p>32-bit signed integer type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [2, 1, 3, 7]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; def func(ser):\n...     ser_nw = nw.from_native(ser, series_only=True)\n...     return ser_nw.cast(nw.Int32).dtype\n</code></pre> <pre><code>&gt;&gt;&gt; func(ser_pd)\nInt32\n&gt;&gt;&gt; func(ser_pl)\nInt32\n&gt;&gt;&gt; func(ser_pa)\nInt32\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Int16","title":"<code>Int16</code>","text":"<p>16-bit signed integer type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [2, 1, 3, 7]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; def func(ser):\n...     ser_nw = nw.from_native(ser, series_only=True)\n...     return ser_nw.cast(nw.Int16).dtype\n</code></pre> <pre><code>&gt;&gt;&gt; func(ser_pd)\nInt16\n&gt;&gt;&gt; func(ser_pl)\nInt16\n&gt;&gt;&gt; func(ser_pa)\nInt16\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Int8","title":"<code>Int8</code>","text":"<p>8-bit signed integer type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [2, 1, 3, 7]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; def func(ser):\n...     ser_nw = nw.from_native(ser, series_only=True)\n...     return ser_nw.cast(nw.Int8).dtype\n</code></pre> <pre><code>&gt;&gt;&gt; func(ser_pd)\nInt8\n&gt;&gt;&gt; func(ser_pl)\nInt8\n&gt;&gt;&gt; func(ser_pa)\nInt8\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.UInt128","title":"<code>UInt128</code>","text":"<p>128-bit unsigned integer type.</p>"},{"location":"api-reference/dtypes/#narwhals.dtypes.UInt64","title":"<code>UInt64</code>","text":"<p>64-bit unsigned integer type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [2, 1, 3, 7]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; def func(ser):\n...     ser_nw = nw.from_native(ser, series_only=True)\n...     return ser_nw.cast(nw.UInt64).dtype\n</code></pre> <pre><code>&gt;&gt;&gt; func(ser_pd)\nUInt64\n&gt;&gt;&gt; func(ser_pl)\nUInt64\n&gt;&gt;&gt; func(ser_pa)\nUInt64\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.UInt32","title":"<code>UInt32</code>","text":"<p>32-bit unsigned integer type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [2, 1, 3, 7]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; def func(ser):\n...     ser_nw = nw.from_native(ser, series_only=True)\n...     return ser_nw.cast(nw.UInt32).dtype\n</code></pre> <pre><code>&gt;&gt;&gt; func(ser_pd)\nUInt32\n&gt;&gt;&gt; func(ser_pl)\nUInt32\n&gt;&gt;&gt; func(ser_pa)\nUInt32\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.UInt16","title":"<code>UInt16</code>","text":"<p>16-bit unsigned integer type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [2, 1, 3, 7]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; def func(ser):\n...     ser_nw = nw.from_native(ser, series_only=True)\n...     return ser_nw.cast(nw.UInt16).dtype\n</code></pre> <pre><code>&gt;&gt;&gt; func(ser_pd)\nUInt16\n&gt;&gt;&gt; func(ser_pl)\nUInt16\n&gt;&gt;&gt; func(ser_pa)\nUInt16\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.UInt8","title":"<code>UInt8</code>","text":"<p>8-bit unsigned integer type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [2, 1, 3, 7]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; def func(ser):\n...     ser_nw = nw.from_native(ser, series_only=True)\n...     return ser_nw.cast(nw.UInt8).dtype\n</code></pre> <pre><code>&gt;&gt;&gt; func(ser_pd)\nUInt8\n&gt;&gt;&gt; func(ser_pl)\nUInt8\n&gt;&gt;&gt; func(ser_pa)\nUInt8\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Field","title":"<code>Field</code>","text":"<p>Definition of a single field within a <code>Struct</code> DataType.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the field within its parent <code>Struct</code>.</p> required <code>dtype</code> <code>type[DType] | DType</code> <p>The <code>DataType</code> of the field's values.</p> required"},{"location":"api-reference/dtypes/#narwhals.dtypes.Float64","title":"<code>Float64</code>","text":"<p>64-bit floating point type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [0.001, 0.1, 0.01, 0.1]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nFloat64\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nFloat64\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nFloat64\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Float32","title":"<code>Float32</code>","text":"<p>32-bit floating point type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [0.001, 0.1, 0.01, 0.1]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; def func(ser):\n...     ser_nw = nw.from_native(ser, series_only=True)\n...     return ser_nw.cast(nw.Float32).dtype\n</code></pre> <pre><code>&gt;&gt;&gt; func(ser_pd)\nFloat32\n&gt;&gt;&gt; func(ser_pl)\nFloat32\n&gt;&gt;&gt; func(ser_pa)\nFloat32\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Boolean","title":"<code>Boolean</code>","text":"<p>Boolean type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [True, False, False, True]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nBoolean\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nBoolean\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nBoolean\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Categorical","title":"<code>Categorical</code>","text":"<p>A categorical encoding of a set of strings.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [\"beluga\", \"narwhal\", \"orca\", \"vaquita\"]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).cast(nw.Categorical).dtype\nCategorical\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).cast(nw.Categorical).dtype\nCategorical\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).cast(nw.Categorical).dtype\nCategorical\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Enum","title":"<code>Enum</code>","text":"<p>A fixed categorical encoding of a unique set of strings.</p> <p>Polars has an Enum data type, while pandas and PyArrow do not.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [\"beluga\", \"narwhal\", \"orca\", \"vaquita\"]\n&gt;&gt;&gt; ser_pl = pl.Series(data, dtype=pl.Enum(data))\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nEnum\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.String","title":"<code>String</code>","text":"<p>UTF-8 encoded string type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [\"beluga\", \"narwhal\", \"orca\", \"vaquita\"]\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nString\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nString\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nString\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Struct","title":"<code>Struct</code>","text":"<p>Struct composite type.</p> <p>Parameters:</p> Name Type Description Default <code>fields</code> <code>Sequence[Field] | Mapping[str, DType | type[DType]]</code> <p>The fields that make up the struct. Can be either a sequence of Field objects or a mapping of column names to data types.</p> required <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = [{\"a\": 1, \"b\": [\"narwhal\", \"beluga\"]}, {\"a\": 2, \"b\": [\"orca\"]}]\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nStruct({'a': Int64, 'b': List(String)})\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nStruct({'a': Int64, 'b': List(String)})\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Struct.to_schema","title":"<code>to_schema()</code>","text":"<p>Return Struct dtype as a schema dict.</p> <p>Returns:</p> Type Description <code>OrderedDict[str, DType | type[DType]]</code> <p>Mapping from column name to dtype.</p>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Date","title":"<code>Date</code>","text":"<p>Data type representing a calendar date.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from datetime import date, timedelta\n&gt;&gt;&gt; data = [date(2024, 12, 1) + timedelta(days=d) for d in range(4)]\n&gt;&gt;&gt; ser_pd = pd.Series(data, dtype=\"date32[pyarrow]\")\n&gt;&gt;&gt; ser_pl = pl.Series(data)\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nDate\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nDate\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nDate\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Datetime","title":"<code>Datetime</code>","text":"<p>Data type representing a calendar date and time of day.</p> <p>Parameters:</p> Name Type Description Default <code>time_unit</code> <code>Literal['us', 'ns', 'ms', 's']</code> <p>Unit of time. Defaults to <code>'us'</code> (microseconds).</p> <code>'us'</code> <code>time_zone</code> <code>str | timezone | None</code> <p>Time zone string, as defined in zoneinfo (to see valid strings run <code>import zoneinfo; zoneinfo.available_timezones()</code> for a full list).</p> <code>None</code> Notes <p>Adapted from Polars implementation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import pyarrow.compute as pc\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from datetime import datetime, timedelta\n&gt;&gt;&gt; data = [datetime(2024, 12, 9) + timedelta(days=n) for n in range(5)]\n&gt;&gt;&gt; ser_pd = (\n...     pd.Series(data)\n...     .dt.tz_localize(\"Africa/Accra\")\n...     .astype(\"datetime64[ms, Africa/Accra]\")\n... )\n&gt;&gt;&gt; ser_pl = (\n...     pl.Series(data).cast(pl.Datetime(\"ms\")).dt.replace_time_zone(\"Africa/Accra\")\n... )\n&gt;&gt;&gt; ser_pa = pc.assume_timezone(\n...     pa.chunked_array([data], type=pa.timestamp(\"ms\")), \"Africa/Accra\"\n... )\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nDatetime(time_unit='ms', time_zone='Africa/Accra')\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nDatetime(time_unit='ms', time_zone='Africa/Accra')\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nDatetime(time_unit='ms', time_zone='Africa/Accra')\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Duration","title":"<code>Duration</code>","text":"<p>Data type representing a time duration.</p> <p>Parameters:</p> Name Type Description Default <code>time_unit</code> <code>Literal['us', 'ns', 'ms', 's']</code> <p>Unit of time. Defaults to <code>'us'</code> (microseconds).</p> <code>'us'</code> Notes <p>Adapted from Polars implementation</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; data = [timedelta(seconds=d) for d in range(1, 4)]\n&gt;&gt;&gt; ser_pd = pd.Series(data).astype(\"timedelta64[ms]\")\n&gt;&gt;&gt; ser_pl = pl.Series(data).cast(pl.Duration(\"ms\"))\n&gt;&gt;&gt; ser_pa = pa.chunked_array([data], type=pa.duration(\"ms\"))\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nDuration(time_unit='ms')\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nDuration(time_unit='ms')\n&gt;&gt;&gt; nw.from_native(ser_pa, series_only=True).dtype\nDuration(time_unit='ms')\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Object","title":"<code>Object</code>","text":"<p>Data type for wrapping arbitrary Python objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; class Foo: ...\n&gt;&gt;&gt; ser_pd = pd.Series([Foo(), Foo()])\n&gt;&gt;&gt; ser_pl = pl.Series([Foo(), Foo()])\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nObject\n&gt;&gt;&gt; nw.from_native(ser_pl, series_only=True).dtype\nObject\n</code></pre>"},{"location":"api-reference/dtypes/#narwhals.dtypes.Unknown","title":"<code>Unknown</code>","text":"<p>Type representing DataType values that could not be determined statically.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = pd.period_range(\"2000-01\", periods=4, freq=\"M\")\n&gt;&gt;&gt; ser_pd = pd.Series(data)\n</code></pre> <pre><code>&gt;&gt;&gt; nw.from_native(ser_pd, series_only=True).dtype\nUnknown\n</code></pre>"},{"location":"api-reference/exceptions/","title":"<code>narwhals.exceptions</code>","text":""},{"location":"api-reference/exceptions/#narwhals.exceptions.ColumnNotFoundError","title":"<code>ColumnNotFoundError</code>","text":"<p>Exception raised when column name isn't present.</p>"},{"location":"api-reference/exceptions/#narwhals.exceptions.InvalidIntoExprError","title":"<code>InvalidIntoExprError</code>","text":"<p>Exception raised when object can't be converted to expression.</p>"},{"location":"api-reference/exceptions/#narwhals.exceptions.InvalidOperationError","title":"<code>InvalidOperationError</code>","text":"<p>Exception raised during invalid operations.</p>"},{"location":"api-reference/exceptions/#narwhals.exceptions.NarwhalsUnstableWarning","title":"<code>NarwhalsUnstableWarning</code>","text":"<p>Warning issued when a method or function is considered unstable in the stable api.</p>"},{"location":"api-reference/expr/","title":"<code>narwhals.Expr</code>","text":""},{"location":"api-reference/expr/#narwhals.Expr.abs","title":"<code>abs()</code>","text":"<p>Return absolute value of each element.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, -2], \"b\": [-3, 4]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_abs(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").abs()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_abs</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_abs(df_pd)\n   a  b\n0  1  3\n1  2  4\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_abs(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 3   \u2502\n\u2502 2   \u2506 4   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_abs(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[1,2]]\nb: [[3,4]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.alias","title":"<code>alias(name)</code>","text":"<p>Rename the expression.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The new name.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [4, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_alias(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select((nw.col(\"b\") + 10).alias(\"c\")).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_alias</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_alias(df_pd)\n    c\n0  14\n1  15\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_alias(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 c   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 14  \u2502\n\u2502 15  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_alias(df_pa)\npyarrow.Table\nc: int64\n----\nc: [[14,15]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.all","title":"<code>all()</code>","text":"<p>Return whether all values in the column are <code>True</code>.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [True, False], \"b\": [True, True]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_all(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").all()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_all</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_all(df_pd)\n       a     b\n0  False  True\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_all(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2506 b    \u2502\n\u2502 ---   \u2506 ---  \u2502\n\u2502 bool  \u2506 bool \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 false \u2506 true \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_all(df_pa)\npyarrow.Table\na: bool\nb: bool\n----\na: [[false]]\nb: [[true]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.any","title":"<code>any()</code>","text":"<p>Return whether any of the values in the column are <code>True</code>.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [True, False], \"b\": [True, True]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_any(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").any()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_any</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_any(df_pd)\n      a     b\n0  True  True\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_any(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b    \u2502\n\u2502 ---  \u2506 ---  \u2502\n\u2502 bool \u2506 bool \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 true \u2506 true \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_any(df_pa)\npyarrow.Table\na: bool\nb: bool\n----\na: [[true]]\nb: [[true]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.arg_max","title":"<code>arg_max()</code>","text":"<p>Returns the index of the maximum value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [10, 20], \"b\": [150, 100]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_arg_max(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\", \"b\").arg_max().name.suffix(\"_arg_max\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_arg_max</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_arg_max(df_pd)\n   a_arg_max  b_arg_max\n0          1          0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_max(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a_arg_max \u2506 b_arg_max \u2502\n\u2502 ---       \u2506 ---       \u2502\n\u2502 u32       \u2506 u32       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1         \u2506 0         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_max(df_pa)\npyarrow.Table\na_arg_max: int64\nb_arg_max: int64\n----\na_arg_max: [[1]]\nb_arg_max: [[0]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.arg_min","title":"<code>arg_min()</code>","text":"<p>Returns the index of the minimum value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [10, 20], \"b\": [150, 100]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_arg_min(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\", \"b\").arg_min().name.suffix(\"_arg_min\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_arg_min</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_arg_min(df_pd)\n   a_arg_min  b_arg_min\n0          0          1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_min(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a_arg_min \u2506 b_arg_min \u2502\n\u2502 ---       \u2506 ---       \u2502\n\u2502 u32       \u2506 u32       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0         \u2506 1         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_min(df_pa)\npyarrow.Table\na_arg_min: int64\nb_arg_min: int64\n----\na_arg_min: [[0]]\nb_arg_min: [[1]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.arg_true","title":"<code>arg_true()</code>","text":"<p>Find elements where boolean expression is True.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p>"},{"location":"api-reference/expr/#narwhals.Expr.cast","title":"<code>cast(dtype)</code>","text":"<p>Redefine an object's data type.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DType | type[DType]</code> <p>Data type that the object will be cast into.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cast(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"foo\").cast(nw.Float32), nw.col(\"bar\").cast(nw.UInt8)\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cast</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cast(df_pd)\n   foo  bar\n0  1.0    6\n1  2.0    7\n2  3.0    8\n&gt;&gt;&gt; agnostic_cast(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 f32 \u2506 u8  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0 \u2506 6   \u2502\n\u2502 2.0 \u2506 7   \u2502\n\u2502 3.0 \u2506 8   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_cast(df_pa)\npyarrow.Table\nfoo: float\nbar: uint8\n----\nfoo: [[1,2,3]]\nbar: [[6,7,8]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.count","title":"<code>count()</code>","text":"<p>Returns the number of non-null elements in the column.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [None, 4, 4]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_count(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.all().count()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_count</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_count(df_pd)\n   a  b\n0  3  2\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_count(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 u32 \u2506 u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 3   \u2506 2   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_count(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[3]]\nb: [[2]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.cum_count","title":"<code>cum_count(*, reverse=False)</code>","text":"<p>Return the cumulative count of the non-null values in the column.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [\"x\", \"k\", None, \"d\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_count(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"a\").cum_count().alias(\"cum_count\"),\n...         nw.col(\"a\").cum_count(reverse=True).alias(\"cum_count_reverse\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cum_count</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_count(df_pd)\n      a  cum_count  cum_count_reverse\n0     x          1                  3\n1     k          2                  2\n2  None          2                  1\n3     d          3                  1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_count(df_pl)\nshape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 cum_count \u2506 cum_count_reverse \u2502\n\u2502 ---  \u2506 ---       \u2506 ---               \u2502\n\u2502 str  \u2506 u32       \u2506 u32               \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 x    \u2506 1         \u2506 3                 \u2502\n\u2502 k    \u2506 2         \u2506 2                 \u2502\n\u2502 null \u2506 2         \u2506 1                 \u2502\n\u2502 d    \u2506 3         \u2506 1                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_count(df_pa)\npyarrow.Table\na: string\ncum_count: uint32\ncum_count_reverse: uint32\n----\na: [[\"x\",\"k\",null,\"d\"]]\ncum_count: [[1,2,2,3]]\ncum_count_reverse: [[3,2,1,1]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.cum_max","title":"<code>cum_max(*, reverse=False)</code>","text":"<p>Return the cumulative max of the non-null values in the column.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 3, None, 2]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_max(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"a\").cum_max().alias(\"cum_max\"),\n...         nw.col(\"a\").cum_max(reverse=True).alias(\"cum_max_reverse\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_max(df_pd)\n     a  cum_max  cum_max_reverse\n0  1.0      1.0              3.0\n1  3.0      3.0              3.0\n2  NaN      NaN              NaN\n3  2.0      3.0              2.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_max(df_pl)\nshape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 cum_max \u2506 cum_max_reverse \u2502\n\u2502 ---  \u2506 ---     \u2506 ---             \u2502\n\u2502 i64  \u2506 i64     \u2506 i64             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1       \u2506 3               \u2502\n\u2502 3    \u2506 3       \u2506 3               \u2502\n\u2502 null \u2506 null    \u2506 null            \u2502\n\u2502 2    \u2506 3       \u2506 2               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_max(df_pa)\npyarrow.Table\na: int64\ncum_max: int64\ncum_max_reverse: int64\n----\na: [[1,3,null,2]]\ncum_max: [[1,3,null,3]]\ncum_max_reverse: [[3,3,null,2]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.cum_min","title":"<code>cum_min(*, reverse=False)</code>","text":"<p>Return the cumulative min of the non-null values in the column.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [3, 1, None, 2]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_min(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"a\").cum_min().alias(\"cum_min\"),\n...         nw.col(\"a\").cum_min(reverse=True).alias(\"cum_min_reverse\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cum_min</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_min(df_pd)\n     a  cum_min  cum_min_reverse\n0  3.0      3.0              1.0\n1  1.0      1.0              1.0\n2  NaN      NaN              NaN\n3  2.0      1.0              2.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_min(df_pl)\nshape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 cum_min \u2506 cum_min_reverse \u2502\n\u2502 ---  \u2506 ---     \u2506 ---             \u2502\n\u2502 i64  \u2506 i64     \u2506 i64             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 3    \u2506 3       \u2506 1               \u2502\n\u2502 1    \u2506 1       \u2506 1               \u2502\n\u2502 null \u2506 null    \u2506 null            \u2502\n\u2502 2    \u2506 1       \u2506 2               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_min(df_pa)\npyarrow.Table\na: int64\ncum_min: int64\ncum_min_reverse: int64\n----\na: [[3,1,null,2]]\ncum_min: [[3,1,null,1]]\ncum_min_reverse: [[1,1,null,2]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.cum_prod","title":"<code>cum_prod(*, reverse=False)</code>","text":"<p>Return the cumulative product of the non-null values in the column.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 3, None, 2]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_prod(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"a\").cum_prod().alias(\"cum_prod\"),\n...         nw.col(\"a\").cum_prod(reverse=True).alias(\"cum_prod_reverse\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cum_prod</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_prod(df_pd)\n     a  cum_prod  cum_prod_reverse\n0  1.0       1.0               6.0\n1  3.0       3.0               6.0\n2  NaN       NaN               NaN\n3  2.0       6.0               2.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_prod(df_pl)\nshape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 cum_prod \u2506 cum_prod_reverse \u2502\n\u2502 ---  \u2506 ---      \u2506 ---              \u2502\n\u2502 i64  \u2506 i64      \u2506 i64              \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 1        \u2506 6                \u2502\n\u2502 3    \u2506 3        \u2506 6                \u2502\n\u2502 null \u2506 null     \u2506 null             \u2502\n\u2502 2    \u2506 6        \u2506 2                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_prod(df_pa)\npyarrow.Table\na: int64\ncum_prod: int64\ncum_prod_reverse: int64\n----\na: [[1,3,null,2]]\ncum_prod: [[1,3,null,6]]\ncum_prod_reverse: [[6,6,null,2]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.cum_sum","title":"<code>cum_sum(*, reverse=False)</code>","text":"<p>Return cumulative sum.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 1, 3, 5, 5], \"b\": [2, 4, 4, 6, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_sum(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").cum_sum()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cum_sum</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_sum(df_pd)\n    a   b\n0   1   2\n1   2   6\n2   5  10\n3  10  16\n4  15  22\n&gt;&gt;&gt; agnostic_cum_sum(df_pl)\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 2   \u2502\n\u2502 2   \u2506 6   \u2502\n\u2502 5   \u2506 10  \u2502\n\u2502 10  \u2506 16  \u2502\n\u2502 15  \u2506 22  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_cum_sum(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[1,2,5,10,15]]\nb: [[2,6,10,16,22]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.diff","title":"<code>diff()</code>","text":"<p>Returns the difference between each element and the previous one.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Notes <p>pandas may change the dtype here, for example when introducing missing values in an integer column. To ensure, that the dtype doesn't change, you may want to use <code>fill_null</code> and <code>cast</code>. For example, to calculate the diff and fill missing values with <code>0</code> in a Int64 column, you could do:</p> <pre><code>nw.col(\"a\").diff().fill_null(0).cast(nw.Int64)\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 1, 3, 5, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_diff(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(a_diff=nw.col(\"a\").diff()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_diff</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_diff(df_pd)\n   a_diff\n0     NaN\n1     0.0\n2     2.0\n3     2.0\n4     0.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_diff(df_pl)\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a_diff \u2502\n\u2502 ---    \u2502\n\u2502 i64    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 null   \u2502\n\u2502 0      \u2502\n\u2502 2      \u2502\n\u2502 2      \u2502\n\u2502 0      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_diff(df_pa)\npyarrow.Table\na_diff: int64\n----\na_diff: [[null,0,2,2,0]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.drop_nulls","title":"<code>drop_nulls()</code>","text":"<p>Drop null values.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; df_pd = pd.DataFrame({\"a\": [2.0, 4.0, float(\"nan\"), 3.0, None, 5.0]})\n&gt;&gt;&gt; df_pl = pl.DataFrame({\"a\": [2.0, 4.0, None, 3.0, None, 5.0]})\n&gt;&gt;&gt; df_pa = pa.table({\"a\": [2.0, 4.0, None, 3.0, None, 5.0]})\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_drop_nulls(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").drop_nulls()).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_drop_nulls</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_drop_nulls(df_pd)\n     a\n0  2.0\n1  4.0\n3  3.0\n5  5.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_drop_nulls(df_pl)\nshape: (4, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2.0 \u2502\n\u2502 4.0 \u2502\n\u2502 3.0 \u2502\n\u2502 5.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_drop_nulls(df_pa)\npyarrow.Table\na: double\n----\na: [[2,4,3,5]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.ewm_mean","title":"<code>ewm_mean(*, com=None, span=None, half_life=None, alpha=None, adjust=True, min_samples=1, ignore_nulls=False)</code>","text":"<p>Compute exponentially-weighted moving average.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>Parameters:</p> Name Type Description Default <code>com</code> <code>float | None</code> <p>Specify decay in terms of center of mass, \\(\\gamma\\), with  \\(\\alpha = \\frac{1}{1+\\gamma}\\forall\\gamma\\geq0\\)</p> <code>None</code> <code>span</code> <code>float | None</code> <p>Specify decay in terms of span, \\(\\theta\\), with  \\(\\alpha = \\frac{2}{\\theta + 1} \\forall \\theta \\geq 1\\)</p> <code>None</code> <code>half_life</code> <code>float | None</code> <p>Specify decay in terms of half-life, \\(\\tau\\), with  \\(\\alpha = 1 - \\exp \\left\\{ \\frac{ -\\ln(2) }{ \\tau } \\right\\} \\forall \\tau &gt; 0\\)</p> <code>None</code> <code>alpha</code> <code>float | None</code> <p>Specify smoothing factor alpha directly, \\(0 &lt; \\alpha \\leq 1\\).</p> <code>None</code> <code>adjust</code> <code>bool</code> <p>Divide by decaying adjustment factor in beginning periods to account for imbalance in relative weightings</p> <ul> <li>When <code>adjust=True</code> (the default) the EW function is calculated   using weights \\(w_i = (1 - \\alpha)^i\\)</li> <li>When <code>adjust=False</code> the EW function is calculated recursively by   $$   y_0=x_0   $$   $$   y_t = (1 - \\alpha)y_{t - 1} + \\alpha x_t   $$</li> </ul> <code>True</code> <code>min_samples</code> <code>int</code> <p>Minimum number of observations in window required to have a value, (otherwise result is null).</p> <code>1</code> <code>ignore_nulls</code> <code>bool</code> <p>Ignore missing values when calculating weights.</p> <ul> <li>When <code>ignore_nulls=False</code> (default), weights are based on absolute   positions.   For example, the weights of \\(x_0\\) and \\(x_2\\) used in   calculating the final weighted average of \\([x_0, None, x_2]\\) are   \\((1-\\alpha)^2\\) and \\(1\\) if <code>adjust=True</code>, and   \\((1-\\alpha)^2\\) and \\(\\alpha\\) if <code>adjust=False</code>.</li> <li>When <code>ignore_nulls=True</code>, weights are based   on relative positions. For example, the weights of   \\(x_0\\) and \\(x_2\\) used in calculating the final weighted   average of \\([x_0, None, x_2]\\) are   \\(1-\\alpha\\) and \\(1\\) if <code>adjust=True</code>,   and \\(1-\\alpha\\) and \\(\\alpha\\) if <code>adjust=False</code>.</li> </ul> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>Expr</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_ewm_mean(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\").ewm_mean(com=1, ignore_nulls=False)\n...     ).to_native()\n</code></pre> <p>We can then pass either pandas or Polars to <code>agnostic_ewm_mean</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_ewm_mean(df_pd)\n          a\n0  1.000000\n1  1.666667\n2  2.428571\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_ewm_mean(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a        \u2502\n\u2502 ---      \u2502\n\u2502 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0      \u2502\n\u2502 1.666667 \u2502\n\u2502 2.428571 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.fill_null","title":"<code>fill_null(value=None, strategy=None, limit=None)</code>","text":"<p>Fill null values with given value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any | None</code> <p>Value used to fill null values.</p> <code>None</code> <code>strategy</code> <code>Literal['forward', 'backward'] | None</code> <p>Strategy used to fill null values.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Number of consecutive null values to fill when using the 'forward' or 'backward' strategy.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; df_pd = pd.DataFrame(\n...     {\n...         \"a\": [2, 4, None, None, 3, 5],\n...         \"b\": [2.0, 4.0, float(\"nan\"), float(\"nan\"), 3.0, 5.0],\n...     }\n... )\n&gt;&gt;&gt; data = {\n...     \"a\": [2, 4, None, None, 3, 5],\n...     \"b\": [2.0, 4.0, None, None, 3.0, 5.0],\n... }\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_fill_null(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(nw.col(\"a\", \"b\").fill_null(0)).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_fill_null</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_fill_null(df_pd)\n     a    b\n0  2.0  2.0\n1  4.0  4.0\n2  0.0  0.0\n3  0.0  0.0\n4  3.0  3.0\n5  5.0  5.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null(df_pl)\nshape: (6, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 2.0 \u2502\n\u2502 4   \u2506 4.0 \u2502\n\u2502 0   \u2506 0.0 \u2502\n\u2502 0   \u2506 0.0 \u2502\n\u2502 3   \u2506 3.0 \u2502\n\u2502 5   \u2506 5.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null(df_pa)\npyarrow.Table\na: int64\nb: double\n----\na: [[2,4,0,0,3,5]]\nb: [[2,4,0,0,3,5]]\n</code></pre> <p>Using a strategy:</p> <pre><code>&gt;&gt;&gt; def agnostic_fill_null_with_strategy(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"a\", \"b\")\n...         .fill_null(strategy=\"forward\", limit=1)\n...         .name.suffix(\"_filled\")\n...     ).to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null_with_strategy(df_pd)\n     a    b  a_filled  b_filled\n0  2.0  2.0       2.0       2.0\n1  4.0  4.0       4.0       4.0\n2  NaN  NaN       4.0       4.0\n3  NaN  NaN       NaN       NaN\n4  3.0  3.0       3.0       3.0\n5  5.0  5.0       5.0       5.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null_with_strategy(df_pl)\nshape: (6, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b    \u2506 a_filled \u2506 b_filled \u2502\n\u2502 ---  \u2506 ---  \u2506 ---      \u2506 ---      \u2502\n\u2502 i64  \u2506 f64  \u2506 i64      \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2    \u2506 2.0  \u2506 2        \u2506 2.0      \u2502\n\u2502 4    \u2506 4.0  \u2506 4        \u2506 4.0      \u2502\n\u2502 null \u2506 null \u2506 4        \u2506 4.0      \u2502\n\u2502 null \u2506 null \u2506 null     \u2506 null     \u2502\n\u2502 3    \u2506 3.0  \u2506 3        \u2506 3.0      \u2502\n\u2502 5    \u2506 5.0  \u2506 5        \u2506 5.0      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null_with_strategy(df_pa)\npyarrow.Table\na: int64\nb: double\na_filled: int64\nb_filled: double\n----\na: [[2,4,null,null,3,5]]\nb: [[2,4,null,null,3,5]]\na_filled: [[2,4,4,null,3,5]]\nb_filled: [[2,4,4,null,3,5]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.filter","title":"<code>filter(*predicates)</code>","text":"<p>Filters elements based on a condition, returning a new expression.</p> <p>Parameters:</p> Name Type Description Default <code>predicates</code> <code>Any</code> <p>Conditions to filter by (which get ANDed together).</p> <code>()</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [2, 3, 4, 5, 6, 7], \"b\": [10, 11, 12, 13, 14, 15]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\").filter(nw.col(\"a\") &gt; 4),\n...         nw.col(\"b\").filter(nw.col(\"b\") &lt; 13),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_filter</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_filter(df_pd)\n   a   b\n3  5  10\n4  6  11\n5  7  12\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_filter(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 5   \u2506 10  \u2502\n\u2502 6   \u2506 11  \u2502\n\u2502 7   \u2506 12  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_filter(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[5,6,7]]\nb: [[10,11,12]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.gather_every","title":"<code>gather_every(n, offset=0)</code>","text":"<p>Take every nth value in the Series and return as new Series.</p> <p>Warning</p> <p><code>Expr.gather_every</code> is deprecated and will be removed in a future version. Hint: instead of <code>df.select(nw.col('a').gather_every())</code>, use <code>df.select(nw.col('a')).gather_every()</code> instead. Note: this will remain available in <code>narwhals.stable.v1</code>. See stable api for more information.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Gather every n-th row.</p> required <code>offset</code> <code>int</code> <p>Starting index.</p> <code>0</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p>"},{"location":"api-reference/expr/#narwhals.Expr.head","title":"<code>head(n=10)</code>","text":"<p>Get the first <code>n</code> rows.</p> <p>Warning</p> <p><code>Expr.head</code> is deprecated and will be removed in a future version. Hint: instead of <code>df.select(nw.col('a').head())</code>, use <code>df.select(nw.col('a')).head()</code> instead. Note: this will remain available in <code>narwhals.stable.v1</code>. See stable api for more information.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to return.</p> <code>10</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p>"},{"location":"api-reference/expr/#narwhals.Expr.clip","title":"<code>clip(lower_bound=None, upper_bound=None)</code>","text":"<p>Clip values in the Series.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bound</code> <code>IntoExpr | Any | None</code> <p>Lower bound value. String literals are treated as column names.</p> <code>None</code> <code>upper_bound</code> <code>IntoExpr | Any | None</code> <p>Upper bound value. String literals are treated as column names.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_clip_lower(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").clip(2)).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_clip_lower</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_clip_lower(df_pd)\n   a\n0  2\n1  2\n2  3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_clip_lower(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2502\n\u2502 2   \u2502\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_clip_lower(df_pa)\npyarrow.Table\na: int64\n----\na: [[2,2,3]]\n</code></pre> <p>We define another library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_clip_upper(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").clip(upper_bound=2)).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_clip_upper</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_clip_upper(df_pd)\n   a\n0  1\n1  2\n2  2\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_clip_upper(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2502 2   \u2502\n\u2502 2   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_clip_upper(df_pa)\npyarrow.Table\na: int64\n----\na: [[1,2,2]]\n</code></pre> <p>We can have both at the same time</p> <pre><code>&gt;&gt;&gt; data = {\"a\": [-1, 1, -3, 3, -5, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_clip(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").clip(-1, 3)).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_clip</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_clip(df_pd)\n   a\n0 -1\n1  1\n2 -1\n3  3\n4 -1\n5  3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_clip(df_pl)\nshape: (6, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -1  \u2502\n\u2502 1   \u2502\n\u2502 -1  \u2502\n\u2502 3   \u2502\n\u2502 -1  \u2502\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_clip(df_pa)\npyarrow.Table\na: int64\n----\na: [[-1,1,-1,3,-1,3]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.is_between","title":"<code>is_between(lower_bound, upper_bound, closed='both')</code>","text":"<p>Check if this expression is between the given lower and upper bounds.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bound</code> <code>Any | IntoExpr</code> <p>Lower bound value. String literals are interpreted as column names.</p> required <code>upper_bound</code> <code>Any | IntoExpr</code> <p>Upper bound value. String literals are interpreted as column names.</p> required <code>closed</code> <code>Literal['left', 'right', 'none', 'both']</code> <p>Define which sides of the interval are closed (inclusive).</p> <code>'both'</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 4, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_between(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").is_between(2, 4, \"right\")).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_between</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_between(df_pd)\n       a\n0  False\n1  False\n2   True\n3   True\n4  False\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_between(df_pl)\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2502\n\u2502 ---   \u2502\n\u2502 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 false \u2502\n\u2502 false \u2502\n\u2502 true  \u2502\n\u2502 true  \u2502\n\u2502 false \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_between(df_pa)\npyarrow.Table\na: bool\n----\na: [[false,false,true,true,false]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.is_duplicated","title":"<code>is_duplicated()</code>","text":"<p>Return a boolean mask indicating duplicated values.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 1], \"b\": [\"a\", \"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_duplicated(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.all().is_duplicated()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_duplicated</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_duplicated(df_pd)\n       a      b\n0   True   True\n1  False   True\n2  False  False\n3   True  False\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_duplicated(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2506 b     \u2502\n\u2502 ---   \u2506 ---   \u2502\n\u2502 bool  \u2506 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 true  \u2506 true  \u2502\n\u2502 false \u2506 true  \u2502\n\u2502 false \u2506 false \u2502\n\u2502 true  \u2506 false \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_duplicated(df_pa)\npyarrow.Table\na: bool\nb: bool\n----\na: [[true,false,false,true]]\nb: [[true,true,false,false]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.is_finite","title":"<code>is_finite()</code>","text":"<p>Returns boolean values indicating which original values are finite.</p> Warning <p>Different backend handle null values differently. <code>is_finite</code> will return False for NaN and Null's in the Dask and pandas non-nullable backend, while for Polars, PyArrow and pandas nullable backends null values are kept as such.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Expression of <code>Boolean</code> data type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [float(\"nan\"), float(\"inf\"), 2.0, None]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_finite(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").is_finite()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_finite</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_finite(df_pd)\n       a\n0  False\n1  False\n2   True\n3  False\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_finite(df_pl)\nshape: (4, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2502\n\u2502 ---   \u2502\n\u2502 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 false \u2502\n\u2502 false \u2502\n\u2502 true  \u2502\n\u2502 null  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_finite(df_pa)\npyarrow.Table\na: bool\n----\na: [[false,false,true,null]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.is_first_distinct","title":"<code>is_first_distinct()</code>","text":"<p>Return a boolean mask indicating the first occurrence of each distinct value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 1], \"b\": [\"a\", \"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_first_distinct(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.all().is_first_distinct()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_first_distinct</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_first_distinct(df_pd)\n       a      b\n0   True   True\n1   True  False\n2   True   True\n3  False   True\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_first_distinct(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2506 b     \u2502\n\u2502 ---   \u2506 ---   \u2502\n\u2502 bool  \u2506 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 true  \u2506 true  \u2502\n\u2502 true  \u2506 false \u2502\n\u2502 true  \u2506 true  \u2502\n\u2502 false \u2506 true  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_first_distinct(df_pa)\npyarrow.Table\na: bool\nb: bool\n----\na: [[true,true,true,false]]\nb: [[true,false,true,true]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.is_in","title":"<code>is_in(other)</code>","text":"<p>Check if elements of this expression are present in the other iterable.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>iterable</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 9, 10]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_in(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(b=nw.col(\"a\").is_in([1, 2])).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_in</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_in(df_pd)\n    a      b\n0   1   True\n1   2   True\n2   9  False\n3  10  False\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_in(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b     \u2502\n\u2502 --- \u2506 ---   \u2502\n\u2502 i64 \u2506 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 true  \u2502\n\u2502 2   \u2506 true  \u2502\n\u2502 9   \u2506 false \u2502\n\u2502 10  \u2506 false \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_in(df_pa)\npyarrow.Table\na: int64\nb: bool\n----\na: [[1,2,9,10]]\nb: [[true,true,false,false]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.is_last_distinct","title":"<code>is_last_distinct()</code>","text":"<p>Return a boolean mask indicating the last occurrence of each distinct value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 1], \"b\": [\"a\", \"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_last_distinct(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.all().is_last_distinct()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_last_distinct</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_last_distinct(df_pd)\n       a      b\n0  False  False\n1   True   True\n2   True   True\n3   True   True\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_last_distinct(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2506 b     \u2502\n\u2502 ---   \u2506 ---   \u2502\n\u2502 bool  \u2506 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 false \u2506 false \u2502\n\u2502 true  \u2506 true  \u2502\n\u2502 true  \u2506 true  \u2502\n\u2502 true  \u2506 true  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_last_distinct(df_pa)\npyarrow.Table\na: bool\nb: bool\n----\na: [[false,true,true,true]]\nb: [[false,true,true,true]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.is_nan","title":"<code>is_nan()</code>","text":"<p>Indicate which values are NaN.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"orig\": [0.0, None, 2.0]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data).astype({\"orig\": \"Float64\"})\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_self_div_is_nan(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         divided=nw.col(\"orig\") / nw.col(\"orig\"),\n...         divided_is_nan=(nw.col(\"orig\") / nw.col(\"orig\")).is_nan(),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_self_div_is_nan</code>:</p> <pre><code>&gt;&gt;&gt; print(agnostic_self_div_is_nan(df_pd))\n   orig  divided  divided_is_nan\n0   0.0      NaN            True\n1  &lt;NA&gt;     &lt;NA&gt;            &lt;NA&gt;\n2   2.0      1.0           False\n</code></pre> <pre><code>&gt;&gt;&gt; print(agnostic_self_div_is_nan(df_pl))\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 orig \u2506 divided \u2506 divided_is_nan \u2502\n\u2502 ---  \u2506 ---     \u2506 ---            \u2502\n\u2502 f64  \u2506 f64     \u2506 bool           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0.0  \u2506 NaN     \u2506 true           \u2502\n\u2502 null \u2506 null    \u2506 null           \u2502\n\u2502 2.0  \u2506 1.0     \u2506 false          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; print(agnostic_self_div_is_nan(df_pa))\npyarrow.Table\norig: double\ndivided: double\ndivided_is_nan: bool\n----\norig: [[0,null,2]]\ndivided: [[nan,null,1]]\ndivided_is_nan: [[true,null,false]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.is_null","title":"<code>is_null()</code>","text":"<p>Returns a boolean Series indicating which values are null.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; df_pd = pd.DataFrame(\n...     {\n...         \"a\": [2, 4, None, 3, 5],\n...         \"b\": [2.0, 4.0, float(\"nan\"), 3.0, 5.0],\n...     }\n... )\n&gt;&gt;&gt; data = {\n...     \"a\": [2, 4, None, 3, 5],\n...     \"b\": [2.0, 4.0, None, 3.0, 5.0],\n... }\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_null(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         a_is_null=nw.col(\"a\").is_null(), b_is_null=nw.col(\"b\").is_null()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_is_null</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_null(df_pd)\n     a    b  a_is_null  b_is_null\n0  2.0  2.0      False      False\n1  4.0  4.0      False      False\n2  NaN  NaN       True       True\n3  3.0  3.0      False      False\n4  5.0  5.0      False      False\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_null(df_pl)\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b    \u2506 a_is_null \u2506 b_is_null \u2502\n\u2502 ---  \u2506 ---  \u2506 ---       \u2506 ---       \u2502\n\u2502 i64  \u2506 f64  \u2506 bool      \u2506 bool      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2    \u2506 2.0  \u2506 false     \u2506 false     \u2502\n\u2502 4    \u2506 4.0  \u2506 false     \u2506 false     \u2502\n\u2502 null \u2506 null \u2506 true      \u2506 true      \u2502\n\u2502 3    \u2506 3.0  \u2506 false     \u2506 false     \u2502\n\u2502 5    \u2506 5.0  \u2506 false     \u2506 false     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_null(df_pa)\npyarrow.Table\na: int64\nb: double\na_is_null: bool\nb_is_null: bool\n----\na: [[2,4,null,3,5]]\nb: [[2,4,null,3,5]]\na_is_null: [[false,false,true,false,false]]\nb_is_null: [[false,false,true,false,false]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.is_unique","title":"<code>is_unique()</code>","text":"<p>Return a boolean mask indicating unique values.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 1], \"b\": [\"a\", \"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_unique(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.all().is_unique()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_unique</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_unique(df_pd)\n       a      b\n0  False  False\n1   True  False\n2   True   True\n3  False   True\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_unique(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2506 b     \u2502\n\u2502 ---   \u2506 ---   \u2502\n\u2502 bool  \u2506 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 false \u2506 false \u2502\n\u2502 true  \u2506 false \u2502\n\u2502 true  \u2506 true  \u2502\n\u2502 false \u2506 true  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_unique(df_pa)\npyarrow.Table\na: bool\nb: bool\n----\na: [[false,true,true,false]]\nb: [[false,false,true,true]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.len","title":"<code>len()</code>","text":"<p>Return the number of elements in the column.</p> <p>Null values count towards the total.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [\"x\", \"y\", \"z\"], \"b\": [1, 2, 1]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function that computes the len over different values of \"b\" column:</p> <pre><code>&gt;&gt;&gt; def agnostic_len(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\").filter(nw.col(\"b\") == 1).len().alias(\"a1\"),\n...         nw.col(\"a\").filter(nw.col(\"b\") == 2).len().alias(\"a2\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_len</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_len(df_pd)\n   a1  a2\n0   2   1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_len(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a1  \u2506 a2  \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 u32 \u2506 u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_len(df_pa)\npyarrow.Table\na1: int64\na2: int64\n----\na1: [[2]]\na2: [[1]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.map_batches","title":"<code>map_batches(function, return_dtype=None)</code>","text":"<p>Apply a custom python function to a whole Series or sequence of Series.</p> <p>The output of this custom function is presumed to be either a Series, or a NumPy array (in which case it will be automatically converted into a Series).</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>Callable[[Any], Self]</code> <p>Function to apply to Series.</p> required <code>return_dtype</code> <code>DType | None</code> <p>Dtype of the output Series. If not set, the dtype will be inferred based on the first non-null value that is returned by the function.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_map_batches(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\", \"b\").map_batches(\n...             lambda s: s.to_numpy() + 1, return_dtype=nw.Float64\n...         )\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_map_batches</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_map_batches(df_pd)\n     a    b\n0  2.0  5.0\n1  3.0  6.0\n2  4.0  7.0\n&gt;&gt;&gt; agnostic_map_batches(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 f64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2.0 \u2506 5.0 \u2502\n\u2502 3.0 \u2506 6.0 \u2502\n\u2502 4.0 \u2506 7.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_map_batches(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[2,3,4]]\nb: [[5,6,7]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.max","title":"<code>max()</code>","text":"<p>Returns the maximum value(s) from a column(s).</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [10, 20], \"b\": [50, 100]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_max(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.max(\"a\", \"b\")).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_max</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_max(df_pd)\n    a    b\n0  20  100\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_max(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 20  \u2506 100 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_max(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[20]]\nb: [[100]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.mean","title":"<code>mean()</code>","text":"<p>Get mean value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [-1, 0, 1], \"b\": [2, 4, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_mean(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").mean()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_mean</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_mean(df_pd)\n     a    b\n0  0.0  4.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mean(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 f64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0.0 \u2506 4.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mean(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[0]]\nb: [[4]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.median","title":"<code>median()</code>","text":"<p>Get median value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Notes <p>Results might slightly differ across backends due to differences in the underlying algorithms used to compute the median.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 8, 3], \"b\": [4, 5, 2]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_median(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").median()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_median</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_median(df_pd)\n     a    b\n0  3.0  4.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_median(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 f64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 3.0 \u2506 4.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_median(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[3]]\nb: [[4]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.min","title":"<code>min()</code>","text":"<p>Returns the minimum value(s) from a column(s).</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [4, 3]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_min(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.min(\"a\", \"b\")).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_min</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_min(df_pd)\n   a  b\n0  1  3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[1]]\nb: [[3]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.mode","title":"<code>mode()</code>","text":"<p>Compute the most occurring value(s).</p> <p>Can return multiple values.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 1, 2, 3],\n...     \"b\": [1, 1, 2, 2],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_mode(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").mode()).sort(\"a\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_mode</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_mode(df_pd)\n   a\n0  1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mode(df_pl)\nshape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mode(df_pa)\npyarrow.Table\na: int64\n----\na: [[1]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.null_count","title":"<code>null_count()</code>","text":"<p>Count null values.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, None, 1], \"b\": [\"a\", None, \"b\", None]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_null_count(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.all().null_count()).to_native()\n</code></pre> <p>We can then pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_null_count</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_null_count(df_pd)\n   a  b\n0  1  2\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_null_count(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 u32 \u2506 u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 2   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_null_count(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[1]]\nb: [[2]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.n_unique","title":"<code>n_unique()</code>","text":"<p>Returns count of unique values.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 4, 5], \"b\": [1, 1, 3, 3, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_n_unique(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").n_unique()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_n_unique</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_n_unique(df_pd)\n   a  b\n0  5  3\n&gt;&gt;&gt; agnostic_n_unique(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 u32 \u2506 u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 5   \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_n_unique(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[5]]\nb: [[3]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.over","title":"<code>over(*keys)</code>","text":"<p>Compute expressions over the given groups.</p> <p>Parameters:</p> Name Type Description Default <code>keys</code> <code>str | Iterable[str]</code> <p>Names of columns to compute window expression over.   Must be names of columns, as opposed to expressions -   so, this is a bit less flexible than Polars' <code>Expr.over</code>.</p> <code>()</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [1, 1, 2]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_min_over_b(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         a_min_per_group=nw.col(\"a\").min().over(\"b\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_min_over_b</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_min_over_b(df_pd)\n   a  b  a_min_per_group\n0  1  1                1\n1  2  1                1\n2  3  2                3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min_over_b(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 a_min_per_group \u2502\n\u2502 --- \u2506 --- \u2506 ---             \u2502\n\u2502 i64 \u2506 i64 \u2506 i64             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 1   \u2506 1               \u2502\n\u2502 2   \u2506 1   \u2506 1               \u2502\n\u2502 3   \u2506 2   \u2506 3               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min_over_b(df_pa)\npyarrow.Table\na: int64\nb: int64\na_min_per_group: int64\n----\na: [[1,2,3]]\nb: [[1,1,2]]\na_min_per_group: [[1,1,3]]\n</code></pre> <p>Cumulative operations are also supported, but (currently) only for pandas and Polars:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_sum(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(c=nw.col(\"a\").cum_sum().over(\"b\")).to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_sum(df_pd)\n   a  b  c\n0  1  1  1\n1  2  1  3\n2  3  2  3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_sum(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 1   \u2506 1   \u2502\n\u2502 2   \u2506 1   \u2506 3   \u2502\n\u2502 3   \u2506 2   \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.pipe","title":"<code>pipe(function, *args, **kwargs)</code>","text":"<p>Pipe function call.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>Callable[Concatenate[Self, PS], R]</code> <p>Function to apply.</p> required <code>args</code> <code>args</code> <p>Positional arguments to pass to function.</p> <code>()</code> <code>kwargs</code> <code>kwargs</code> <p>Keyword arguments to pass to function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>R</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 4]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Lets define a library-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_pipe(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").pipe(lambda x: x + 1)).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_pipe</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_pipe(df_pd)\n   a\n0  2\n1  3\n2  4\n3  5\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_pipe(df_pl)\nshape: (4, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2502\n\u2502 3   \u2502\n\u2502 4   \u2502\n\u2502 5   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_pipe(df_pa)\npyarrow.Table\na: int64\n----\na: [[2,3,4,5]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.quantile","title":"<code>quantile(quantile, interpolation)</code>","text":"<p>Get quantile value.</p> <p>Parameters:</p> Name Type Description Default <code>quantile</code> <code>float</code> <p>Quantile between 0.0 and 1.0.</p> required <code>interpolation</code> <code>Literal['nearest', 'higher', 'lower', 'midpoint', 'linear']</code> <p>Interpolation method.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Note <ul> <li>pandas and Polars may have implementation differences for a given interpolation method.</li> <li>dask has     its own method to approximate quantile and it doesn't implement 'nearest', 'higher',     'lower', 'midpoint' as interpolation method - use 'linear' which is closest to the     native 'dask' - method.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": list(range(50)), \"b\": list(range(50, 100))}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_quantile(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\", \"b\").quantile(0.5, interpolation=\"linear\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_quantile</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_quantile(df_pd)\n      a     b\n0  24.5  74.5\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_quantile(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b    \u2502\n\u2502 ---  \u2506 ---  \u2502\n\u2502 f64  \u2506 f64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 24.5 \u2506 74.5 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_quantile(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[24.5]]\nb: [[74.5]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.rank","title":"<code>rank(method='average', *, descending=False)</code>","text":"<p>Assign ranks to data, dealing with ties appropriately.</p> Notes <p>The resulting dtype may differ between backends.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>Literal['average', 'min', 'max', 'dense', 'ordinal']</code> <p>The method used to assign ranks to tied elements. The following methods are available (default is 'average'):</p> <ul> <li>'average' : The average of the ranks that would have been assigned to   all the tied values is assigned to each value.</li> <li>'min' : The minimum of the ranks that would have been assigned to all     the tied values is assigned to each value. (This is also referred to     as \"competition\" ranking.)</li> <li>'max' : The maximum of the ranks that would have been assigned to all     the tied values is assigned to each value.</li> <li>'dense' : Like 'min', but the rank of the next highest element is    assigned the rank immediately after those assigned to the tied    elements.</li> <li>'ordinal' : All values are given a distinct rank, corresponding to the     order that the values occur in the Series.</li> </ul> <code>'average'</code> <code>descending</code> <code>bool</code> <p>Rank in descending order.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression with rank data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [3, 6, 1, 1, 6]}\n</code></pre> <p>We define a dataframe-agnostic function that computes the dense rank for the data:</p> <pre><code>&gt;&gt;&gt; def agnostic_dense_rank(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     result = df.with_columns(rnk=nw.col(\"a\").rank(method=\"dense\"))\n...     return result.to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dense_rank</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dense_rank(pd.DataFrame(data))\n   a  rnk\n0  3  2.0\n1  6  3.0\n2  1  1.0\n3  1  1.0\n4  6  3.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dense_rank(pl.DataFrame(data))\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 rnk \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 3   \u2506 2   \u2502\n\u2502 6   \u2506 3   \u2502\n\u2502 1   \u2506 1   \u2502\n\u2502 1   \u2506 1   \u2502\n\u2502 6   \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dense_rank(pa.table(data))\npyarrow.Table\na: int64\nrnk: uint64\n----\na: [[3,6,1,1,6]]\nrnk: [[2,3,1,1,3]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.replace_strict","title":"<code>replace_strict(old, new=None, *, return_dtype=None)</code>","text":"<p>Replace all values by different values.</p> <p>This function must replace all non-null input values (else it raises an error).</p> <p>Parameters:</p> Name Type Description Default <code>old</code> <code>Sequence[Any] | Mapping[Any, Any]</code> <p>Sequence of values to replace. It also accepts a mapping of values to their replacement as syntactic sugar for <code>replace_all(old=list(mapping.keys()), new=list(mapping.values()))</code>.</p> required <code>new</code> <code>Sequence[Any] | None</code> <p>Sequence of values to replace by. Length must match the length of <code>old</code>.</p> <code>None</code> <code>return_dtype</code> <code>DType | type[DType] | None</code> <p>The data type of the resulting expression. If set to <code>None</code> (default), the data type is determined automatically based on the other inputs.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [3, 0, 1, 2]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define dataframe-agnostic functions:</p> <pre><code>&gt;&gt;&gt; def agnostic_replace_strict(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         b=nw.col(\"a\").replace_strict(\n...             [0, 1, 2, 3],\n...             [\"zero\", \"one\", \"two\", \"three\"],\n...             return_dtype=nw.String,\n...         )\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_replace_strict</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_replace_strict(df_pd)\n   a      b\n0  3  three\n1  0   zero\n2  1    one\n3  2    two\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace_strict(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b     \u2502\n\u2502 --- \u2506 ---   \u2502\n\u2502 i64 \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 3   \u2506 three \u2502\n\u2502 0   \u2506 zero  \u2502\n\u2502 1   \u2506 one   \u2502\n\u2502 2   \u2506 two   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace_strict(df_pa)\npyarrow.Table\na: int64\nb: string\n----\na: [[3,0,1,2]]\nb: [[\"three\",\"zero\",\"one\",\"two\"]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.rolling_mean","title":"<code>rolling_mean(window_size, *, min_samples=None, center=False)</code>","text":"<p>Apply a rolling mean (moving mean) over the values.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>A window of length <code>window_size</code> will traverse the values. The resulting values will be aggregated to their mean.</p> <p>The window at a given row will include the row itself and the <code>window_size - 1</code> elements before it.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>The length of the window in number of elements. It must be a strictly positive integer.</p> required <code>min_samples</code> <code>int | None</code> <p>The number of values in the window that should be non-null before computing a result. If set to <code>None</code> (default), it will be set equal to <code>window_size</code>. If provided, it must be a strictly positive integer, and less than or equal to <code>window_size</code></p> <code>None</code> <code>center</code> <code>bool</code> <p>Set the labels at the center of the window.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1.0, 2.0, None, 4.0]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rolling_mean(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         b=nw.col(\"a\").rolling_mean(window_size=3, min_samples=1)\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_rolling_mean</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rolling_mean(df_pd)\n     a    b\n0  1.0  1.0\n1  2.0  1.5\n2  NaN  1.5\n3  4.0  3.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_mean(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b   \u2502\n\u2502 ---  \u2506 --- \u2502\n\u2502 f64  \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0  \u2506 1.0 \u2502\n\u2502 2.0  \u2506 1.5 \u2502\n\u2502 null \u2506 1.5 \u2502\n\u2502 4.0  \u2506 3.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_mean(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[1,2,null,4]]\nb: [[1,1.5,1.5,3]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.rolling_std","title":"<code>rolling_std(window_size, *, min_samples=None, center=False, ddof=1)</code>","text":"<p>Apply a rolling standard deviation (moving standard deviation) over the values.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>A window of length <code>window_size</code> will traverse the values. The resulting values will be aggregated to their standard deviation.</p> <p>The window at a given row will include the row itself and the <code>window_size - 1</code> elements before it.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>The length of the window in number of elements. It must be a strictly positive integer.</p> required <code>min_samples</code> <code>int | None</code> <p>The number of values in the window that should be non-null before computing a result. If set to <code>None</code> (default), it will be set equal to <code>window_size</code>. If provided, it must be a strictly positive integer, and less than or equal to <code>window_size</code>.</p> <code>None</code> <code>center</code> <code>bool</code> <p>Set the labels at the center of the window.</p> <code>False</code> <code>ddof</code> <code>int</code> <p>Delta Degrees of Freedom; the divisor for a length N window is N - ddof.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1.0, 2.0, None, 4.0]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rolling_std(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         b=nw.col(\"a\").rolling_std(window_size=3, min_samples=1)\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_rolling_std</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rolling_std(df_pd)\n     a         b\n0  1.0       NaN\n1  2.0  0.707107\n2  NaN  0.707107\n3  4.0  1.414214\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_std(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b        \u2502\n\u2502 ---  \u2506 ---      \u2502\n\u2502 f64  \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0  \u2506 null     \u2502\n\u2502 2.0  \u2506 0.707107 \u2502\n\u2502 null \u2506 0.707107 \u2502\n\u2502 4.0  \u2506 1.414214 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_std(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[1,2,null,4]]\nb: [[nan,0.7071067811865476,0.7071067811865476,1.4142135623730951]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.rolling_sum","title":"<code>rolling_sum(window_size, *, min_samples=None, center=False)</code>","text":"<p>Apply a rolling sum (moving sum) over the values.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>A window of length <code>window_size</code> will traverse the values. The resulting values will be aggregated to their sum.</p> <p>The window at a given row will include the row itself and the <code>window_size - 1</code> elements before it.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>The length of the window in number of elements. It must be a strictly positive integer.</p> required <code>min_samples</code> <code>int | None</code> <p>The number of values in the window that should be non-null before computing a result. If set to <code>None</code> (default), it will be set equal to <code>window_size</code>. If provided, it must be a strictly positive integer, and less than or equal to <code>window_size</code></p> <code>None</code> <code>center</code> <code>bool</code> <p>Set the labels at the center of the window.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1.0, 2.0, None, 4.0]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rolling_sum(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         b=nw.col(\"a\").rolling_sum(window_size=3, min_samples=1)\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_rolling_sum</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rolling_sum(df_pd)\n     a    b\n0  1.0  1.0\n1  2.0  3.0\n2  NaN  3.0\n3  4.0  6.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_sum(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b   \u2502\n\u2502 ---  \u2506 --- \u2502\n\u2502 f64  \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0  \u2506 1.0 \u2502\n\u2502 2.0  \u2506 3.0 \u2502\n\u2502 null \u2506 3.0 \u2502\n\u2502 4.0  \u2506 6.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_sum(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[1,2,null,4]]\nb: [[1,3,3,6]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.rolling_var","title":"<code>rolling_var(window_size, *, min_samples=None, center=False, ddof=1)</code>","text":"<p>Apply a rolling variance (moving variance) over the values.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>A window of length <code>window_size</code> will traverse the values. The resulting values will be aggregated to their variance.</p> <p>The window at a given row will include the row itself and the <code>window_size - 1</code> elements before it.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>The length of the window in number of elements. It must be a strictly positive integer.</p> required <code>min_samples</code> <code>int | None</code> <p>The number of values in the window that should be non-null before computing a result. If set to <code>None</code> (default), it will be set equal to <code>window_size</code>. If provided, it must be a strictly positive integer, and less than or equal to <code>window_size</code>.</p> <code>None</code> <code>center</code> <code>bool</code> <p>Set the labels at the center of the window.</p> <code>False</code> <code>ddof</code> <code>int</code> <p>Delta Degrees of Freedom; the divisor for a length N window is N - ddof.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1.0, 2.0, None, 4.0]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rolling_var(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         b=nw.col(\"a\").rolling_var(window_size=3, min_samples=1)\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_rolling_var</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rolling_var(df_pd)\n     a    b\n0  1.0  NaN\n1  2.0  0.5\n2  NaN  0.5\n3  4.0  2.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_var(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b    \u2502\n\u2502 ---  \u2506 ---  \u2502\n\u2502 f64  \u2506 f64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0  \u2506 null \u2502\n\u2502 2.0  \u2506 0.5  \u2502\n\u2502 null \u2506 0.5  \u2502\n\u2502 4.0  \u2506 2.0  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_var(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[1,2,null,4]]\nb: [[nan,0.5,0.5,2]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.round","title":"<code>round(decimals=0)</code>","text":"<p>Round underlying floating point data by <code>decimals</code> digits.</p> <p>Parameters:</p> Name Type Description Default <code>decimals</code> <code>int</code> <p>Number of decimals to round by.</p> <code>0</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Notes <p>For values exactly halfway between rounded decimal values pandas behaves differently than Polars and Arrow.</p> <p>pandas rounds to the nearest even value (e.g. -0.5 and 0.5 round to 0.0, 1.5 and 2.5 round to 2.0, 3.5 and 4.5 to 4.0, etc..).</p> <p>Polars and Arrow round away from 0 (e.g. -0.5 to -1.0, 0.5 to 1.0, 1.5 to 2.0, 2.5 to 3.0, etc..).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1.12345, 2.56789, 3.901234]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function that rounds to the first decimal:</p> <pre><code>&gt;&gt;&gt; def agnostic_round(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").round(1)).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_round</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_round(df_pd)\n     a\n0  1.1\n1  2.6\n2  3.9\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_round(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.1 \u2502\n\u2502 2.6 \u2502\n\u2502 3.9 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_round(df_pa)\npyarrow.Table\na: double\n----\na: [[1.1,2.6,3.9]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.sample","title":"<code>sample(n=None, *, fraction=None, with_replacement=False, seed=None)</code>","text":"<p>Sample randomly from this expression.</p> <p>Warning</p> <p><code>Expr.sample</code> is deprecated and will be removed in a future version. Hint: instead of <code>df.select(nw.col('a').sample())</code>, use <code>df.select(nw.col('a')).sample()</code> instead. Note: this will remain available in <code>narwhals.stable.v1</code>. See stable api for more information.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | None</code> <p>Number of items to return. Cannot be used with fraction.</p> <code>None</code> <code>fraction</code> <code>float | None</code> <p>Fraction of items to return. Cannot be used with n.</p> <code>None</code> <code>with_replacement</code> <code>bool</code> <p>Allow values to be sampled more than once.</p> <code>False</code> <code>seed</code> <code>int | None</code> <p>Seed for the random number generator. If set to None (default), a random seed is generated for each sample operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p>"},{"location":"api-reference/expr/#narwhals.Expr.shift","title":"<code>shift(n)</code>","text":"<p>Shift values by <code>n</code> positions.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of positions to shift values by.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> Notes <p>pandas may change the dtype here, for example when introducing missing values in an integer column. To ensure, that the dtype doesn't change, you may want to use <code>fill_null</code> and <code>cast</code>. For example, to shift and fill missing values with <code>0</code> in a Int64 column, you could do:</p> <pre><code>nw.col(\"a\").shift(1).fill_null(0).cast(nw.Int64)\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 1, 3, 5, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_shift(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(a_shift=nw.col(\"a\").shift(n=1)).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_shift</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_shift(df_pd)\n   a_shift\n0      NaN\n1      1.0\n2      1.0\n3      3.0\n4      5.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_shift(df_pl)\nshape: (5, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a_shift \u2502\n\u2502 ---     \u2502\n\u2502 i64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 null    \u2502\n\u2502 1       \u2502\n\u2502 1       \u2502\n\u2502 3       \u2502\n\u2502 5       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_shift(df_pa)\npyarrow.Table\na_shift: int64\n----\na_shift: [[null,1,1,3,5]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.sort","title":"<code>sort(*, descending=False, nulls_last=False)</code>","text":"<p>Sort this column. Place null values first.</p> <p>Warning</p> <p><code>Expr.sort</code> is deprecated and will be removed in a future version. Hint: instead of <code>df.select(nw.col('a').sort())</code>, use <code>df.select(nw.col('a')).sort()</code> instead. Note: this will remain available in <code>narwhals.stable.v1</code>. See stable api for more information.</p> <p>Parameters:</p> Name Type Description Default <code>descending</code> <code>bool</code> <p>Sort in descending order.</p> <code>False</code> <code>nulls_last</code> <code>bool</code> <p>Place null values last instead of first.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p>"},{"location":"api-reference/expr/#narwhals.Expr.skew","title":"<code>skew()</code>","text":"<p>Calculate the sample skewness of a column.</p> <p>Returns:</p> Type Description <code>Self</code> <p>An expression representing the sample skewness of the column.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 4, 5], \"b\": [1, 1, 2, 10, 100]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_skew(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").skew()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_skew</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_skew(df_pd)\n     a         b\n0  0.0  1.472427\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_skew(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b        \u2502\n\u2502 --- \u2506 ---      \u2502\n\u2502 f64 \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0.0 \u2506 1.472427 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_skew(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[0]]\nb: [[1.4724267269058975]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.std","title":"<code>std(*, ddof=1)</code>","text":"<p>Get standard deviation.</p> <p>Parameters:</p> Name Type Description Default <code>ddof</code> <code>int</code> <p>\"Delta Degrees of Freedom\": the divisor used in the calculation is N - ddof, where N represents the number of elements. By default ddof is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [20, 25, 60], \"b\": [1.5, 1, -1.4]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_std(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").std(ddof=0)).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_std</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_std(df_pd)\n          a         b\n0  17.79513  1.265789\n&gt;&gt;&gt; agnostic_std(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a        \u2506 b        \u2502\n\u2502 ---      \u2506 ---      \u2502\n\u2502 f64      \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 17.79513 \u2506 1.265789 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_std(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[17.795130420052185]]\nb: [[1.2657891697365016]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.sum","title":"<code>sum()</code>","text":"<p>Return the sum value.</p> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [5, 10], \"b\": [50, 100]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_sum(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").sum()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_sum</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_sum(df_pd)\n    a    b\n0  15  150\n&gt;&gt;&gt; agnostic_sum(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 15  \u2506 150 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_sum(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[15]]\nb: [[150]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.tail","title":"<code>tail(n=10)</code>","text":"<p>Get the last <code>n</code> rows.</p> <p>Warning</p> <p><code>Expr.tail</code> is deprecated and will be removed in a future version. Hint: instead of <code>df.select(nw.col('a').tail())</code>, use <code>df.select(nw.col('a')).tail()</code> instead. Note: this will remain available in <code>narwhals.stable.v1</code>. See stable api for more information.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to return.</p> <code>10</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p>"},{"location":"api-reference/expr/#narwhals.Expr.unique","title":"<code>unique()</code>","text":"<p>Return unique values of this expression.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 1, 3, 5, 5], \"b\": [2, 4, 4, 6, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_unique(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").unique().sum()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_unique</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_unique(df_pd)\n   a   b\n0  9  12\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_unique(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 9   \u2506 12  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_unique(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[9]]\nb: [[12]]\n</code></pre>"},{"location":"api-reference/expr/#narwhals.Expr.var","title":"<code>var(*, ddof=1)</code>","text":"<p>Get variance.</p> <p>Parameters:</p> Name Type Description Default <code>ddof</code> <code>int</code> <p>\"Delta Degrees of Freedom\": the divisor used in the calculation is N - ddof,      where N represents the number of elements. By default ddof is 1.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [20, 25, 60], \"b\": [1.5, 1, -1.4]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_var(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\", \"b\").var(ddof=0)).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_var</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_var(df_pd)\n            a         b\n0  316.666667  1.602222\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_var(df_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a          \u2506 b        \u2502\n\u2502 ---        \u2506 ---      \u2502\n\u2502 f64        \u2506 f64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 316.666667 \u2506 1.602222 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_var(df_pa)\npyarrow.Table\na: double\nb: double\n----\na: [[316.6666666666667]]\nb: [[1.6022222222222222]]\n</code></pre>"},{"location":"api-reference/expr_cat/","title":"<code>narwhals.Expr.cat</code>","text":""},{"location":"api-reference/expr_cat/#narwhals.expr.ExprCatNamespace.get_categories","title":"<code>get_categories()</code>","text":"<p>Get unique categories from column.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <p>Let's create some dataframes:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"fruits\": [\"apple\", \"mango\", \"mango\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data, dtype=\"category\")\n&gt;&gt;&gt; df_pl = pl.DataFrame(data, schema={\"fruits\": pl.Categorical})\n</code></pre> <p>We define a dataframe-agnostic function to get unique categories from column 'fruits':</p> <pre><code>&gt;&gt;&gt; def agnostic_cat_get_categories(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"fruits\").cat.get_categories()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas or Polars to    <code>agnostic_cat_get_categories</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cat_get_categories(df_pd)\n  fruits\n0  apple\n1  mango\n\n&gt;&gt;&gt; agnostic_cat_get_categories(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 fruits \u2502\n\u2502 ---    \u2502\n\u2502 str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 apple  \u2502\n\u2502 mango  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/expr_dt/","title":"<code>narwhals.Expr.dt</code>","text":""},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.convert_time_zone","title":"<code>convert_time_zone(time_zone)</code>","text":"<p>Convert to a new time zone.</p> <p>If converting from a time-zone-naive column, then conversion happens as if converting from UTC.</p> <p>Parameters:</p> Name Type Description Default <code>time_zone</code> <code>str</code> <p>Target time zone.</p> required <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [\n...         datetime(2024, 1, 1, tzinfo=timezone.utc),\n...         datetime(2024, 1, 2, tzinfo=timezone.utc),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_convert_time_zone(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\").dt.convert_time_zone(\"Asia/Kathmandu\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_convert_time_zone</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_convert_time_zone(df_pd)\n                          a\n0 2024-01-01 05:45:00+05:45\n1 2024-01-02 05:45:00+05:45\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_convert_time_zone(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a                            \u2502\n\u2502 ---                          \u2502\n\u2502 datetime[\u03bcs, Asia/Kathmandu] \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2024-01-01 05:45:00 +0545    \u2502\n\u2502 2024-01-02 05:45:00 +0545    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_convert_time_zone(df_pa)\npyarrow.Table\na: timestamp[us, tz=Asia/Kathmandu]\n----\na: [[2024-01-01 00:00:00.000000Z,2024-01-02 00:00:00.000000Z]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.date","title":"<code>date()</code>","text":"<p>Extract the date from underlying DateTime representation.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If pandas default backend is being used.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [datetime(2012, 1, 7, 10, 20), datetime(2023, 3, 10, 11, 32)]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data).convert_dtypes(dtype_backend=\"pyarrow\")\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_date(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\").dt.date()).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_date</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_date(df_pd)\n            a\n0  2012-01-07\n1  2023-03-10\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_date(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a          \u2502\n\u2502 ---        \u2502\n\u2502 date       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2012-01-07 \u2502\n\u2502 2023-03-10 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_date(df_pa)\npyarrow.Table\na: date32[day]\n----\na: [[2012-01-07,2023-03-10]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.day","title":"<code>day()</code>","text":"<p>Extract day from underlying DateTime representation.</p> <p>Returns the day of month starting from 1. The return value ranges from 1 to 31. (The last day of month differs by months.)</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"datetime\": [\n...         datetime(1978, 6, 1),\n...         datetime(2024, 12, 13),\n...         datetime(2065, 1, 1),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_day(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"datetime\").dt.day().alias(\"day\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_day</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_day(df_pd)\n    datetime  day\n0 1978-06-01    1\n1 2024-12-13   13\n2 2065-01-01    1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_day(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime            \u2506 day \u2502\n\u2502 ---                 \u2506 --- \u2502\n\u2502 datetime[\u03bcs]        \u2506 i8  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1978-06-01 00:00:00 \u2506 1   \u2502\n\u2502 2024-12-13 00:00:00 \u2506 13  \u2502\n\u2502 2065-01-01 00:00:00 \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_day(df_pa)\npyarrow.Table\ndatetime: timestamp[us]\nday: int64\n----\ndatetime: [[1978-06-01 00:00:00.000000,2024-12-13 00:00:00.000000,2065-01-01 00:00:00.000000]]\nday: [[1,13,1]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.hour","title":"<code>hour()</code>","text":"<p>Extract hour from underlying DateTime representation.</p> <p>Returns the hour number from 0 to 23.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"datetime\": [\n...         datetime(1978, 1, 1, 1),\n...         datetime(2024, 10, 13, 5),\n...         datetime(2065, 1, 1, 10),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_hour(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"datetime\").dt.hour().alias(\"hour\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_hour</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_hour(df_pd)\n             datetime  hour\n0 1978-01-01 01:00:00     1\n1 2024-10-13 05:00:00     5\n2 2065-01-01 10:00:00    10\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_hour(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime            \u2506 hour \u2502\n\u2502 ---                 \u2506 ---  \u2502\n\u2502 datetime[\u03bcs]        \u2506 i8   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1978-01-01 01:00:00 \u2506 1    \u2502\n\u2502 2024-10-13 05:00:00 \u2506 5    \u2502\n\u2502 2065-01-01 10:00:00 \u2506 10   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_hour(df_pa)\npyarrow.Table\ndatetime: timestamp[us]\nhour: int64\n----\ndatetime: [[1978-01-01 01:00:00.000000,2024-10-13 05:00:00.000000,2065-01-01 10:00:00.000000]]\nhour: [[1,5,10]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.microsecond","title":"<code>microsecond()</code>","text":"<p>Extract microseconds from underlying DateTime representation.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"datetime\": [\n...         datetime(1978, 1, 1, 1, 1, 1, 0),\n...         datetime(2024, 10, 13, 5, 30, 14, 505000),\n...         datetime(2065, 1, 1, 10, 20, 30, 67000),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_microsecond(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"datetime\").dt.microsecond().alias(\"microsecond\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_microsecond</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_microsecond(df_pd)\n                 datetime  microsecond\n0 1978-01-01 01:01:01.000            0\n1 2024-10-13 05:30:14.505       505000\n2 2065-01-01 10:20:30.067        67000\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_microsecond(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime                \u2506 microsecond \u2502\n\u2502 ---                     \u2506 ---         \u2502\n\u2502 datetime[\u03bcs]            \u2506 i32         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1978-01-01 01:01:01     \u2506 0           \u2502\n\u2502 2024-10-13 05:30:14.505 \u2506 505000      \u2502\n\u2502 2065-01-01 10:20:30.067 \u2506 67000       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_microsecond(df_pa)\npyarrow.Table\ndatetime: timestamp[us]\nmicrosecond: int64\n----\ndatetime: [[1978-01-01 01:01:01.000000,2024-10-13 05:30:14.505000,2065-01-01 10:20:30.067000]]\nmicrosecond: [[0,505000,67000]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.millisecond","title":"<code>millisecond()</code>","text":"<p>Extract milliseconds from underlying DateTime representation.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"datetime\": [\n...         datetime(1978, 1, 1, 1, 1, 1, 0),\n...         datetime(2024, 10, 13, 5, 30, 14, 505000),\n...         datetime(2065, 1, 1, 10, 20, 30, 67000),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_millisecond(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"datetime\").dt.millisecond().alias(\"millisecond\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_millisecond</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_millisecond(df_pd)\n                 datetime  millisecond\n0 1978-01-01 01:01:01.000            0\n1 2024-10-13 05:30:14.505          505\n2 2065-01-01 10:20:30.067           67\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_millisecond(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime                \u2506 millisecond \u2502\n\u2502 ---                     \u2506 ---         \u2502\n\u2502 datetime[\u03bcs]            \u2506 i32         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1978-01-01 01:01:01     \u2506 0           \u2502\n\u2502 2024-10-13 05:30:14.505 \u2506 505         \u2502\n\u2502 2065-01-01 10:20:30.067 \u2506 67          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_millisecond(df_pa)\npyarrow.Table\ndatetime: timestamp[us]\nmillisecond: int64\n----\ndatetime: [[1978-01-01 01:01:01.000000,2024-10-13 05:30:14.505000,2065-01-01 10:20:30.067000]]\nmillisecond: [[0,505,67]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.minute","title":"<code>minute()</code>","text":"<p>Extract minutes from underlying DateTime representation.</p> <p>Returns the minute number from 0 to 59.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"datetime\": [\n...         datetime(1978, 1, 1, 1, 1),\n...         datetime(2024, 10, 13, 5, 30),\n...         datetime(2065, 1, 1, 10, 20),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_minute(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"datetime\").dt.minute().alias(\"minute\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_minute</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_minute(df_pd)\n             datetime  minute\n0 1978-01-01 01:01:00       1\n1 2024-10-13 05:30:00      30\n2 2065-01-01 10:20:00      20\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_minute(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime            \u2506 minute \u2502\n\u2502 ---                 \u2506 ---    \u2502\n\u2502 datetime[\u03bcs]        \u2506 i8     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1978-01-01 01:01:00 \u2506 1      \u2502\n\u2502 2024-10-13 05:30:00 \u2506 30     \u2502\n\u2502 2065-01-01 10:20:00 \u2506 20     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_minute(df_pa)\npyarrow.Table\ndatetime: timestamp[us]\nminute: int64\n----\ndatetime: [[1978-01-01 01:01:00.000000,2024-10-13 05:30:00.000000,2065-01-01 10:20:00.000000]]\nminute: [[1,30,20]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.month","title":"<code>month()</code>","text":"<p>Extract month from underlying DateTime representation.</p> <p>Returns the month number starting from 1. The return value ranges from 1 to 12.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"datetime\": [\n...         datetime(1978, 6, 1),\n...         datetime(2024, 12, 13),\n...         datetime(2065, 1, 1),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_month(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"datetime\").dt.month().alias(\"month\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_month</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_month(df_pd)\n    datetime  month\n0 1978-06-01      6\n1 2024-12-13     12\n2 2065-01-01      1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_month(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime            \u2506 month \u2502\n\u2502 ---                 \u2506 ---   \u2502\n\u2502 datetime[\u03bcs]        \u2506 i8    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1978-06-01 00:00:00 \u2506 6     \u2502\n\u2502 2024-12-13 00:00:00 \u2506 12    \u2502\n\u2502 2065-01-01 00:00:00 \u2506 1     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_month(df_pa)\npyarrow.Table\ndatetime: timestamp[us]\nmonth: int64\n----\ndatetime: [[1978-06-01 00:00:00.000000,2024-12-13 00:00:00.000000,2065-01-01 00:00:00.000000]]\nmonth: [[6,12,1]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.nanosecond","title":"<code>nanosecond()</code>","text":"<p>Extract Nanoseconds from underlying DateTime representation.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"datetime\": [\n...         datetime(1978, 1, 1, 1, 1, 1, 0),\n...         datetime(2024, 10, 13, 5, 30, 14, 500000),\n...         datetime(2065, 1, 1, 10, 20, 30, 60000),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_nanosecond(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"datetime\").dt.nanosecond().alias(\"nanosecond\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_nanosecond</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_nanosecond(df_pd)\n                 datetime  nanosecond\n0 1978-01-01 01:01:01.000           0\n1 2024-10-13 05:30:14.500   500000000\n2 2065-01-01 10:20:30.060    60000000\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_nanosecond(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime                \u2506 nanosecond \u2502\n\u2502 ---                     \u2506 ---        \u2502\n\u2502 datetime[\u03bcs]            \u2506 i32        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1978-01-01 01:01:01     \u2506 0          \u2502\n\u2502 2024-10-13 05:30:14.500 \u2506 500000000  \u2502\n\u2502 2065-01-01 10:20:30.060 \u2506 60000000   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_nanosecond(df_pa)\npyarrow.Table\ndatetime: timestamp[us]\nnanosecond: int64\n----\ndatetime: [[1978-01-01 01:01:01.000000,2024-10-13 05:30:14.500000,2065-01-01 10:20:30.060000]]\nnanosecond: [[0,500000000,60000000]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.ordinal_day","title":"<code>ordinal_day()</code>","text":"<p>Get ordinal day.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [datetime(2020, 1, 1), datetime(2020, 8, 3)]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_ordinal_day(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         a_ordinal_day=nw.col(\"a\").dt.ordinal_day()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_ordinal_day</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_ordinal_day(df_pd)\n           a  a_ordinal_day\n0 2020-01-01              1\n1 2020-08-03            216\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_ordinal_day(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a                   \u2506 a_ordinal_day \u2502\n\u2502 ---                 \u2506 ---           \u2502\n\u2502 datetime[\u03bcs]        \u2506 i16           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2020-01-01 00:00:00 \u2506 1             \u2502\n\u2502 2020-08-03 00:00:00 \u2506 216           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_ordinal_day(df_pa)\npyarrow.Table\na: timestamp[us]\na_ordinal_day: int64\n----\na: [[2020-01-01 00:00:00.000000,2020-08-03 00:00:00.000000]]\na_ordinal_day: [[1,216]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.replace_time_zone","title":"<code>replace_time_zone(time_zone)</code>","text":"<p>Replace time zone.</p> <p>Parameters:</p> Name Type Description Default <code>time_zone</code> <code>str | None</code> <p>Target time zone.</p> required <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [\n...         datetime(2024, 1, 1, tzinfo=timezone.utc),\n...         datetime(2024, 1, 2, tzinfo=timezone.utc),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_replace_time_zone(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\").dt.replace_time_zone(\"Asia/Kathmandu\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_replace_time_zone</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_replace_time_zone(df_pd)\n                          a\n0 2024-01-01 00:00:00+05:45\n1 2024-01-02 00:00:00+05:45\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_replace_time_zone(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a                            \u2502\n\u2502 ---                          \u2502\n\u2502 datetime[\u03bcs, Asia/Kathmandu] \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2024-01-01 00:00:00 +0545    \u2502\n\u2502 2024-01-02 00:00:00 +0545    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_replace_time_zone(df_pa)\npyarrow.Table\na: timestamp[us, tz=Asia/Kathmandu]\n----\na: [[2023-12-31 18:15:00.000000Z,2024-01-01 18:15:00.000000Z]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.second","title":"<code>second()</code>","text":"<p>Extract seconds from underlying DateTime representation.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"datetime\": [\n...         datetime(1978, 1, 1, 1, 1, 1),\n...         datetime(2024, 10, 13, 5, 30, 14),\n...         datetime(2065, 1, 1, 10, 20, 30),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_second(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"datetime\").dt.second().alias(\"second\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_second</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_second(df_pd)\n             datetime  second\n0 1978-01-01 01:01:01       1\n1 2024-10-13 05:30:14      14\n2 2065-01-01 10:20:30      30\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_second(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime            \u2506 second \u2502\n\u2502 ---                 \u2506 ---    \u2502\n\u2502 datetime[\u03bcs]        \u2506 i8     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1978-01-01 01:01:01 \u2506 1      \u2502\n\u2502 2024-10-13 05:30:14 \u2506 14     \u2502\n\u2502 2065-01-01 10:20:30 \u2506 30     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_second(df_pa)\npyarrow.Table\ndatetime: timestamp[us]\nsecond: int64\n----\ndatetime: [[1978-01-01 01:01:01.000000,2024-10-13 05:30:14.000000,2065-01-01 10:20:30.000000]]\nsecond: [[1,14,30]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.timestamp","title":"<code>timestamp(time_unit='us')</code>","text":"<p>Return a timestamp in the given time unit.</p> <p>Parameters:</p> Name Type Description Default <code>time_unit</code> <code>Literal['ns', 'us', 'ms']</code> <p>{'ns', 'us', 'ms'} Time unit.</p> <code>'us'</code> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import date\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"date\": [date(2001, 1, 1), None, date(2001, 1, 3)]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data, dtype=\"datetime64[ns]\")\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_timestamp(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"date\").dt.timestamp().alias(\"timestamp_us\"),\n...         nw.col(\"date\").dt.timestamp(\"ms\").alias(\"timestamp_ms\"),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_timestamp</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_timestamp(df_pd)\n        date  timestamp_us  timestamp_ms\n0 2001-01-01  9.783072e+14  9.783072e+11\n1        NaT           NaN           NaN\n2 2001-01-03  9.784800e+14  9.784800e+11\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_timestamp(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 date       \u2506 timestamp_us    \u2506 timestamp_ms \u2502\n\u2502 ---        \u2506 ---             \u2506 ---          \u2502\n\u2502 date       \u2506 i64             \u2506 i64          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2001-01-01 \u2506 978307200000000 \u2506 978307200000 \u2502\n\u2502 null       \u2506 null            \u2506 null         \u2502\n\u2502 2001-01-03 \u2506 978480000000000 \u2506 978480000000 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_timestamp(df_pa)\npyarrow.Table\ndate: date32[day]\ntimestamp_us: int64\ntimestamp_ms: int64\n----\ndate: [[2001-01-01,null,2001-01-03]]\ntimestamp_us: [[978307200000000,null,978480000000000]]\ntimestamp_ms: [[978307200000,null,978480000000]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.total_microseconds","title":"<code>total_microseconds()</code>","text":"<p>Get total microseconds.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>The function outputs the total microseconds in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> and <code>cast</code> in this case.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [\n...         timedelta(microseconds=10),\n...         timedelta(milliseconds=1, microseconds=200),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_total_microseconds(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         a_total_microseconds=nw.col(\"a\").dt.total_microseconds()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_total_microseconds</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_total_microseconds(df_pd)\n                       a  a_total_microseconds\n0 0 days 00:00:00.000010                    10\n1 0 days 00:00:00.001200                  1200\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_total_microseconds(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a            \u2506 a_total_microseconds \u2502\n\u2502 ---          \u2506 ---                  \u2502\n\u2502 duration[\u03bcs] \u2506 i64                  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 10\u00b5s         \u2506 10                   \u2502\n\u2502 1200\u00b5s       \u2506 1200                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_total_microseconds(df_pa)\npyarrow.Table\na: duration[us]\na_total_microseconds: int64\n----\na: [[10,1200]]\na_total_microseconds: [[10,1200]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.total_milliseconds","title":"<code>total_milliseconds()</code>","text":"<p>Get total milliseconds.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>The function outputs the total milliseconds in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> and <code>cast</code> in this case.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [\n...         timedelta(milliseconds=10),\n...         timedelta(milliseconds=20, microseconds=40),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_total_milliseconds(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         a_total_milliseconds=nw.col(\"a\").dt.total_milliseconds()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_total_milliseconds</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_total_milliseconds(df_pd)\n                       a  a_total_milliseconds\n0 0 days 00:00:00.010000                    10\n1 0 days 00:00:00.020040                    20\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_total_milliseconds(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a            \u2506 a_total_milliseconds \u2502\n\u2502 ---          \u2506 ---                  \u2502\n\u2502 duration[\u03bcs] \u2506 i64                  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 10ms         \u2506 10                   \u2502\n\u2502 20040\u00b5s      \u2506 20                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_total_milliseconds(df_pa)\npyarrow.Table\na: duration[us]\na_total_milliseconds: int64\n----\na: [[10000,20040]]\na_total_milliseconds: [[10,20]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.total_minutes","title":"<code>total_minutes()</code>","text":"<p>Get total minutes.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>The function outputs the total minutes in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> and <code>cast</code> in this case.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [timedelta(minutes=10), timedelta(minutes=20, seconds=40)]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_total_minutes(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         a_total_minutes=nw.col(\"a\").dt.total_minutes()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_total_minutes</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_total_minutes(df_pd)\n                a  a_total_minutes\n0 0 days 00:10:00               10\n1 0 days 00:20:40               20\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_total_minutes(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a            \u2506 a_total_minutes \u2502\n\u2502 ---          \u2506 ---             \u2502\n\u2502 duration[\u03bcs] \u2506 i64             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 10m          \u2506 10              \u2502\n\u2502 20m 40s      \u2506 20              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_total_minutes(df_pa)\npyarrow.Table\na: duration[us]\na_total_minutes: int64\n----\na: [[600000000,1240000000]]\na_total_minutes: [[10,20]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.total_nanoseconds","title":"<code>total_nanoseconds()</code>","text":"<p>Get total nanoseconds.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>The function outputs the total nanoseconds in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> and <code>cast</code> in this case.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = [\"2024-01-01 00:00:00.000000001\", \"2024-01-01 00:00:00.000000002\"]\n&gt;&gt;&gt; df_pd = pd.DataFrame({\"a\": pd.to_datetime(data)})\n&gt;&gt;&gt; df_pl = pl.DataFrame({\"a\": data}).with_columns(\n...     pl.col(\"a\").str.to_datetime(time_unit=\"ns\")\n... )\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_total_nanoseconds(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         a_diff_total_nanoseconds=nw.col(\"a\").diff().dt.total_nanoseconds()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_total_nanoseconds</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_total_nanoseconds(df_pd)\n                              a  a_diff_total_nanoseconds\n0 2024-01-01 00:00:00.000000001                       NaN\n1 2024-01-01 00:00:00.000000002                       1.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_total_nanoseconds(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a                             \u2506 a_diff_total_nanoseconds \u2502\n\u2502 ---                           \u2506 ---                      \u2502\n\u2502 datetime[ns]                  \u2506 i64                      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2024-01-01 00:00:00.000000001 \u2506 null                     \u2502\n\u2502 2024-01-01 00:00:00.000000002 \u2506 1                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.total_seconds","title":"<code>total_seconds()</code>","text":"<p>Get total seconds.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>The function outputs the total seconds in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> and <code>cast</code> in this case.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [timedelta(seconds=10), timedelta(seconds=20, milliseconds=40)]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_total_seconds(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         a_total_seconds=nw.col(\"a\").dt.total_seconds()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_total_seconds</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_total_seconds(df_pd)\n                       a  a_total_seconds\n0        0 days 00:00:10               10\n1 0 days 00:00:20.040000               20\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_total_seconds(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a            \u2506 a_total_seconds \u2502\n\u2502 ---          \u2506 ---             \u2502\n\u2502 duration[\u03bcs] \u2506 i64             \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 10s          \u2506 10              \u2502\n\u2502 20s 40ms     \u2506 20              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_total_seconds(df_pa)\npyarrow.Table\na: duration[us]\na_total_seconds: int64\n----\na: [[10000000,20040000]]\na_total_seconds: [[10,20]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.to_string","title":"<code>to_string(format)</code>","text":"<p>Convert a Date/Time/Datetime column into a String column with the given format.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Format to format temporal column with.</p> required <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>Unfortunately, different libraries interpret format directives a bit differently.</p> <ul> <li>Chrono, the library used by Polars, uses <code>\"%.f\"</code> for fractional seconds,   whereas pandas and Python stdlib use <code>\".%f\"</code>.</li> <li>PyArrow interprets <code>\"%S\"</code> as \"seconds, including fractional seconds\"   whereas most other tools interpret it as \"just seconds, as 2 digits\".</li> </ul> <p>Therefore, we make the following adjustments:</p> <ul> <li>for pandas-like libraries, we replace <code>\"%S.%f\"</code> with <code>\"%S%.f\"</code>.</li> <li>for PyArrow, we replace <code>\"%S.%f\"</code> with <code>\"%S\"</code>.</li> </ul> <p>Workarounds like these don't make us happy, and we try to avoid them as much as possible, but here we feel like it's the best compromise.</p> <p>If you just want to format a date/datetime Series as a local datetime string, and have it work as consistently as possible across libraries, we suggest using:</p> <ul> <li><code>\"%Y-%m-%dT%H:%M:%S%.f\"</code> for datetimes</li> <li><code>\"%Y-%m-%d\"</code> for dates</li> </ul> <p>though note that, even then, different tools may return a different number of trailing zeros. Nonetheless, this is probably consistent enough for most applications.</p> <p>If you have an application where this is not enough, please open an issue and let us know.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [\n...         datetime(2020, 3, 1),\n...         datetime(2020, 4, 1),\n...         datetime(2020, 5, 1),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_to_string(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\").dt.to_string(\"%Y/%m/%d %H:%M:%S\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_to_string</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_to_string(df_pd)\n                     a\n0  2020/03/01 00:00:00\n1  2020/04/01 00:00:00\n2  2020/05/01 00:00:00\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_to_string(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a                   \u2502\n\u2502 ---                 \u2502\n\u2502 str                 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2020/03/01 00:00:00 \u2502\n\u2502 2020/04/01 00:00:00 \u2502\n\u2502 2020/05/01 00:00:00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_to_string(df_pa)\npyarrow.Table\na: string\n----\na: [[\"2020/03/01 00:00:00.000000\",\"2020/04/01 00:00:00.000000\",\"2020/05/01 00:00:00.000000\"]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.weekday","title":"<code>weekday()</code>","text":"<p>Extract the week day from the underlying Date representation.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>Returns the ISO weekday number where monday = 1 and sunday = 7</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [datetime(2020, 1, 1), datetime(2020, 8, 3)]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_weekday(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(a_weekday=nw.col(\"a\").dt.weekday()).to_native()\n</code></pre> <p>We can then pass either pandas, Polars, PyArrow, and other supported libraries to <code>agnostic_dt_weekday</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_weekday(df_pd)\n           a  a_weekday\n0 2020-01-01          3\n1 2020-08-03          1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_weekday(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a                   \u2506 a_weekday \u2502\n\u2502 ---                 \u2506 ---       \u2502\n\u2502 datetime[\u03bcs]        \u2506 i8        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2020-01-01 00:00:00 \u2506 3         \u2502\n\u2502 2020-08-03 00:00:00 \u2506 1         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_weekday(df_pa)\npyarrow.Table\na: timestamp[us]\na_weekday: int64\n----\na: [[2020-01-01 00:00:00.000000,2020-08-03 00:00:00.000000]]\na_weekday: [[3,1]]\n</code></pre>"},{"location":"api-reference/expr_dt/#narwhals.expr.ExprDateTimeNamespace.year","title":"<code>year()</code>","text":"<p>Extract year from underlying DateTime representation.</p> <p>Returns the year number in the calendar date.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"datetime\": [\n...         datetime(1978, 6, 1),\n...         datetime(2024, 12, 13),\n...         datetime(2065, 1, 1),\n...     ]\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dt_year(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.col(\"datetime\").dt.year().alias(\"year\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dt_year</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dt_year(df_pd)\n    datetime  year\n0 1978-06-01  1978\n1 2024-12-13  2024\n2 2065-01-01  2065\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_year(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime            \u2506 year \u2502\n\u2502 ---                 \u2506 ---  \u2502\n\u2502 datetime[\u03bcs]        \u2506 i32  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1978-06-01 00:00:00 \u2506 1978 \u2502\n\u2502 2024-12-13 00:00:00 \u2506 2024 \u2502\n\u2502 2065-01-01 00:00:00 \u2506 2065 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dt_year(df_pa)\npyarrow.Table\ndatetime: timestamp[us]\nyear: int64\n----\ndatetime: [[1978-06-01 00:00:00.000000,2024-12-13 00:00:00.000000,2065-01-01 00:00:00.000000]]\nyear: [[1978,2024,2065]]\n</code></pre>"},{"location":"api-reference/expr_list/","title":"<code>narwhals.Expr.list</code>","text":""},{"location":"api-reference/expr_list/#narwhals.expr.ExprListNamespace.len","title":"<code>len()</code>","text":"<p>Return the number of elements in each list.</p> <p>Null values count towards the total.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [[1, 2], [3, 4, None], None, []]}\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_list_len(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(a_len=nw.col(\"a\").list.len()).to_native()\n</code></pre> <p>We can then pass pandas / PyArrow / Polars / any other supported library:</p> <pre><code>&gt;&gt;&gt; agnostic_list_len(\n...     pd.DataFrame(data).astype({\"a\": pd.ArrowDtype(pa.list_(pa.int64()))})\n... )\n               a  a_len\n0        [1. 2.]      2\n1  [ 3.  4. nan]      3\n2           &lt;NA&gt;   &lt;NA&gt;\n3             []      0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_list_len(pl.DataFrame(data))\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a            \u2506 a_len \u2502\n\u2502 ---          \u2506 ---   \u2502\n\u2502 list[i64]    \u2506 u32   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 [1, 2]       \u2506 2     \u2502\n\u2502 [3, 4, null] \u2506 3     \u2502\n\u2502 null         \u2506 null  \u2502\n\u2502 []           \u2506 0     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_list_len(pa.table(data))\npyarrow.Table\na: list&lt;item: int64&gt;\n  child 0, item: int64\na_len: uint32\n----\na: [[[1,2],[3,4,null],null,[]]]\na_len: [[2,3,null,0]]\n</code></pre>"},{"location":"api-reference/expr_name/","title":"<code>narwhals.Expr.name</code>","text":""},{"location":"api-reference/expr_name/#narwhals.expr.ExprNameNamespace.keep","title":"<code>keep()</code>","text":"<p>Keep the original root name of the expression.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>This will undo any previous renaming operations on the expression. Due to implementation constraints, this method can only be called as the last expression in a chain. Only one name operation per expression will work.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2], \"BAR\": [4, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_name_keep(df_native: IntoFrame) -&gt; list[str]:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"foo\").alias(\"alias_for_foo\").name.keep()).columns\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_name_keep</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_name_keep(df_pd)\n['foo']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_keep(df_pl)\n['foo']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_keep(df_pa)\n['foo']\n</code></pre>"},{"location":"api-reference/expr_name/#narwhals.expr.ExprNameNamespace.map","title":"<code>map(function)</code>","text":"<p>Rename the output of an expression by mapping a function over the root name.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>Callable[[str], str]</code> <p>Function that maps a root name to a new name.</p> required <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>This will undo any previous renaming operations on the expression. Due to implementation constraints, this method can only be called as the last expression in a chain. Only one name operation per expression will work.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2], \"BAR\": [4, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; renaming_func = lambda s: s[::-1]  # reverse column name\n&gt;&gt;&gt; def agnostic_name_map(df_native: IntoFrame) -&gt; list[str]:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"foo\", \"BAR\").name.map(renaming_func)).columns\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_name_map</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_name_map(df_pd)\n['oof', 'RAB']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_map(df_pl)\n['oof', 'RAB']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_map(df_pa)\n['oof', 'RAB']\n</code></pre>"},{"location":"api-reference/expr_name/#narwhals.expr.ExprNameNamespace.prefix","title":"<code>prefix(prefix)</code>","text":"<p>Add a prefix to the root column name of the expression.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Prefix to add to the root column name.</p> required <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>This will undo any previous renaming operations on the expression. Due to implementation constraints, this method can only be called as the last expression in a chain. Only one name operation per expression will work.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2], \"BAR\": [4, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_name_prefix(df_native: IntoFrame, prefix: str) -&gt; list[str]:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"foo\", \"BAR\").name.prefix(prefix)).columns\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_name_prefix</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_name_prefix(df_pd, \"with_prefix_\")\n['with_prefix_foo', 'with_prefix_BAR']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_prefix(df_pl, \"with_prefix_\")\n['with_prefix_foo', 'with_prefix_BAR']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_prefix(df_pa, \"with_prefix_\")\n['with_prefix_foo', 'with_prefix_BAR']\n</code></pre>"},{"location":"api-reference/expr_name/#narwhals.expr.ExprNameNamespace.suffix","title":"<code>suffix(suffix)</code>","text":"<p>Add a suffix to the root column name of the expression.</p> <p>Parameters:</p> Name Type Description Default <code>suffix</code> <code>str</code> <p>Suffix to add to the root column name.</p> required <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>This will undo any previous renaming operations on the expression. Due to implementation constraints, this method can only be called as the last expression in a chain. Only one name operation per expression will work.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2], \"BAR\": [4, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_name_suffix(df_native: IntoFrame, suffix: str) -&gt; list[str]:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"foo\", \"BAR\").name.suffix(suffix)).columns\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_name_suffix</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_name_suffix(df_pd, \"_with_suffix\")\n['foo_with_suffix', 'BAR_with_suffix']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_suffix(df_pl, \"_with_suffix\")\n['foo_with_suffix', 'BAR_with_suffix']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_suffix(df_pa, \"_with_suffix\")\n['foo_with_suffix', 'BAR_with_suffix']\n</code></pre>"},{"location":"api-reference/expr_name/#narwhals.expr.ExprNameNamespace.to_lowercase","title":"<code>to_lowercase()</code>","text":"<p>Make the root column name lowercase.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>This will undo any previous renaming operations on the expression. Due to implementation constraints, this method can only be called as the last expression in a chain. Only one name operation per expression will work.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2], \"BAR\": [4, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_name_to_lowercase(df_native: IntoFrame) -&gt; list[str]:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"foo\", \"BAR\").name.to_lowercase()).columns\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_name_to_lowercase</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_name_to_lowercase(df_pd)\n['foo', 'bar']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_to_lowercase(df_pl)\n['foo', 'bar']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_to_lowercase(df_pa)\n['foo', 'bar']\n</code></pre>"},{"location":"api-reference/expr_name/#narwhals.expr.ExprNameNamespace.to_uppercase","title":"<code>to_uppercase()</code>","text":"<p>Make the root column name uppercase.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>This will undo any previous renaming operations on the expression. Due to implementation constraints, this method can only be called as the last expression in a chain. Only one name operation per expression will work.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2], \"BAR\": [4, 5]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_name_to_uppercase(df_native: IntoFrame) -&gt; list[str]:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"foo\", \"BAR\").name.to_uppercase()).columns\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_name_to_uppercase</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_name_to_uppercase(df_pd)\n['FOO', 'BAR']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_to_uppercase(df_pl)\n['FOO', 'BAR']\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name_to_uppercase(df_pa)\n['FOO', 'BAR']\n</code></pre>"},{"location":"api-reference/expr_str/","title":"<code>narwhals.Expr.str</code>","text":""},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.contains","title":"<code>contains(pattern, *, literal=False)</code>","text":"<p>Check if string contains a substring that matches a pattern.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>A Character sequence or valid regular expression pattern.</p> required <code>literal</code> <code>bool</code> <p>If True, treats the pattern as a literal string.      If False, assumes the pattern is a regular expression.</p> <code>False</code> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"pets\": [\"cat\", \"dog\", \"rabbit and parrot\", \"dove\", None]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_contains(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         default_match=nw.col(\"pets\").str.contains(\"parrot|Dove\"),\n...         case_insensitive_match=nw.col(\"pets\").str.contains(\"(?i)parrot|Dove\"),\n...         literal_match=nw.col(\"pets\").str.contains(\n...             \"parrot|Dove\", literal=True\n...         ),\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_contains</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_contains(df_pd)\n                pets default_match case_insensitive_match literal_match\n0                cat         False                  False         False\n1                dog         False                  False         False\n2  rabbit and parrot          True                   True         False\n3               dove         False                   True         False\n4               None          None                   None          None\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_contains(df_pl)\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 pets              \u2506 default_match \u2506 case_insensitive_match \u2506 literal_match \u2502\n\u2502 ---               \u2506 ---           \u2506 ---                    \u2506 ---           \u2502\n\u2502 str               \u2506 bool          \u2506 bool                   \u2506 bool          \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 cat               \u2506 false         \u2506 false                  \u2506 false         \u2502\n\u2502 dog               \u2506 false         \u2506 false                  \u2506 false         \u2502\n\u2502 rabbit and parrot \u2506 true          \u2506 true                   \u2506 false         \u2502\n\u2502 dove              \u2506 false         \u2506 true                   \u2506 false         \u2502\n\u2502 null              \u2506 null          \u2506 null                   \u2506 null          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_contains(df_pa)\npyarrow.Table\npets: string\ndefault_match: bool\ncase_insensitive_match: bool\nliteral_match: bool\n----\npets: [[\"cat\",\"dog\",\"rabbit and parrot\",\"dove\",null]]\ndefault_match: [[false,false,true,false,null]]\ncase_insensitive_match: [[false,false,true,true,null]]\nliteral_match: [[false,false,false,false,null]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.ends_with","title":"<code>ends_with(suffix)</code>","text":"<p>Check if string values end with a substring.</p> <p>Parameters:</p> Name Type Description Default <code>suffix</code> <code>str</code> <p>suffix substring</p> required <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"fruits\": [\"apple\", \"mango\", None]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_ends_with(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         has_suffix=nw.col(\"fruits\").str.ends_with(\"ngo\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_ends_with</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_ends_with(df_pd)\n  fruits has_suffix\n0  apple      False\n1  mango       True\n2   None       None\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_ends_with(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 fruits \u2506 has_suffix \u2502\n\u2502 ---    \u2506 ---        \u2502\n\u2502 str    \u2506 bool       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 apple  \u2506 false      \u2502\n\u2502 mango  \u2506 true       \u2502\n\u2502 null   \u2506 null       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_ends_with(df_pa)\npyarrow.Table\nfruits: string\nhas_suffix: bool\n----\nfruits: [[\"apple\",\"mango\",null]]\nhas_suffix: [[false,true,null]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.head","title":"<code>head(n=5)</code>","text":"<p>Take the first n elements of each string.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of elements to take. Negative indexing is not supported.</p> <code>5</code> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>If the length of the string has fewer than <code>n</code> characters, the full string is returned.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"lyrics\": [\"Atatata\", \"taata\", \"taatatata\", \"zukkyun\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_head(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         lyrics_head=nw.col(\"lyrics\").str.head()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_head</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_head(df_pd)\n      lyrics lyrics_head\n0    Atatata       Atata\n1      taata       taata\n2  taatatata       taata\n3    zukkyun       zukky\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_head(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 lyrics    \u2506 lyrics_head \u2502\n\u2502 ---       \u2506 ---         \u2502\n\u2502 str       \u2506 str         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Atatata   \u2506 Atata       \u2502\n\u2502 taata     \u2506 taata       \u2502\n\u2502 taatatata \u2506 taata       \u2502\n\u2502 zukkyun   \u2506 zukky       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_head(df_pa)\npyarrow.Table\nlyrics: string\nlyrics_head: string\n----\nlyrics: [[\"Atatata\",\"taata\",\"taatatata\",\"zukkyun\"]]\nlyrics_head: [[\"Atata\",\"taata\",\"taata\",\"zukky\"]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.len_chars","title":"<code>len_chars()</code>","text":"<p>Return the length of each string as the number of characters.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"words\": [\"foo\", \"Caf\u00e9\", \"345\", \"\u6771\u4eac\", None]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_len_chars(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         words_len=nw.col(\"words\").str.len_chars()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_len_chars</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_len_chars(df_pd)\n  words  words_len\n0   foo        3.0\n1  Caf\u00e9        4.0\n2   345        3.0\n3    \u6771\u4eac        2.0\n4  None        NaN\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_len_chars(df_pl)\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 words \u2506 words_len \u2502\n\u2502 ---   \u2506 ---       \u2502\n\u2502 str   \u2506 u32       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 foo   \u2506 3         \u2502\n\u2502 Caf\u00e9  \u2506 4         \u2502\n\u2502 345   \u2506 3         \u2502\n\u2502 \u6771\u4eac  \u2506 2         \u2502\n\u2502 null  \u2506 null      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_len_chars(df_pa)\npyarrow.Table\nwords: string\nwords_len: int32\n----\nwords: [[\"foo\",\"Caf\u00e9\",\"345\",\"\u6771\u4eac\",null]]\nwords_len: [[3,4,3,2,null]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.replace","title":"<code>replace(pattern, value, *, literal=False, n=1)</code>","text":"<p>Replace first matching regex/literal substring with a new string value.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>A valid regular expression pattern.</p> required <code>value</code> <code>str</code> <p>String that will replace the matched substring.</p> required <code>literal</code> <code>bool</code> <p>Treat <code>pattern</code> as a literal string.</p> <code>False</code> <code>n</code> <code>int</code> <p>Number of matches to replace.</p> <code>1</code> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [\"123abc\", \"abc abc123\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_replace(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     df = df.with_columns(replaced=nw.col(\"foo\").str.replace(\"abc\", \"\"))\n...     return df.to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_replace</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_replace(df_pd)\n          foo replaced\n0      123abc      123\n1  abc abc123   abc123\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_replace(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo        \u2506 replaced \u2502\n\u2502 ---        \u2506 ---      \u2502\n\u2502 str        \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 123abc     \u2506 123      \u2502\n\u2502 abc abc123 \u2506  abc123  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_replace(df_pa)\npyarrow.Table\nfoo: string\nreplaced: string\n----\nfoo: [[\"123abc\",\"abc abc123\"]]\nreplaced: [[\"123\",\" abc123\"]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.replace_all","title":"<code>replace_all(pattern, value, *, literal=False)</code>","text":"<p>Replace all matching regex/literal substring with a new string value.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>A valid regular expression pattern.</p> required <code>value</code> <code>str</code> <p>String that will replace the matched substring.</p> required <code>literal</code> <code>bool</code> <p>Treat <code>pattern</code> as a literal string.</p> <code>False</code> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [\"123abc\", \"abc abc123\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_replace_all(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     df = df.with_columns(replaced=nw.col(\"foo\").str.replace_all(\"abc\", \"\"))\n...     return df.to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_replace_all</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_replace_all(df_pd)\n          foo replaced\n0      123abc      123\n1  abc abc123      123\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_replace_all(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo        \u2506 replaced \u2502\n\u2502 ---        \u2506 ---      \u2502\n\u2502 str        \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 123abc     \u2506 123      \u2502\n\u2502 abc abc123 \u2506  123     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_replace_all(df_pa)\npyarrow.Table\nfoo: string\nreplaced: string\n----\nfoo: [[\"123abc\",\"abc abc123\"]]\nreplaced: [[\"123\",\" 123\"]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.slice","title":"<code>slice(offset, length=None)</code>","text":"<p>Create subslices of the string values of an expression.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>int</code> <p>Start index. Negative indexing is supported.</p> required <code>length</code> <code>int | None</code> <p>Length of the slice. If set to <code>None</code> (default), the slice is taken to the end of the string.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"s\": [\"pear\", None, \"papaya\", \"dragonfruit\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_slice(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         s_sliced=nw.col(\"s\").str.slice(4, length=3)\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_slice</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_slice(df_pd)\n             s s_sliced\n0         pear\n1         None     None\n2       papaya       ya\n3  dragonfruit      onf\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_slice(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 s           \u2506 s_sliced \u2502\n\u2502 ---         \u2506 ---      \u2502\n\u2502 str         \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 pear        \u2506          \u2502\n\u2502 null        \u2506 null     \u2502\n\u2502 papaya      \u2506 ya       \u2502\n\u2502 dragonfruit \u2506 onf      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_slice(df_pa)\npyarrow.Table\ns: string\ns_sliced: string\n----\ns: [[\"pear\",null,\"papaya\",\"dragonfruit\"]]\ns_sliced: [[\"\",null,\"ya\",\"onf\"]]\n</code></pre> <p>Using negative indexes:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_slice_negative(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(s_sliced=nw.col(\"s\").str.slice(-3)).to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_slice_negative(df_pd)\n             s s_sliced\n0         pear      ear\n1         None     None\n2       papaya      aya\n3  dragonfruit      uit\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_slice_negative(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 s           \u2506 s_sliced \u2502\n\u2502 ---         \u2506 ---      \u2502\n\u2502 str         \u2506 str      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 pear        \u2506 ear      \u2502\n\u2502 null        \u2506 null     \u2502\n\u2502 papaya      \u2506 aya      \u2502\n\u2502 dragonfruit \u2506 uit      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_slice_negative(df_pa)\npyarrow.Table\ns: string\ns_sliced: string\n----\ns: [[\"pear\",null,\"papaya\",\"dragonfruit\"]]\ns_sliced: [[\"ear\",null,\"aya\",\"uit\"]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.starts_with","title":"<code>starts_with(prefix)</code>","text":"<p>Check if string values start with a substring.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>prefix substring</p> required <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"fruits\": [\"apple\", \"mango\", None]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_starts_with(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         has_prefix=nw.col(\"fruits\").str.starts_with(\"app\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_starts_with</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_starts_with(df_pd)\n  fruits has_prefix\n0  apple       True\n1  mango      False\n2   None       None\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_starts_with(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 fruits \u2506 has_prefix \u2502\n\u2502 ---    \u2506 ---        \u2502\n\u2502 str    \u2506 bool       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 apple  \u2506 true       \u2502\n\u2502 mango  \u2506 false      \u2502\n\u2502 null   \u2506 null       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_starts_with(df_pa)\npyarrow.Table\nfruits: string\nhas_prefix: bool\n----\nfruits: [[\"apple\",\"mango\",null]]\nhas_prefix: [[true,false,null]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.strip_chars","title":"<code>strip_chars(characters=None)</code>","text":"<p>Remove leading and trailing characters.</p> <p>Parameters:</p> Name Type Description Default <code>characters</code> <code>str | None</code> <p>The set of characters to be removed. All combinations of this set of characters will be stripped from the start and end of the string. If set to None (default), all leading and trailing whitespace is removed instead.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from typing import Any\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"fruits\": [\"apple\", \"\\nmango\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_strip_chars(df_native: IntoFrame) -&gt; dict[str, Any]:\n...     df = nw.from_native(df_native)\n...     df = df.with_columns(stripped=nw.col(\"fruits\").str.strip_chars())\n...     return df.to_dict(as_series=False)\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_strip_chars</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_strip_chars(df_pd)\n{'fruits': ['apple', '\\nmango'], 'stripped': ['apple', 'mango']}\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_strip_chars(df_pl)\n{'fruits': ['apple', '\\nmango'], 'stripped': ['apple', 'mango']}\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_strip_chars(df_pa)\n{'fruits': ['apple', '\\nmango'], 'stripped': ['apple', 'mango']}\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.tail","title":"<code>tail(n=5)</code>","text":"<p>Take the last n elements of each string.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of elements to take. Negative indexing is not supported.</p> <code>5</code> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>If the length of the string has fewer than <code>n</code> characters, the full string is returned.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"lyrics\": [\"Atatata\", \"taata\", \"taatatata\", \"zukkyun\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_tail(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         lyrics_tail=nw.col(\"lyrics\").str.tail()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_tail</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_tail(df_pd)\n      lyrics lyrics_tail\n0    Atatata       atata\n1      taata       taata\n2  taatatata       atata\n3    zukkyun       kkyun\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_tail(df_pl)\nshape: (4, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 lyrics    \u2506 lyrics_tail \u2502\n\u2502 ---       \u2506 ---         \u2502\n\u2502 str       \u2506 str         \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 Atatata   \u2506 atata       \u2502\n\u2502 taata     \u2506 taata       \u2502\n\u2502 taatatata \u2506 atata       \u2502\n\u2502 zukkyun   \u2506 kkyun       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_tail(df_pa)\npyarrow.Table\nlyrics: string\nlyrics_tail: string\n----\nlyrics: [[\"Atatata\",\"taata\",\"taatatata\",\"zukkyun\"]]\nlyrics_tail: [[\"atata\",\"taata\",\"atata\",\"kkyun\"]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.to_datetime","title":"<code>to_datetime(format=None)</code>","text":"<p>Convert to Datetime dtype.</p> Warning <p>As different backends auto-infer format in different ways, if <code>format=None</code> there is no guarantee that the result will be equal.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str | None</code> <p>Format to use for conversion. If set to None (default), the format is inferred from the data.</p> <code>None</code> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>pandas defaults to nanosecond time unit, Polars to microsecond. Prior to pandas 2.0, nanoseconds were the only time unit supported in pandas, with no ability to set any other one. The ability to set the time unit in pandas, if the version permits, will arrive.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = [\"2020-01-01\", \"2020-01-02\"]\n&gt;&gt;&gt; df_pd = pd.DataFrame({\"a\": data})\n&gt;&gt;&gt; df_pl = pl.DataFrame({\"a\": data})\n&gt;&gt;&gt; df_pa = pa.table({\"a\": data})\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_to_datetime(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.col(\"a\").str.to_datetime(format=\"%Y-%m-%d\")\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_to_datetime</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_to_datetime(df_pd)\n           a\n0 2020-01-01\n1 2020-01-02\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_to_datetime(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a                   \u2502\n\u2502 ---                 \u2502\n\u2502 datetime[\u03bcs]        \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2020-01-01 00:00:00 \u2502\n\u2502 2020-01-02 00:00:00 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_to_datetime(df_pa)\npyarrow.Table\na: timestamp[us]\n----\na: [[2020-01-01 00:00:00.000000,2020-01-02 00:00:00.000000]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.to_lowercase","title":"<code>to_lowercase()</code>","text":"<p>Transform string to lowercase variant.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"fruits\": [\"APPLE\", \"MANGO\", None]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_to_lowercase(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         lower_col=nw.col(\"fruits\").str.to_lowercase()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_to_lowercase</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_to_lowercase(df_pd)\n  fruits lower_col\n0  APPLE     apple\n1  MANGO     mango\n2   None      None\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_to_lowercase(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 fruits \u2506 lower_col \u2502\n\u2502 ---    \u2506 ---       \u2502\n\u2502 str    \u2506 str       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 APPLE  \u2506 apple     \u2502\n\u2502 MANGO  \u2506 mango     \u2502\n\u2502 null   \u2506 null      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_to_lowercase(df_pa)\npyarrow.Table\nfruits: string\nlower_col: string\n----\nfruits: [[\"APPLE\",\"MANGO\",null]]\nlower_col: [[\"apple\",\"mango\",null]]\n</code></pre>"},{"location":"api-reference/expr_str/#narwhals.expr.ExprStringNamespace.to_uppercase","title":"<code>to_uppercase()</code>","text":"<p>Transform string to uppercase variant.</p> <p>Returns:</p> Type Description <code>ExprT</code> <p>A new expression.</p> Notes <p>The PyArrow backend will convert '\u00df' to '\u1e9e' instead of 'SS'. For more info see the related issue. There may be other unicode-edge-case-related variations across implementations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"fruits\": [\"apple\", \"mango\", None]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_str_to_uppercase(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         upper_col=nw.col(\"fruits\").str.to_uppercase()\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_str_to_uppercase</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_str_to_uppercase(df_pd)\n  fruits upper_col\n0  apple     APPLE\n1  mango     MANGO\n2   None      None\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_to_uppercase(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 fruits \u2506 upper_col \u2502\n\u2502 ---    \u2506 ---       \u2502\n\u2502 str    \u2506 str       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 apple  \u2506 APPLE     \u2502\n\u2502 mango  \u2506 MANGO     \u2502\n\u2502 null   \u2506 null      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_str_to_uppercase(df_pa)\npyarrow.Table\nfruits: string\nupper_col: string\n----\nfruits: [[\"apple\",\"mango\",null]]\nupper_col: [[\"APPLE\",\"MANGO\",null]]\n</code></pre>"},{"location":"api-reference/group_by/","title":"<code>narwhals.GroupBy</code>","text":""},{"location":"api-reference/group_by/#narwhals.group_by.GroupBy.agg","title":"<code>agg(*aggs, **named_aggs)</code>","text":"<p>Compute aggregations for each group of a group by operation.</p> <p>Parameters:</p> Name Type Description Default <code>aggs</code> <code>Expr | Iterable[Expr]</code> <p>Aggregations to compute for each group of the group by operation, specified as positional arguments.</p> <code>()</code> <code>named_aggs</code> <code>Expr</code> <p>Additional aggregations, specified as keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrameT</code> <p>A new Dataframe.</p> <p>Examples:</p> <p>Group by one column or by multiple columns and call <code>agg</code> to compute the grouped sum of another column.</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; df_pd = pd.DataFrame(\n...     {\n...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n...         \"b\": [1, 2, 1, 3, 3],\n...         \"c\": [5, 4, 3, 2, 1],\n...     }\n... )\n&gt;&gt;&gt; df_pl = pl.DataFrame(\n...     {\n...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n...         \"b\": [1, 2, 1, 3, 3],\n...         \"c\": [5, 4, 3, 2, 1],\n...     }\n... )\n</code></pre> <p>We define library agnostic functions:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def func(df):\n...     return df.group_by(\"a\").agg(nw.col(\"b\").sum()).sort(\"a\")\n</code></pre> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def func_mult_col(df):\n...     return df.group_by(\"a\", \"b\").agg(nw.sum(\"c\")).sort(\"a\", \"b\")\n</code></pre> <p>We can then pass either pandas or Polars to <code>func</code> and <code>func_mult_col</code>:</p> <pre><code>&gt;&gt;&gt; func(df_pd)\n   a  b\n0  a  2\n1  b  5\n2  c  3\n&gt;&gt;&gt; func(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 2   \u2502\n\u2502 b   \u2506 5   \u2502\n\u2502 c   \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; func_mult_col(df_pd)\n   a  b  c\n0  a  1  8\n1  b  2  4\n2  b  3  2\n3  c  3  1\n&gt;&gt;&gt; func_mult_col(df_pl)\nshape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1   \u2506 8   \u2502\n\u2502 b   \u2506 2   \u2506 4   \u2502\n\u2502 b   \u2506 3   \u2506 2   \u2502\n\u2502 c   \u2506 3   \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/lazy_group_by/","title":"<code>narwhals.LazyGroupBy</code>","text":""},{"location":"api-reference/lazy_group_by/#narwhals.group_by.LazyGroupBy.agg","title":"<code>agg(*aggs, **named_aggs)</code>","text":"<p>Compute aggregations for each group of a group by operation.</p> <p>If a library does not support lazy execution, then this is a no-op.</p> <p>Parameters:</p> Name Type Description Default <code>aggs</code> <code>Expr | Iterable[Expr]</code> <p>Aggregations to compute for each group of the group by operation, specified as positional arguments.</p> <code>()</code> <code>named_aggs</code> <code>Expr</code> <p>Additional aggregations, specified as keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LazyFrameT</code> <p>A new LazyFrame.</p> <p>Examples:</p> <p>Group by one column or by multiple columns and call <code>agg</code> to compute the grouped sum of another column.</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(\n...     {\n...         \"a\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n...         \"b\": [1, 2, 1, 3, 3],\n...         \"c\": [5, 4, 3, 2, 1],\n...     }\n... )\n</code></pre> <p>We define library agnostic functions:</p> <pre><code>&gt;&gt;&gt; def agnostic_func_one_col(lf_native: IntoFrameT) -&gt; IntoFrameT:\n...     lf = nw.from_native(lf_native)\n...     return nw.to_native(lf.group_by(\"a\").agg(nw.col(\"b\").sum()).sort(\"a\"))\n</code></pre> <pre><code>&gt;&gt;&gt; def agnostic_func_mult_col(lf_native: IntoFrameT) -&gt; IntoFrameT:\n...     lf = nw.from_native(lf_native)\n...     return nw.to_native(lf.group_by(\"a\", \"b\").agg(nw.sum(\"c\")).sort(\"a\", \"b\"))\n</code></pre> <p>We can then pass a lazy frame and materialise it with <code>collect</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_func_one_col(lf_pl).collect()\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 2   \u2502\n\u2502 b   \u2506 5   \u2502\n\u2502 c   \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_func_mult_col(lf_pl).collect()\nshape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1   \u2506 8   \u2502\n\u2502 b   \u2506 2   \u2506 4   \u2502\n\u2502 b   \u2506 3   \u2506 2   \u2502\n\u2502 c   \u2506 3   \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/lazyframe/","title":"<code>narwhals.LazyFrame</code>","text":"<p>Narwhals LazyFrame, backed by a native lazyframe.</p> <p>Warning</p> <p>This class is not meant to be instantiated directly - instead use <code>narwhals.from_native</code> with a native object that is a lazy dataframe from one of the supported backend (e.g. polars.LazyFrame, dask_expr._collection.DataFrame): <pre><code>narwhals.from_native(native_lazyframe)\n</code></pre></p>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.columns","title":"<code>columns</code>  <code>property</code>","text":"<p>Get column names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>The column names stored in a list.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_columns(df_native: IntoFrame) -&gt; list[str]:\n...     df = nw.from_native(df_native)\n...     return df.columns\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_columns</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_columns(lf_pl)\n['foo', 'bar', 'ham']\n&gt;&gt;&gt; agnostic_columns(lf_dask)\n['foo', 'bar', 'ham']\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.implementation","title":"<code>implementation</code>  <code>property</code>","text":"<p>Return implementation of native frame.</p> <p>This can be useful when you need to use special-casing for features outside of Narwhals' scope - for example, when dealing with pandas' Period Dtype.</p> <p>Returns:</p> Type Description <code>Implementation</code> <p>Implementation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; lf_pl = pl.LazyFrame({\"a\": [1, 2, 3]})\n&gt;&gt;&gt; lf_dask = dd.from_dict({\"a\": [1, 2, 3]}, npartitions=2)\n</code></pre> <pre><code>&gt;&gt;&gt; lf = nw.from_native(lf_pl)\n&gt;&gt;&gt; lf.implementation\n&lt;Implementation.POLARS: 6&gt;\n&gt;&gt;&gt; lf.implementation.is_pandas()\nFalse\n&gt;&gt;&gt; lf.implementation.is_polars()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; lf = nw.from_native(lf_dask)\n&gt;&gt;&gt; lf.implementation\n&lt;Implementation.DASK: 7&gt;\n&gt;&gt;&gt; lf.implementation.is_dask()\nTrue\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.schema","title":"<code>schema</code>  <code>property</code>","text":"<p>Get an ordered mapping of column names to their data type.</p> <p>Returns:</p> Type Description <code>Schema</code> <p>A Narwhals Schema object that displays the mapping of column names.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6.0, 7.0, 8.0],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <pre><code>&gt;&gt;&gt; lf = nw.from_native(lf_pl)\n&gt;&gt;&gt; lf.schema\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n</code></pre> <pre><code>&gt;&gt;&gt; lf = nw.from_native(lf_dask)\n&gt;&gt;&gt; lf.schema\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.clone","title":"<code>clone()</code>","text":"<p>Create a copy of this DataFrame.</p> <p>Returns:</p> Type Description <code>Self</code> <p>An identical copy of the original LazyFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [3, 4]}\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we copy the DataFrame:</p> <pre><code>&gt;&gt;&gt; def agnostic_clone(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.clone().collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars to <code>agnostic_clone</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_clone(lf_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 3   \u2502\n\u2502 2   \u2506 4   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.collect","title":"<code>collect()</code>","text":"<p>Materialize this LazyFrame into a DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame[Any]</code> <p>DataFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; data = {\n...     \"a\": [\"a\", \"b\", \"a\", \"b\", \"b\", \"c\"],\n...     \"b\": [1, 2, 3, 4, 5, 6],\n...     \"c\": [6, 5, 4, 3, 2, 1],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <pre><code>&gt;&gt;&gt; lf = nw.from_native(lf_pl)\n&gt;&gt;&gt; lf\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n|     Narwhals LazyFrame      |\n|-----------------------------|\n|&lt;LazyFrame at ...\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; df = lf.group_by(\"a\").agg(nw.all().sum()).collect()\n&gt;&gt;&gt; df.to_native().sort(\"a\")\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 4   \u2506 10  \u2502\n\u2502 b   \u2506 11  \u2506 10  \u2502\n\u2502 c   \u2506 6   \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; lf = nw.from_native(lf_dask)\n&gt;&gt;&gt; lf\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n|        Narwhals LazyFrame         |\n|-----------------------------------|\n|Dask DataFrame Structure:          |\n|                    a      b      c|\n|npartitions=2                      |\n|0              string  int64  int64|\n|3                 ...    ...    ...|\n|5                 ...    ...    ...|\n|Dask Name: frompandas, 1 expression|\n|Expr=df                            |\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; df = lf.group_by(\"a\").agg(nw.col(\"b\", \"c\").sum()).collect()\n&gt;&gt;&gt; df.to_native()\n   a   b   c\n0  a   4  10\n1  b  11  10\n2  c   6   1\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.collect_schema","title":"<code>collect_schema()</code>","text":"<p>Get an ordered mapping of column names to their data type.</p> <p>Returns:</p> Type Description <code>Schema</code> <p>A Narwhals Schema object that displays the mapping of column names.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6.0, 7.0, 8.0],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <pre><code>&gt;&gt;&gt; lf = nw.from_native(lf_pl)\n&gt;&gt;&gt; lf.collect_schema()\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n</code></pre> <pre><code>&gt;&gt;&gt; lf = nw.from_native(lf_dask)\n&gt;&gt;&gt; lf.collect_schema()\nSchema({'foo': Int64, 'bar': Float64, 'ham': String})\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.drop","title":"<code>drop(*columns, strict=True)</code>","text":"<p>Remove columns from the LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>*columns</code> <code>str | Iterable[str]</code> <p>Names of the columns that should be removed from the dataframe.</p> <code>()</code> <code>strict</code> <code>bool</code> <p>Validate that all column names exist in the schema and throw an exception if a column name does not exist in the schema.</p> <code>True</code> <p>Returns:</p> Type Description <code>Self</code> <p>The LazyFrame with the specified columns removed.</p> Warning <p><code>strict</code> argument is ignored for <code>polars&lt;1.0.0</code>.</p> <p>Please consider upgrading to a newer version or pass to eager mode.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_drop(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.drop(\"ham\").collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_drop</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_drop(lf_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6.0 \u2502\n\u2502 2   \u2506 7.0 \u2502\n\u2502 3   \u2506 8.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_drop(lf_dask)\n   foo  bar\n0    1  6.0\n1    2  7.0\n2    3  8.0\n</code></pre> <p>Use positional arguments to drop multiple columns.</p> <pre><code>&gt;&gt;&gt; def agnostic_drop(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.drop(\"foo\", \"ham\").collect().to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_drop(lf_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 bar \u2502\n\u2502 --- \u2502\n\u2502 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 6.0 \u2502\n\u2502 7.0 \u2502\n\u2502 8.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_drop(lf_dask)\n   bar\n0  6.0\n1  7.0\n2  8.0\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.drop_nulls","title":"<code>drop_nulls(subset=None)</code>","text":"<p>Drop rows that contain null values.</p> <p>Parameters:</p> Name Type Description Default <code>subset</code> <code>str | list[str] | None</code> <p>Column name(s) for which null values are considered. If set to None (default), use all columns.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The original object with the rows removed that contained the null values.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1.0, 2.0, None], \"ba\": [1.0, None, 2.0]}\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_drop_nulls(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.drop_nulls().collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_drop_nulls</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_drop_nulls(lf_pl)\nshape: (1, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 ba  \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 f64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.0 \u2506 1.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_drop_nulls(lf_dask)\n     a   ba\n0  1.0  1.0\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.explode","title":"<code>explode(columns, *more_columns)</code>","text":"<p>Explode the dataframe to long format by exploding the given columns.</p> Notes <p>It is possible to explode multiple columns only if these columns have matching element counts.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str | Sequence[str]</code> <p>Column names. The underlying columns being exploded must be of the <code>List</code> data type.</p> required <code>*more_columns</code> <code>str</code> <p>Additional names of columns to explode, specified as positional arguments.</p> <code>()</code> <p>Returns:</p> Type Description <code>Self</code> <p>New LazyFrame</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; data = {\n...     \"a\": [\"x\", \"y\", \"z\", \"w\"],\n...     \"lst1\": [[1, 2], None, [None], []],\n...     \"lst2\": [[3, None], None, [42], []],\n... }\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_explode(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     return (\n...         nw.from_native(df_native)\n...         .with_columns(nw.col(\"lst1\", \"lst2\").cast(nw.List(nw.Int32())))\n...         .explode(\"lst1\", \"lst2\")\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <p>We can then pass any supported library such as Polars to <code>agnostic_explode</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_explode(pl.LazyFrame(data))\nshape: (5, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 lst1 \u2506 lst2 \u2502\n\u2502 --- \u2506 ---  \u2506 ---  \u2502\n\u2502 str \u2506 i32  \u2506 i32  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 x   \u2506 1    \u2506 3    \u2502\n\u2502 x   \u2506 2    \u2506 null \u2502\n\u2502 y   \u2506 null \u2506 null \u2502\n\u2502 z   \u2506 null \u2506 42   \u2502\n\u2502 w   \u2506 null \u2506 null \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.filter","title":"<code>filter(*predicates, **constraints)</code>","text":"<p>Filter the rows in the LazyFrame based on a predicate expression.</p> <p>The original order of the remaining rows is preserved.</p> <p>Parameters:</p> Name Type Description Default <code>*predicates</code> <code>IntoExpr | Iterable[IntoExpr] | list[bool]</code> <p>Expression that evaluates to a boolean Series. Can also be a (single!) boolean list.</p> <code>()</code> <code>**constraints</code> <code>Any</code> <p>Column filters; use <code>name = value</code> to filter columns by the supplied value. Each constraint will behave the same as <code>nw.col(name).eq(value)</code>, and will be implicitly joined with the other filter conditions using &amp;.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The filtered LazyFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6, 7, 8],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we filter on one condition.</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.filter(nw.col(\"foo\") &gt; 1).collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_filter</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_filter(lf_pl)\nshape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 7   \u2506 b   \u2502\n\u2502 3   \u2506 8   \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(lf_dask)\n   foo  bar ham\n1    2    7   b\n2    3    8   c\n</code></pre> <p>Filter on multiple conditions:</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return (\n...         df.filter((nw.col(\"foo\") &lt; 3) &amp; (nw.col(\"ham\") == \"a\"))\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_filter(lf_pl)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6   \u2506 a   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(lf_dask)\n   foo  bar ham\n0    1    6   a\n</code></pre> <p>Provide multiple filters using <code>*args</code> syntax:</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return (\n...         df.filter(\n...             nw.col(\"foo\") == 1,\n...             nw.col(\"ham\") == \"a\",\n...         )\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_filter(lf_pl)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6   \u2506 a   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(lf_dask)\n   foo  bar ham\n0    1    6   a\n</code></pre> <p>Filter on an OR condition:</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return (\n...         df.filter((nw.col(\"foo\") == 1) | (nw.col(\"ham\") == \"c\"))\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_filter(lf_pl)\nshape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6   \u2506 a   \u2502\n\u2502 3   \u2506 8   \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(lf_dask)\n   foo  bar ham\n0    1    6   a\n2    3    8   c\n</code></pre> <p>Provide multiple filters using <code>**kwargs</code> syntax:</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.filter(foo=2, ham=\"b\").collect().to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_filter(lf_pl)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 7   \u2506 b   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_filter(lf_dask)\n   foo  bar ham\n1    2    7   b\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.gather_every","title":"<code>gather_every(n, offset=0)</code>","text":"<p>Take every nth row in the DataFrame and return as a new DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Gather every n-th row.</p> required <code>offset</code> <code>int</code> <p>Starting index.</p> <code>0</code> <p>Returns:</p> Type Description <code>Self</code> <p>The LazyFrame containing only the selected rows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3, 4], \"b\": [5, 6, 7, 8]}\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we gather every 2 rows, starting from a offset of 1:</p> <pre><code>&gt;&gt;&gt; def agnostic_gather_every(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.gather_every(n=2, offset=1).collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_gather_every</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_gather_every(lf_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 6   \u2502\n\u2502 4   \u2506 8   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_gather_every(lf_dask)\n   a  b\n1  2  6\n3  4  8\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.group_by","title":"<code>group_by(*keys, drop_null_keys=False)</code>","text":"<p>Start a group by operation.</p> <p>Parameters:</p> Name Type Description Default <code>*keys</code> <code>str | Iterable[str]</code> <p>Column(s) to group by. Accepts expression input. Strings are parsed as column names.</p> <code>()</code> <code>drop_null_keys</code> <code>bool</code> <p>if True, then groups where any key is null won't be included in the result.</p> <code>False</code> <p>Returns:</p> Type Description <code>LazyGroupBy[Self]</code> <p>Object which can be used to perform aggregations.</p> <p>Examples:</p> <p>Group by one column and call <code>agg</code> to compute the grouped sum of another column.</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [\"a\", \"b\", \"a\", \"b\", \"c\"],\n...     \"b\": [1, 2, 1, 3, 3],\n...     \"c\": [5, 4, 3, 2, 1],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we group by one column and call <code>agg</code> to compute the grouped sum of another column.</p> <pre><code>&gt;&gt;&gt; def agnostic_group_by_agg(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return (\n...         df.group_by(\"a\")\n...         .agg(nw.col(\"b\").sum())\n...         .sort(\"a\")\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_group_by_agg</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_group_by_agg(lf_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 2   \u2502\n\u2502 b   \u2506 5   \u2502\n\u2502 c   \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_group_by_agg(lf_dask)\n   a  b\n0  a  2\n1  b  5\n2  c  3\n</code></pre> <p>Group by multiple columns by passing a list of column names.</p> <pre><code>&gt;&gt;&gt; def agnostic_group_by_agg(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return (\n...         df.group_by([\"a\", \"b\"])\n...         .agg(nw.max(\"c\"))\n...         .sort([\"a\", \"b\"])\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_group_by_agg(lf_pl)\nshape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 str \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 a   \u2506 1   \u2506 5   \u2502\n\u2502 b   \u2506 2   \u2506 4   \u2502\n\u2502 b   \u2506 3   \u2506 2   \u2502\n\u2502 c   \u2506 3   \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_group_by_agg(lf_dask)\n   a  b  c\n0  a  1  5\n1  b  2  4\n2  b  3  2\n3  c  3  1\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.head","title":"<code>head(n=5)</code>","text":"<p>Get <code>n</code> rows.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to return.</p> <code>5</code> <p>Returns:</p> Type Description <code>Self</code> <p>A subset of the LazyFrame of shape (n, n_columns).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 2, 3, 4, 5, 6],\n...     \"b\": [7, 8, 9, 10, 11, 12],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function that gets the first 3 rows.</p> <pre><code>&gt;&gt;&gt; def agnostic_head(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.head(3).collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_head</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_head(lf_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 7   \u2502\n\u2502 2   \u2506 8   \u2502\n\u2502 3   \u2506 9   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_head(lf_dask)\n   a  b\n0  1  7\n1  2  8\n2  3  9\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.join","title":"<code>join(other, on=None, how='inner', *, left_on=None, right_on=None, suffix='_right')</code>","text":"<p>Add a join operation to the Logical Plan.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Self</code> <p>Lazy DataFrame to join with.</p> required <code>on</code> <code>str | list[str] | None</code> <p>Name(s) of the join columns in both DataFrames. If set, <code>left_on</code> and <code>right_on</code> should be None.</p> <code>None</code> <code>how</code> <code>Literal['inner', 'left', 'cross', 'semi', 'anti']</code> <p>Join strategy.</p> <ul> <li>inner: Returns rows that have matching values in both tables.</li> <li>left: Returns all rows from the left table, and the matched rows from the right table.</li> <li>cross: Returns the Cartesian product of rows from both tables.</li> <li>semi: Filter rows that have a match in the right table.</li> <li>anti: Filter rows that do not have a match in the right table.</li> </ul> <code>'inner'</code> <code>left_on</code> <code>str | list[str] | None</code> <p>Join column of the left DataFrame.</p> <code>None</code> <code>right_on</code> <code>str | list[str] | None</code> <p>Join column of the right DataFrame.</p> <code>None</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <code>'_right'</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new joined LazyFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6.0, 7.0, 8.0],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; data_other = {\n...     \"apple\": [\"x\", \"y\", \"z\"],\n...     \"ham\": [\"a\", \"b\", \"d\"],\n... }\n</code></pre> <pre><code>&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; other_pl = pl.LazyFrame(data_other)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n&gt;&gt;&gt; other_dask = dd.from_dict(data_other, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we join over \"ham\" column:</p> <pre><code>&gt;&gt;&gt; def agnostic_join_on_ham(\n...     df_native: IntoFrameT,\n...     other_native: IntoFrameT,\n... ) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     other = nw.from_native(other_native)\n...     return (\n...         df.join(other, left_on=\"ham\", right_on=\"ham\")\n...         .sort(\"ham\")\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_join_on_ham</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_join_on_ham(lf_pl, other_pl)\nshape: (2, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2506 apple \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2506 ---   \u2502\n\u2502 i64 \u2506 f64 \u2506 str \u2506 str   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6.0 \u2506 a   \u2506 x     \u2502\n\u2502 2   \u2506 7.0 \u2506 b   \u2506 y     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_join_on_ham(lf_dask, other_dask)\n   foo  bar ham apple\n0    1  6.0   a     x\n0    2  7.0   b     y\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.join_asof","title":"<code>join_asof(other, *, left_on=None, right_on=None, on=None, by_left=None, by_right=None, by=None, strategy='backward', suffix='_right')</code>","text":"<p>Perform an asof join.</p> <p>This is similar to a left-join except that we match on nearest key rather than equal keys.</p> <p>Both DataFrames must be sorted by the asof_join key.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Self</code> <p>DataFrame to join with.</p> required <code>left_on</code> <code>str | None</code> <p>Name(s) of the left join column(s).</p> <code>None</code> <code>right_on</code> <code>str | None</code> <p>Name(s) of the right join column(s).</p> <code>None</code> <code>on</code> <code>str | None</code> <p>Join column of both DataFrames. If set, left_on and right_on should be None.</p> <code>None</code> <code>by_left</code> <code>str | list[str] | None</code> <p>join on these columns before doing asof join</p> <code>None</code> <code>by_right</code> <code>str | list[str] | None</code> <p>join on these columns before doing asof join</p> <code>None</code> <code>by</code> <code>str | list[str] | None</code> <p>join on these columns before doing asof join</p> <code>None</code> <code>strategy</code> <code>Literal['backward', 'forward', 'nearest']</code> <p>Join strategy. The default is \"backward\".</p> <ul> <li>backward: selects the last row in the right DataFrame whose \"on\" key is less than or equal to the left's key.</li> <li>forward: selects the first row in the right DataFrame whose \"on\" key is greater than or equal to the left's key.</li> <li>nearest: search selects the last row in the right DataFrame whose value is nearest to the left's key.</li> </ul> <code>'backward'</code> <code>suffix</code> <code>str</code> <p>Suffix to append to columns with a duplicate name.</p> <code>'_right'</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new joined LazyFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; from typing import Literal\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data_gdp = {\n...     \"datetime\": [\n...         datetime(2016, 1, 1),\n...         datetime(2017, 1, 1),\n...         datetime(2018, 1, 1),\n...         datetime(2019, 1, 1),\n...         datetime(2020, 1, 1),\n...     ],\n...     \"gdp\": [4164, 4411, 4566, 4696, 4827],\n... }\n&gt;&gt;&gt; data_population = {\n...     \"datetime\": [\n...         datetime(2016, 3, 1),\n...         datetime(2018, 8, 1),\n...         datetime(2019, 1, 1),\n...     ],\n...     \"population\": [82.19, 82.66, 83.12],\n... }\n&gt;&gt;&gt; gdp_pl = pl.LazyFrame(data_gdp)\n&gt;&gt;&gt; population_pl = pl.LazyFrame(data_population)\n&gt;&gt;&gt; gdp_dask = dd.from_dict(data_gdp, npartitions=2)\n&gt;&gt;&gt; population_dask = dd.from_dict(data_population, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we join over \"datetime\" column:</p> <pre><code>&gt;&gt;&gt; def agnostic_join_asof_datetime(\n...     df_native: IntoFrameT,\n...     other_native: IntoFrameT,\n...     strategy: Literal[\"backward\", \"forward\", \"nearest\"],\n... ) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     other = nw.from_native(other_native)\n...     return (\n...         df.sort(\"datetime\")\n...         .join_asof(other, on=\"datetime\", strategy=strategy)\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_join_asof_datetime</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_join_asof_datetime(population_pl, gdp_pl, strategy=\"backward\")\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime            \u2506 population \u2506 gdp  \u2502\n\u2502 ---                 \u2506 ---        \u2506 ---  \u2502\n\u2502 datetime[\u03bcs]        \u2506 f64        \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2016-03-01 00:00:00 \u2506 82.19      \u2506 4164 \u2502\n\u2502 2018-08-01 00:00:00 \u2506 82.66      \u2506 4566 \u2502\n\u2502 2019-01-01 00:00:00 \u2506 83.12      \u2506 4696 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_join_asof_datetime(population_dask, gdp_dask, strategy=\"backward\")\n    datetime  population   gdp\n0 2016-03-01       82.19  4164\n1 2018-08-01       82.66  4566\n0 2019-01-01       83.12  4696\n</code></pre> <p>Here is a real-world times-series example that uses <code>by</code> argument.</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data_quotes = {\n...     \"datetime\": [\n...         datetime(2016, 5, 25, 13, 30, 0, 23),\n...         datetime(2016, 5, 25, 13, 30, 0, 23),\n...         datetime(2016, 5, 25, 13, 30, 0, 30),\n...         datetime(2016, 5, 25, 13, 30, 0, 41),\n...         datetime(2016, 5, 25, 13, 30, 0, 48),\n...         datetime(2016, 5, 25, 13, 30, 0, 49),\n...         datetime(2016, 5, 25, 13, 30, 0, 72),\n...         datetime(2016, 5, 25, 13, 30, 0, 75),\n...     ],\n...     \"ticker\": [\n...         \"GOOG\",\n...         \"MSFT\",\n...         \"MSFT\",\n...         \"MSFT\",\n...         \"GOOG\",\n...         \"AAPL\",\n...         \"GOOG\",\n...         \"MSFT\",\n...     ],\n...     \"bid\": [720.50, 51.95, 51.97, 51.99, 720.50, 97.99, 720.50, 52.01],\n...     \"ask\": [720.93, 51.96, 51.98, 52.00, 720.93, 98.01, 720.88, 52.03],\n... }\n&gt;&gt;&gt; data_trades = {\n...     \"datetime\": [\n...         datetime(2016, 5, 25, 13, 30, 0, 23),\n...         datetime(2016, 5, 25, 13, 30, 0, 38),\n...         datetime(2016, 5, 25, 13, 30, 0, 48),\n...         datetime(2016, 5, 25, 13, 30, 0, 49),\n...         datetime(2016, 5, 25, 13, 30, 0, 48),\n...     ],\n...     \"ticker\": [\"MSFT\", \"MSFT\", \"GOOG\", \"GOOG\", \"AAPL\"],\n...     \"price\": [51.95, 51.95, 720.77, 720.92, 98.0],\n...     \"quantity\": [75, 155, 100, 100, 100],\n... }\n&gt;&gt;&gt; quotes_pl = pl.LazyFrame(data_quotes)\n&gt;&gt;&gt; trades_pl = pl.LazyFrame(data_trades)\n&gt;&gt;&gt; quotes_dask = dd.from_dict(data_quotes, npartitions=2)\n&gt;&gt;&gt; trades_dask = dd.from_dict(data_trades, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we join over \"datetime\" and by \"ticker\" columns:</p> <pre><code>&gt;&gt;&gt; def agnostic_join_asof_datetime_by_ticker(\n...     df_native: IntoFrameT,\n...     other_native: IntoFrameT,\n... ) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     other = nw.from_native(other_native)\n...     return (\n...         df.sort(\"datetime\", \"ticker\")\n...         .join_asof(other, on=\"datetime\", by=\"ticker\")\n...         .sort(\"datetime\", \"ticker\")\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_join_asof_datetime_by_ticker</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_join_asof_datetime_by_ticker(trades_pl, quotes_pl)\nshape: (5, 6)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 datetime                   \u2506 ticker \u2506 price  \u2506 quantity \u2506 bid   \u2506 ask    \u2502\n\u2502 ---                        \u2506 ---    \u2506 ---    \u2506 ---      \u2506 ---   \u2506 ---    \u2502\n\u2502 datetime[\u03bcs]               \u2506 str    \u2506 f64    \u2506 i64      \u2506 f64   \u2506 f64    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2016-05-25 13:30:00.000023 \u2506 MSFT   \u2506 51.95  \u2506 75       \u2506 51.95 \u2506 51.96  \u2502\n\u2502 2016-05-25 13:30:00.000038 \u2506 MSFT   \u2506 51.95  \u2506 155      \u2506 51.97 \u2506 51.98  \u2502\n\u2502 2016-05-25 13:30:00.000048 \u2506 AAPL   \u2506 98.0   \u2506 100      \u2506 null  \u2506 null   \u2502\n\u2502 2016-05-25 13:30:00.000048 \u2506 GOOG   \u2506 720.77 \u2506 100      \u2506 720.5 \u2506 720.93 \u2502\n\u2502 2016-05-25 13:30:00.000049 \u2506 GOOG   \u2506 720.92 \u2506 100      \u2506 720.5 \u2506 720.93 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_join_asof_datetime_by_ticker(trades_dask, quotes_dask)\n                    datetime ticker   price  quantity     bid     ask\n0 2016-05-25 13:30:00.000023   MSFT   51.95        75   51.95   51.96\n0 2016-05-25 13:30:00.000038   MSFT   51.95       155   51.97   51.98\n1 2016-05-25 13:30:00.000048   AAPL   98.00       100     NaN     NaN\n2 2016-05-25 13:30:00.000048   GOOG  720.77       100  720.50  720.93\n3 2016-05-25 13:30:00.000049   GOOG  720.92       100  720.50  720.93\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.lazy","title":"<code>lazy()</code>","text":"<p>Lazify the DataFrame (if possible).</p> <p>If a library does not support lazy execution, then this is a no-op.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A LazyFrame.</p> <p>Examples:</p> <p>Construct pandas and Polars objects:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; df = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(df)\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(df)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_lazy(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.lazy().to_native()\n</code></pre> <p>Note that then, pandas dataframe stay eager, and the Polars LazyFrame stays lazy:</p> <pre><code>&gt;&gt;&gt; agnostic_lazy(df_pd)\n   foo  bar ham\n0    1  6.0   a\n1    2  7.0   b\n2    3  8.0   c\n&gt;&gt;&gt; agnostic_lazy(lf_pl)\n&lt;LazyFrame ...&gt;\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.pipe","title":"<code>pipe(function, *args, **kwargs)</code>","text":"<p>Pipe function call.</p> <p>Parameters:</p> Name Type Description Default <code>function</code> <code>Callable[Concatenate[Self, PS], R]</code> <p>Function to apply.</p> required <code>args</code> <code>args</code> <p>Positional arguments to pass to function.</p> <code>()</code> <code>kwargs</code> <code>kwargs</code> <p>Keyword arguments to pass to function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>R</code> <p>The original object with the function applied.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"ba\": [4, 5, 6]}\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_pipe(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.pipe(lambda _df: _df.select(\"a\")).collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_pipe</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_pipe(lf_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2502 2   \u2502\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_pipe(lf_dask)\n   a\n0  1\n1  2\n2  3\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.rename","title":"<code>rename(mapping)</code>","text":"<p>Rename column names.</p> <p>Parameters:</p> Name Type Description Default <code>mapping</code> <code>dict[str, str]</code> <p>Key value pairs that map from old name to new name, or a       function that takes the old name as input and returns the       new name.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>The LazyFrame with the specified columns renamed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6, 7, 8], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rename(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.rename({\"foo\": \"apple\"}).collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_rename</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rename(lf_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 apple \u2506 bar \u2506 ham \u2502\n\u2502 ---   \u2506 --- \u2506 --- \u2502\n\u2502 i64   \u2506 i64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1     \u2506 6   \u2506 a   \u2502\n\u2502 2     \u2506 7   \u2506 b   \u2502\n\u2502 3     \u2506 8   \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_rename(lf_dask)\n   apple  bar ham\n0      1    6   a\n1      2    7   b\n2      3    8   c\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.select","title":"<code>select(*exprs, **named_exprs)</code>","text":"<p>Select columns from this LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>*exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Column(s) to select, specified as positional arguments. Accepts expression input. Strings are parsed as column names.</p> <code>()</code> <code>**named_exprs</code> <code>IntoExpr</code> <p>Additional columns to select, specified as keyword arguments. The columns will be renamed to the keyword used.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Self</code> <p>The LazyFrame containing only the selected columns.</p> Notes <p>If you'd like to select a column whose name isn't a string (for example, if you're working with pandas) then you should explicitly use <code>nw.col</code> instead of just passing the column name. For example, to select a column named <code>0</code> use <code>df.select(nw.col(0))</code>, not <code>df.select(0)</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3],\n...     \"bar\": [6, 7, 8],\n...     \"ham\": [\"a\", \"b\", \"c\"],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we pass the name of a column to select that column.</p> <pre><code>&gt;&gt;&gt; def agnostic_select(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\"foo\").collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_select</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_select(lf_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2502 2   \u2502\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_select(lf_dask)\n   foo\n0    1\n1    2\n2    3\n</code></pre> <p>Multiple columns can be selected by passing a list of column names.</p> <pre><code>&gt;&gt;&gt; def agnostic_select(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select([\"foo\", \"bar\"]).collect().to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_select(lf_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6   \u2502\n\u2502 2   \u2506 7   \u2502\n\u2502 3   \u2506 8   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_select(lf_dask)\n   foo  bar\n0    1    6\n1    2    7\n2    3    8\n</code></pre> <p>Multiple columns can also be selected using positional arguments instead of a list. Expressions are also accepted.</p> <pre><code>&gt;&gt;&gt; def agnostic_select(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"foo\"), nw.col(\"bar\") + 1).collect().to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_select(lf_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 7   \u2502\n\u2502 2   \u2506 8   \u2502\n\u2502 3   \u2506 9   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_select(lf_dask)\n   foo  bar\n0    1    7\n1    2    8\n2    3    9\n</code></pre> <p>Use keyword arguments to easily name your expression inputs.</p> <pre><code>&gt;&gt;&gt; def agnostic_select(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(threshold=nw.col(\"foo\") * 2).collect().to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_select(lf_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 threshold \u2502\n\u2502 ---       \u2502\n\u2502 i64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2         \u2502\n\u2502 4         \u2502\n\u2502 6         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_select(lf_dask)\n   threshold\n0          2\n1          4\n2          6\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.sort","title":"<code>sort(by, *more_by, descending=False, nulls_last=False)</code>","text":"<p>Sort the LazyFrame by the given columns.</p> <p>Parameters:</p> Name Type Description Default <code>by</code> <code>str | Iterable[str]</code> <p>Column(s) names to sort by.</p> required <code>*more_by</code> <code>str</code> <p>Additional columns to sort by, specified as positional arguments.</p> <code>()</code> <code>descending</code> <code>bool | Sequence[bool]</code> <p>Sort in descending order. When sorting by multiple columns, can be specified per column by passing a sequence of booleans.</p> <code>False</code> <code>nulls_last</code> <code>bool</code> <p>Place null values last; can specify a single boolean applying to all columns or a sequence of booleans for per-column control.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>The sorted LazyFrame.</p> Warning <p>Unlike Polars, it is not possible to specify a sequence of booleans for <code>nulls_last</code> in order to control per-column behaviour. Instead a single boolean is applied for all <code>by</code> columns.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 2, None],\n...     \"b\": [6.0, 5.0, 4.0],\n...     \"c\": [\"a\", \"c\", \"b\"],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we sort by multiple columns in different orders</p> <pre><code>&gt;&gt;&gt; def agnostic_sort(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.sort(\"c\", \"a\", descending=[False, True]).collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_sort</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_sort(lf_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b   \u2506 c   \u2502\n\u2502 ---  \u2506 --- \u2506 --- \u2502\n\u2502 i64  \u2506 f64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1    \u2506 6.0 \u2506 a   \u2502\n\u2502 null \u2506 4.0 \u2506 b   \u2502\n\u2502 2    \u2506 5.0 \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_sort(lf_dask)\n     a    b  c\n0  1.0  6.0  a\n2  NaN  4.0  b\n1  2.0  5.0  c\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.tail","title":"<code>tail(n=5)</code>","text":"<p>Get the last <code>n</code> rows.</p> <p>Warning</p> <p><code>LazyFrame.tail</code> is deprecated and will be removed in a future version. Note: this will remain available in <code>narwhals.stable.v1</code>. See stable api for more information.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to return.</p> <code>5</code> <p>Returns:</p> Type Description <code>Self</code> <p>A subset of the LazyFrame of shape (n, n_columns).</p>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.to_native","title":"<code>to_native()</code>","text":"<p>Convert Narwhals LazyFrame to native one.</p> <p>Returns:</p> Type Description <code>FrameT</code> <p>Object of class that user started with.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"foo\": [1, 2, 3], \"bar\": [6.0, 7.0, 8.0], \"ham\": [\"a\", \"b\", \"c\"]}\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Calling <code>to_native</code> on a Narwhals LazyFrame returns the native object:</p> <pre><code>&gt;&gt;&gt; nw.from_native(lf_pl).to_native().collect()\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 6.0 \u2506 a   \u2502\n\u2502 2   \u2506 7.0 \u2506 b   \u2502\n\u2502 3   \u2506 8.0 \u2506 c   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; nw.from_native(lf_dask).to_native().compute()\n   foo  bar ham\n0    1  6.0   a\n1    2  7.0   b\n2    3  8.0   c\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.unique","title":"<code>unique(subset=None, *, keep='any', maintain_order=None)</code>","text":"<p>Drop duplicate rows from this LazyFrame.</p> <p>Parameters:</p> Name Type Description Default <code>subset</code> <code>str | list[str] | None</code> <p>Column name(s) to consider when identifying duplicate rows.      If set to <code>None</code>, use all columns.</p> <code>None</code> <code>keep</code> <code>Literal['any', 'none']</code> <p>{'first', 'none'} Which of the duplicate rows to keep.</p> <ul> <li>'any': Does not give any guarantee of which row is kept.         This allows more optimizations.</li> <li>'none': Don't keep duplicate rows.</li> </ul> <code>'any'</code> <code>maintain_order</code> <code>bool | None</code> <p>Has no effect and is kept around only for backwards-compatibility.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The LazyFrame with unique rows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"foo\": [1, 2, 3, 1],\n...     \"bar\": [\"a\", \"a\", \"a\", \"a\"],\n...     \"ham\": [\"b\", \"b\", \"b\", \"b\"],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_unique(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.unique([\"bar\", \"ham\"]).collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_unique</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_unique(lf_pl)\nshape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 foo \u2506 bar \u2506 ham \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 str \u2506 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 a   \u2506 b   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_unique(lf_dask)\n   foo bar ham\n0    1   a   b\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.unpivot","title":"<code>unpivot(on=None, *, index=None, variable_name=None, value_name=None)</code>","text":"<p>Unpivot a DataFrame from wide to long format.</p> <p>Optionally leaves identifiers set.</p> <p>This function is useful to massage a DataFrame into a format where one or more columns are identifier variables (index) while all other columns, considered measured variables (on), are \"unpivoted\" to the row axis leaving just two non-identifier columns, 'variable' and 'value'.</p> <p>Parameters:</p> Name Type Description Default <code>on</code> <code>str | list[str] | None</code> <p>Column(s) to use as values variables; if <code>on</code> is empty all columns that are not in <code>index</code> will be used.</p> <code>None</code> <code>index</code> <code>str | list[str] | None</code> <p>Column(s) to use as identifier variables.</p> <code>None</code> <code>variable_name</code> <code>str | None</code> <p>Name to give to the <code>variable</code> column. Defaults to \"variable\".</p> <code>None</code> <code>value_name</code> <code>str | None</code> <p>Name to give to the <code>value</code> column. Defaults to \"value\".</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>The unpivoted LazyFrame.</p> Notes <p>If you're coming from pandas, this is similar to <code>pandas.DataFrame.melt</code>, but with <code>index</code> replacing <code>id_vars</code> and <code>on</code> replacing <code>value_vars</code>. In other frameworks, you might know this operation as <code>pivot_longer</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [\"x\", \"y\", \"z\"],\n...     \"b\": [1, 3, 5],\n...     \"c\": [2, 4, 6],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_unpivot(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return (\n...         (df.unpivot(on=[\"b\", \"c\"], index=\"a\").sort([\"variable\", \"a\"]))\n...         .collect()\n...         .to_native()\n...     )\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_unpivot</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_unpivot(lf_pl)\nshape: (6, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 variable \u2506 value \u2502\n\u2502 --- \u2506 ---      \u2506 ---   \u2502\n\u2502 str \u2506 str      \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 x   \u2506 b        \u2506 1     \u2502\n\u2502 y   \u2506 b        \u2506 3     \u2502\n\u2502 z   \u2506 b        \u2506 5     \u2502\n\u2502 x   \u2506 c        \u2506 2     \u2502\n\u2502 y   \u2506 c        \u2506 4     \u2502\n\u2502 z   \u2506 c        \u2506 6     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_unpivot(lf_dask)\n   a variable  value\n0  x        b      1\n1  y        b      3\n0  z        b      5\n2  x        c      2\n3  y        c      4\n1  z        c      6\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.with_columns","title":"<code>with_columns(*exprs, **named_exprs)</code>","text":"<p>Add columns to this LazyFrame.</p> <p>Added columns will replace existing columns with the same name.</p> <p>Parameters:</p> Name Type Description Default <code>*exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Column(s) to add, specified as positional arguments.      Accepts expression input. Strings are parsed as column names, other      non-expression inputs are parsed as literals.</p> <code>()</code> <code>**named_exprs</code> <code>IntoExpr</code> <p>Additional columns to add, specified as keyword arguments.             The columns will be renamed to the keyword used.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>LazyFrame</code> <code>Self</code> <p>A new LazyFrame with the columns added.</p> Note <p>Creating a new LazyFrame using this method does not create a new copy of existing data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 2, 3, 4],\n...     \"b\": [0.5, 4, 10, 13],\n...     \"c\": [True, True, False, True],\n... }\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function in which we pass an expression to add it as a new column:</p> <pre><code>&gt;&gt;&gt; def agnostic_with_columns(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return (\n...         df.with_columns((nw.col(\"a\") * 2).alias(\"2a\")).collect().to_native()\n...     )\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_with_columns</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_with_columns(lf_pl)\nshape: (4, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b    \u2506 c     \u2506 2a  \u2502\n\u2502 --- \u2506 ---  \u2506 ---   \u2506 --- \u2502\n\u2502 i64 \u2506 f64  \u2506 bool  \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 0.5  \u2506 true  \u2506 2   \u2502\n\u2502 2   \u2506 4.0  \u2506 true  \u2506 4   \u2502\n\u2502 3   \u2506 10.0 \u2506 false \u2506 6   \u2502\n\u2502 4   \u2506 13.0 \u2506 true  \u2506 8   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_with_columns(lf_dask)\n   a     b      c  2a\n0  1   0.5   True   2\n1  2   4.0   True   4\n2  3  10.0  False   6\n3  4  13.0   True   8\n</code></pre>"},{"location":"api-reference/lazyframe/#narwhals.dataframe.LazyFrame.with_row_index","title":"<code>with_row_index(name='index')</code>","text":"<p>Insert column which enumerates rows.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the column as a string. The default is \"index\".</p> <code>'index'</code> <p>Returns:</p> Type Description <code>Self</code> <p>The original object with the column added.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n&gt;&gt;&gt; lf_pl = pl.LazyFrame(data)\n&gt;&gt;&gt; lf_dask = dd.from_dict(data, npartitions=2)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_with_row_index(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_row_index().collect().to_native()\n</code></pre> <p>We can then pass any supported library such as Polars or Dask to <code>agnostic_with_row_index</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_with_row_index(lf_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 index \u2506 a   \u2506 b   \u2502\n\u2502 ---   \u2506 --- \u2506 --- \u2502\n\u2502 u32   \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0     \u2506 1   \u2506 4   \u2502\n\u2502 1     \u2506 2   \u2506 5   \u2502\n\u2502 2     \u2506 3   \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_with_row_index(lf_dask)\n   index  a  b\n0      0  1  4\n1      1  2  5\n2      2  3  6\n</code></pre>"},{"location":"api-reference/narwhals/","title":"Top-level functions","text":"<p>Here are the top-level functions available in Narwhals.</p>"},{"location":"api-reference/narwhals/#narwhals.all","title":"<code>all()</code>","text":"<p>Instantiate an expression representing all columns.</p> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_all(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.all() * 2).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_all</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_all(df_pd)\n   a   b\n0  2   8\n1  4  10\n2  6  12\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_all(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 8   \u2502\n\u2502 4   \u2506 10  \u2502\n\u2502 6   \u2506 12  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_all(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[2,4,6]]\nb: [[8,10,12]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.all_horizontal","title":"<code>all_horizontal(*exprs)</code>","text":"<p>Compute the bitwise AND horizontally across columns.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Name(s) of the columns to use in the aggregation function. Accepts expression input.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [False, False, True, True, False, None],\n...     \"b\": [False, True, True, None, None, None],\n... }\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data).convert_dtypes(dtype_backend=\"pyarrow\")\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_all_horizontal(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\"a\", \"b\", all=nw.all_horizontal(\"a\", \"b\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_all_horizontal</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_all_horizontal(df_pd)\n       a      b    all\n0  False  False  False\n1  False   True  False\n2   True   True   True\n3   True   &lt;NA&gt;   &lt;NA&gt;\n4  False   &lt;NA&gt;  False\n5   &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_all_horizontal(df_pl)\nshape: (6, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2506 b     \u2506 all   \u2502\n\u2502 ---   \u2506 ---   \u2506 ---   \u2502\n\u2502 bool  \u2506 bool  \u2506 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 false \u2506 false \u2506 false \u2502\n\u2502 false \u2506 true  \u2506 false \u2502\n\u2502 true  \u2506 true  \u2506 true  \u2502\n\u2502 true  \u2506 null  \u2506 null  \u2502\n\u2502 false \u2506 null  \u2506 false \u2502\n\u2502 null  \u2506 null  \u2506 null  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_all_horizontal(df_pa)\npyarrow.Table\na: bool\nb: bool\nall: bool\n----\na: [[false,false,true,true,false,null]]\nb: [[false,true,true,null,null,null]]\nall: [[false,false,true,null,false,null]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.any_horizontal","title":"<code>any_horizontal(*exprs)</code>","text":"<p>Compute the bitwise OR horizontally across columns.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Name(s) of the columns to use in the aggregation function. Accepts expression input.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [False, False, True, True, False, None],\n...     \"b\": [False, True, True, None, None, None],\n... }\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data).convert_dtypes(dtype_backend=\"pyarrow\")\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_any_horizontal(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\"a\", \"b\", any=nw.any_horizontal(\"a\", \"b\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_any_horizontal</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_any_horizontal(df_pd)\n       a      b    any\n0  False  False  False\n1  False   True   True\n2   True   True   True\n3   True   &lt;NA&gt;   True\n4  False   &lt;NA&gt;   &lt;NA&gt;\n5   &lt;NA&gt;   &lt;NA&gt;   &lt;NA&gt;\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_any_horizontal(df_pl)\nshape: (6, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a     \u2506 b     \u2506 any   \u2502\n\u2502 ---   \u2506 ---   \u2506 ---   \u2502\n\u2502 bool  \u2506 bool  \u2506 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 false \u2506 false \u2506 false \u2502\n\u2502 false \u2506 true  \u2506 true  \u2502\n\u2502 true  \u2506 true  \u2506 true  \u2502\n\u2502 true  \u2506 null  \u2506 true  \u2502\n\u2502 false \u2506 null  \u2506 null  \u2502\n\u2502 null  \u2506 null  \u2506 null  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_any_horizontal(df_pa)\npyarrow.Table\na: bool\nb: bool\nany: bool\n----\na: [[false,false,true,true,false,null]]\nb: [[false,true,true,null,null,null]]\nany: [[false,true,true,true,null,null]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.col","title":"<code>col(*names)</code>","text":"<p>Creates an expression that references one or more columns by their name(s).</p> <p>Parameters:</p> Name Type Description Default <code>names</code> <code>str | Iterable[str]</code> <p>Name(s) of the columns to use.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [3, 4]}\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_col(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.col(\"a\") * nw.col(\"b\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_col</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_col(df_pd)\n   a\n0  3\n1  8\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_col(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 3   \u2502\n\u2502 8   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_col(df_pa)\npyarrow.Table\na: int64\n----\na: [[3,8]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.concat","title":"<code>concat(items, *, how='vertical')</code>","text":"<p>Concatenate multiple DataFrames, LazyFrames into a single entity.</p> <p>Parameters:</p> Name Type Description Default <code>items</code> <code>Iterable[DataFrame[IntoDataFrameT] | LazyFrame[IntoFrameT]]</code> <p>DataFrames, LazyFrames to concatenate.</p> required <code>how</code> <code>Literal['horizontal', 'vertical', 'diagonal']</code> <p>concatenating strategy:</p> <ul> <li>vertical: Concatenate vertically. Column names must match.</li> <li>horizontal: Concatenate horizontally. If lengths don't match, then     missing rows are filled with null values.</li> <li>diagonal: Finds a union between the column schemas and fills missing column     values with null.</li> </ul> <code>'vertical'</code> <p>Returns:</p> Type Description <code>DataFrame[IntoDataFrameT] | LazyFrame[IntoFrameT]</code> <p>A new DataFrame, Lazyframe resulting from the concatenation.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>The items to concatenate should either all be eager, or all lazy</p> <p>Examples:</p> <p>Let's take an example of vertical concatenation:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data_1 = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n&gt;&gt;&gt; data_2 = {\"a\": [5, 2], \"b\": [1, 4]}\n</code></pre> <pre><code>&gt;&gt;&gt; df_pd_1 = pd.DataFrame(data_1)\n&gt;&gt;&gt; df_pd_2 = pd.DataFrame(data_2)\n&gt;&gt;&gt; df_pl_1 = pl.DataFrame(data_1)\n&gt;&gt;&gt; df_pl_2 = pl.DataFrame(data_2)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def agnostic_vertical_concat(df1, df2):\n...     return nw.concat([df1, df2], how=\"vertical\")\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_vertical_concat(df_pd_1, df_pd_2)\n   a  b\n0  1  4\n1  2  5\n2  3  6\n0  5  1\n1  2  4\n&gt;&gt;&gt; agnostic_vertical_concat(df_pl_1, df_pl_2)\nshape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4   \u2502\n\u2502 2   \u2506 5   \u2502\n\u2502 3   \u2506 6   \u2502\n\u2502 5   \u2506 1   \u2502\n\u2502 2   \u2506 4   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Let's look at case a for horizontal concatenation:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data_1 = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n&gt;&gt;&gt; data_2 = {\"c\": [5, 2], \"d\": [1, 4]}\n</code></pre> <pre><code>&gt;&gt;&gt; df_pd_1 = pd.DataFrame(data_1)\n&gt;&gt;&gt; df_pd_2 = pd.DataFrame(data_2)\n&gt;&gt;&gt; df_pl_1 = pl.DataFrame(data_1)\n&gt;&gt;&gt; df_pl_2 = pl.DataFrame(data_2)\n</code></pre> <p>Defining a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def agnostic_horizontal_concat(df1, df2):\n...     return nw.concat([df1, df2], how=\"horizontal\")\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_horizontal_concat(df_pd_1, df_pd_2)\n   a  b    c    d\n0  1  4  5.0  1.0\n1  2  5  2.0  4.0\n2  3  6  NaN  NaN\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_horizontal_concat(df_pl_1, df_pl_2)\nshape: (3, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c    \u2506 d    \u2502\n\u2502 --- \u2506 --- \u2506 ---  \u2506 ---  \u2502\n\u2502 i64 \u2506 i64 \u2506 i64  \u2506 i64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4   \u2506 5    \u2506 1    \u2502\n\u2502 2   \u2506 5   \u2506 2    \u2506 4    \u2502\n\u2502 3   \u2506 6   \u2506 null \u2506 null \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Let's look at case a for diagonal concatenation:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; data_1 = {\"a\": [1, 2], \"b\": [3.5, 4.5]}\n&gt;&gt;&gt; data_2 = {\"a\": [3, 4], \"z\": [\"x\", \"y\"]}\n</code></pre> <pre><code>&gt;&gt;&gt; df_pd_1 = pd.DataFrame(data_1)\n&gt;&gt;&gt; df_pd_2 = pd.DataFrame(data_2)\n&gt;&gt;&gt; df_pl_1 = pl.DataFrame(data_1)\n&gt;&gt;&gt; df_pl_2 = pl.DataFrame(data_2)\n</code></pre> <p>Defining a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def agnostic_diagonal_concat(df1, df2):\n...     return nw.concat([df1, df2], how=\"diagonal\")\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_diagonal_concat(df_pd_1, df_pd_2)\n   a    b    z\n0  1  3.5  NaN\n1  2  4.5  NaN\n0  3  NaN    x\n1  4  NaN    y\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_diagonal_concat(df_pl_1, df_pl_2)\nshape: (4, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b    \u2506 z    \u2502\n\u2502 --- \u2506 ---  \u2506 ---  \u2502\n\u2502 i64 \u2506 f64  \u2506 str  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 3.5  \u2506 null \u2502\n\u2502 2   \u2506 4.5  \u2506 null \u2502\n\u2502 3   \u2506 null \u2506 x    \u2502\n\u2502 4   \u2506 null \u2506 y    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.concat_str","title":"<code>concat_str(exprs, *more_exprs, separator='', ignore_nulls=False)</code>","text":"<p>Horizontally concatenate columns into a single string column.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Columns to concatenate into a single string column. Accepts expression input. Strings are parsed as column names, other non-expression inputs are parsed as literals. Non-<code>String</code> columns are cast to <code>String</code>.</p> required <code>*more_exprs</code> <code>IntoExpr</code> <p>Additional columns to concatenate into a single string column, specified as positional arguments.</p> <code>()</code> <code>separator</code> <code>str</code> <p>String that will be used to separate the values of each column.</p> <code>''</code> <code>ignore_nulls</code> <code>bool</code> <p>Ignore null values (default is <code>False</code>). If set to <code>False</code>, null values will be propagated and if the row contains any null values, the output is null.</p> <code>False</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 2, 3],\n...     \"b\": [\"dogs\", \"cats\", None],\n...     \"c\": [\"play\", \"swim\", \"walk\"],\n... }\n</code></pre> <p>We define a dataframe-agnostic function that computes the horizontal string concatenation of different columns</p> <pre><code>&gt;&gt;&gt; def agnostic_concat_str(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(\n...         nw.concat_str(\n...             [\n...                 nw.col(\"a\") * 2,\n...                 nw.col(\"b\"),\n...                 nw.col(\"c\"),\n...             ],\n...             separator=\" \",\n...         ).alias(\"full_sentence\")\n...     ).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_concat_str</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_concat_str(pd.DataFrame(data))\n  full_sentence\n0   2 dogs play\n1   4 cats swim\n2          None\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_concat_str(pl.DataFrame(data))\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 full_sentence \u2502\n\u2502 ---           \u2502\n\u2502 str           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2 dogs play   \u2502\n\u2502 4 cats swim   \u2502\n\u2502 null          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_concat_str(pa.table(data))\npyarrow.Table\nfull_sentence: string\n----\nfull_sentence: [[\"2 dogs play\",\"4 cats swim\",null]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.from_arrow","title":"<code>from_arrow(native_frame, *, native_namespace)</code>","text":"<p>Construct a DataFrame from an object which supports the PyCapsule Interface.</p> <p>Parameters:</p> Name Type Description Default <code>native_frame</code> <code>ArrowStreamExportable</code> <p>Object which implements <code>__arrow_c_stream__</code>.</p> required <code>native_namespace</code> <code>ModuleType</code> <p>The native library to use for DataFrame creation.</p> required <p>Returns:</p> Type Description <code>DataFrame[Any]</code> <p>A new DataFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n</code></pre> <p>Let's define a dataframe-agnostic function which creates a PyArrow Table.</p> <pre><code>&gt;&gt;&gt; def agnostic_to_arrow(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return nw.from_arrow(df, native_namespace=pa).to_native()\n</code></pre> <p>Let's see what happens when passing pandas / Polars input:</p> <pre><code>&gt;&gt;&gt; agnostic_to_arrow(pd.DataFrame(data))\npyarrow.Table\na: int64\nb: int64\n----\na: [[1,2,3]]\nb: [[4,5,6]]\n&gt;&gt;&gt; agnostic_to_arrow(pl.DataFrame(data))\npyarrow.Table\na: int64\nb: int64\n----\na: [[1,2,3]]\nb: [[4,5,6]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.from_dict","title":"<code>from_dict(data, schema=None, *, native_namespace=None)</code>","text":"<p>Instantiate DataFrame from dictionary.</p> <p>Indexes (if present, for pandas-like backends) are aligned following the left-hand-rule.</p> Notes <p>For pandas-like dataframes, conversion to schema is applied after dataframe creation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>dict[str, Any]</code> <p>Dictionary to create DataFrame from.</p> required <code>schema</code> <code>dict[str, DType] | Schema | None</code> <p>The DataFrame schema as Schema or dict of {name: type}.</p> <code>None</code> <code>native_namespace</code> <code>ModuleType | None</code> <p>The native library to use for DataFrame creation. Only necessary if inputs are not Narwhals Series.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame[Any]</code> <p>A new DataFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n</code></pre> <p>Let's create a new dataframe of the same class as the dataframe we started with, from a dict of new data:</p> <pre><code>&gt;&gt;&gt; def agnostic_from_dict(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     new_data = {\"c\": [5, 2], \"d\": [1, 4]}\n...     native_namespace = nw.get_native_namespace(df_native)\n...     return nw.from_dict(new_data, native_namespace=native_namespace).to_native()\n</code></pre> <p>Let's see what happens when passing pandas, Polars or PyArrow input:</p> <pre><code>&gt;&gt;&gt; agnostic_from_dict(pd.DataFrame(data))\n   c  d\n0  5  1\n1  2  4\n&gt;&gt;&gt; agnostic_from_dict(pl.DataFrame(data))\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 c   \u2506 d   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 5   \u2506 1   \u2502\n\u2502 2   \u2506 4   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_from_dict(pa.table(data))\npyarrow.Table\nc: int64\nd: int64\n----\nc: [[5,2]]\nd: [[1,4]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.from_native","title":"<code>from_native(native_object, *, strict=None, pass_through=None, eager_only=False, series_only=False, allow_series=None)</code>","text":"<p>Convert <code>native_object</code> to Narwhals Dataframe, Lazyframe, or Series.</p> <p>Parameters:</p> Name Type Description Default <code>native_object</code> <code>IntoFrameT | IntoSeries | T</code> <p>Raw object from user. Depending on the other arguments, input object can be:</p> <ul> <li>a Dataframe / Lazyframe / Series supported by Narwhals (pandas, Polars, PyArrow, ...)</li> <li>an object which implements <code>__narwhals_dataframe__</code>, <code>__narwhals_lazyframe__</code>,   or <code>__narwhals_series__</code></li> </ul> required <code>strict</code> <code>bool | None</code> <p>Determine what happens if the object can't be converted to Narwhals:</p> <ul> <li><code>True</code> or <code>None</code> (default): raise an error</li> <li><code>False</code>: pass object through as-is</li> </ul> <p>Deprecated (v1.13.0):     Please use <code>pass_through</code> instead. Note that <code>strict</code> is still available     (and won't emit a deprecation warning) if you use <code>narwhals.stable.v1</code>,     see perfect backwards compatibility policy.</p> <code>None</code> <code>pass_through</code> <code>bool | None</code> <p>Determine what happens if the object can't be converted to Narwhals:</p> <ul> <li><code>False</code> or <code>None</code> (default): raise an error</li> <li><code>True</code>: pass object through as-is</li> </ul> <code>None</code> <code>eager_only</code> <code>bool</code> <p>Whether to only allow eager objects:</p> <ul> <li><code>False</code> (default): don't require <code>native_object</code> to be eager</li> <li><code>True</code>: only convert to Narwhals if <code>native_object</code> is eager</li> </ul> <code>False</code> <code>series_only</code> <code>bool</code> <p>Whether to only allow Series:</p> <ul> <li><code>False</code> (default): don't require <code>native_object</code> to be a Series</li> <li><code>True</code>: only convert to Narwhals if <code>native_object</code> is a Series</li> </ul> <code>False</code> <code>allow_series</code> <code>bool | None</code> <p>Whether to allow Series (default is only Dataframe / Lazyframe):</p> <ul> <li><code>False</code> or <code>None</code> (default): don't convert to Narwhals if <code>native_object</code> is a Series</li> <li><code>True</code>: allow <code>native_object</code> to be a Series</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>LazyFrame[IntoFrameT] | DataFrame[IntoFrameT] | Series[IntoSeriesT] | T</code> <p>DataFrame, LazyFrame, Series, or original object, depending on which combination of parameters was passed.</p>"},{"location":"api-reference/narwhals/#narwhals.from_numpy","title":"<code>from_numpy(data, schema=None, *, native_namespace)</code>","text":"<p>Construct a DataFrame from a NumPy ndarray.</p> Notes <p>Only row orientation is currently supported.</p> <p>For pandas-like dataframes, conversion to schema is applied after dataframe creation.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Two-dimensional data represented as a NumPy ndarray.</p> required <code>schema</code> <code>dict[str, DType] | Schema | list[str] | None</code> <p>The DataFrame schema as Schema, dict of {name: type}, or a list of str.</p> <code>None</code> <code>native_namespace</code> <code>ModuleType</code> <p>The native library to use for DataFrame creation.</p> required <p>Returns:</p> Type Description <code>DataFrame[Any]</code> <p>A new DataFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [3, 4]}\n</code></pre> <p>Let's create a new dataframe of the same class as the dataframe we started with, from a NumPy ndarray of new data:</p> <pre><code>&gt;&gt;&gt; def agnostic_from_numpy(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     new_data = np.array([[5, 2, 1], [1, 4, 3]])\n...     df = nw.from_native(df_native)\n...     native_namespace = nw.get_native_namespace(df)\n...     return nw.from_numpy(new_data, native_namespace=native_namespace).to_native()\n</code></pre> <p>Let's see what happens when passing pandas, Polars or PyArrow input:</p> <pre><code>&gt;&gt;&gt; agnostic_from_numpy(pd.DataFrame(data))\n   column_0  column_1  column_2\n0         5         2         1\n1         1         4         3\n&gt;&gt;&gt; agnostic_from_numpy(pl.DataFrame(data))\nshape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 column_0 \u2506 column_1 \u2506 column_2 \u2502\n\u2502 ---      \u2506 ---      \u2506 ---      \u2502\n\u2502 i64      \u2506 i64      \u2506 i64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 5        \u2506 2        \u2506 1        \u2502\n\u2502 1        \u2506 4        \u2506 3        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_from_numpy(pa.table(data))\npyarrow.Table\ncolumn_0: int64\ncolumn_1: int64\ncolumn_2: int64\n----\ncolumn_0: [[5,1]]\ncolumn_1: [[2,4]]\ncolumn_2: [[1,3]]\n</code></pre> <p>Let's specify the column names:</p> <pre><code>&gt;&gt;&gt; def agnostic_from_numpy(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     new_data = np.array([[5, 2, 1], [1, 4, 3]])\n...     schema = [\"c\", \"d\", \"e\"]\n...     df = nw.from_native(df_native)\n...     native_namespace = nw.get_native_namespace(df)\n...     return nw.from_numpy(\n...         new_data, native_namespace=native_namespace, schema=schema\n...     ).to_native()\n</code></pre> <p>Let's see the modified outputs:</p> <pre><code>&gt;&gt;&gt; agnostic_from_numpy(pd.DataFrame(data))\n   c  d  e\n0  5  2  1\n1  1  4  3\n&gt;&gt;&gt; agnostic_from_numpy(pl.DataFrame(data))\nshape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 c   \u2506 d   \u2506 e   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 5   \u2506 2   \u2506 1   \u2502\n\u2502 1   \u2506 4   \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_from_numpy(pa.table(data))\npyarrow.Table\nc: int64\nd: int64\ne: int64\n----\nc: [[5,1]]\nd: [[2,4]]\ne: [[1,3]]\n</code></pre> <p>Let's modify the function so that it specifies the schema:</p> <pre><code>&gt;&gt;&gt; def agnostic_from_numpy(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     new_data = np.array([[5, 2, 1], [1, 4, 3]])\n...     schema = {\"c\": nw.Int16(), \"d\": nw.Float32(), \"e\": nw.Int8()}\n...     df = nw.from_native(df_native)\n...     native_namespace = nw.get_native_namespace(df)\n...     return nw.from_numpy(\n...         new_data, native_namespace=native_namespace, schema=schema\n...     ).to_native()\n</code></pre> <p>Let's see the outputs:</p> <pre><code>&gt;&gt;&gt; agnostic_from_numpy(pd.DataFrame(data))\n   c    d  e\n0  5  2.0  1\n1  1  4.0  3\n&gt;&gt;&gt; agnostic_from_numpy(pl.DataFrame(data))\nshape: (2, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 c   \u2506 d   \u2506 e   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i16 \u2506 f32 \u2506 i8  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 5   \u2506 2.0 \u2506 1   \u2502\n\u2502 1   \u2506 4.0 \u2506 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_from_numpy(pa.table(data))\npyarrow.Table\nc: int16\nd: float\ne: int8\n----\nc: [[5,1]]\nd: [[2,4]]\ne: [[1,3]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.generate_temporary_column_name","title":"<code>generate_temporary_column_name(n_bytes, columns)</code>","text":"<p>Generates a unique column name that is not present in the given list of columns.</p> <p>It relies on python secrets token_hex function to return a string nbytes random bytes.</p> <p>Parameters:</p> Name Type Description Default <code>n_bytes</code> <code>int</code> <p>The number of bytes to generate for the token.</p> required <code>columns</code> <code>list[str]</code> <p>The list of columns to check for uniqueness.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A unique token that is not present in the given list of columns.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If a unique token cannot be generated after 100 attempts.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; columns = [\"abc\", \"xyz\"]\n&gt;&gt;&gt; nw.generate_temporary_column_name(n_bytes=8, columns=columns) not in columns\nTrue\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.get_level","title":"<code>get_level(obj)</code>","text":"<p>Level of support Narwhals has for current object.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>DataFrame[Any] | LazyFrame[Any] | Series[IntoSeriesT]</code> <p>Dataframe or Series.</p> required <p>Returns:</p> Type Description <code>Literal['full', 'lazy', 'interchange']</code> <p>This can be one of:</p> <ul> <li>'full': full Narwhals API support</li> <li>'lazy': only lazy operations are supported. This excludes anything   which involves iterating over rows in Python.</li> <li>'interchange': only metadata operations are supported (<code>df.schema</code>)</li> </ul>"},{"location":"api-reference/narwhals/#narwhals.get_native_namespace","title":"<code>get_native_namespace(obj)</code>","text":"<p>Get native namespace from object.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>DataFrame[Any] | LazyFrame[Any] | Series[Any] | DataFrame | Series | DataFrame | LazyFrame | Series | Table | ChunkedArray</code> <p>Dataframe, Lazyframe, or Series.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Native module.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; df = nw.from_native(pd.DataFrame({\"a\": [1, 2, 3]}))\n&gt;&gt;&gt; nw.get_native_namespace(df)\n&lt;module 'pandas'...&gt;\n&gt;&gt;&gt; df = nw.from_native(pl.DataFrame({\"a\": [1, 2, 3]}))\n&gt;&gt;&gt; nw.get_native_namespace(df)\n&lt;module 'polars'...&gt;\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.is_ordered_categorical","title":"<code>is_ordered_categorical(series)</code>","text":"<p>Return whether indices of categories are semantically meaningful.</p> <p>This is a convenience function to accessing what would otherwise be the <code>is_ordered</code> property from the DataFrame Interchange Protocol, see https://data-apis.org/dataframe-protocol/latest/API.html.</p> <ul> <li>For Polars:</li> <li>Enums are always ordered.</li> <li>Categoricals are ordered if <code>dtype.ordering == \"physical\"</code>.</li> <li>For pandas-like APIs:</li> <li>Categoricals are ordered if <code>dtype.cat.ordered == True</code>.</li> <li>For PyArrow table:</li> <li>Categoricals are ordered if <code>dtype.type.ordered == True</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series[Any]</code> <p>Input Series.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether the Series is an ordered categorical.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; data = [\"x\", \"y\"]\n&gt;&gt;&gt; s_pd = pd.Series(data, dtype=pd.CategoricalDtype(ordered=True))\n&gt;&gt;&gt; s_pl = pl.Series(data, dtype=pl.Categorical(ordering=\"physical\"))\n</code></pre> <p>Let's define a library-agnostic function:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def func(s):\n...     return nw.is_ordered_categorical(s)\n</code></pre> <p>Then, we can pass any supported library to <code>func</code>:</p> <pre><code>&gt;&gt;&gt; func(s_pd)\nTrue\n&gt;&gt;&gt; func(s_pl)\nTrue\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.len","title":"<code>len()</code>","text":"<p>Return the number of rows.</p> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [5, 10]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_len(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.len()).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_len</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_len(df_pd)\n   len\n0    2\n&gt;&gt;&gt; agnostic_len(df_pl)\nshape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 len \u2502\n\u2502 --- \u2502\n\u2502 u32 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_len(df_pa)\npyarrow.Table\nlen: int64\n----\nlen: [[2]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.lit","title":"<code>lit(value, dtype=None)</code>","text":"<p>Return an expression representing a literal value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>The value to use as literal.</p> required <code>dtype</code> <code>DType | type[DType] | None</code> <p>The data type of the literal value. If not provided, the data type will be inferred.</p> <code>None</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2]}\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_lit(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(nw.lit(3)).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_lit</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_lit(df_pd)\n   a  literal\n0  1        3\n1  2        3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_lit(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 literal \u2502\n\u2502 --- \u2506 ---     \u2502\n\u2502 i64 \u2506 i32     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 3       \u2502\n\u2502 2   \u2506 3       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_lit(df_pa)\npyarrow.Table\na: int64\nliteral: int64\n----\na: [[1,2]]\nliteral: [[3,3]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.max","title":"<code>max(*columns)</code>","text":"<p>Return the maximum value.</p> Note <p>Syntactic sugar for <code>nw.col(columns).max()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str</code> <p>Name(s) of the columns to use in the aggregation function.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [5, 10]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_max(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.max(\"a\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_max</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_max(df_pd)\n   a\n0  2\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_max(df_pl)\nshape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_max(df_pa)\npyarrow.Table\na: int64\n----\na: [[2]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.max_horizontal","title":"<code>max_horizontal(*exprs)</code>","text":"<p>Get the maximum value horizontally across columns.</p> Notes <p>We support <code>max_horizontal</code> over numeric columns only.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Name(s) of the columns to use in the aggregation function. Accepts expression input.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 8, 3],\n...     \"b\": [4, 5, None],\n...     \"c\": [\"x\", \"y\", \"z\"],\n... }\n</code></pre> <p>We define a dataframe-agnostic function that computes the horizontal max of \"a\" and \"b\" columns:</p> <pre><code>&gt;&gt;&gt; def agnostic_max_horizontal(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.max_horizontal(\"a\", \"b\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_max_horizontal</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_max_horizontal(pd.DataFrame(data))\n     a\n0  4.0\n1  8.0\n2  3.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_max_horizontal(pl.DataFrame(data))\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 4   \u2502\n\u2502 8   \u2502\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_max_horizontal(pa.table(data))\npyarrow.Table\na: int64\n----\na: [[4,8,3]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.maybe_align_index","title":"<code>maybe_align_index(lhs, rhs)</code>","text":"<p>Align <code>lhs</code> to the Index of <code>rhs</code>, if they're both pandas-like.</p> <p>Parameters:</p> Name Type Description Default <code>lhs</code> <code>FrameOrSeriesT</code> <p>Dataframe or Series.</p> required <code>rhs</code> <code>Series[Any] | DataFrame[Any] | LazyFrame[Any]</code> <p>Dataframe or Series to align with.</p> required <p>Returns:</p> Type Description <code>FrameOrSeriesT</code> <p>Same type as input.</p> Notes <p>This is only really intended for backwards-compatibility purposes, for example if your library already aligns indices for users. If you're designing a new library, we highly encourage you to not rely on the Index. For non-pandas-like inputs, this only checks that <code>lhs</code> and <code>rhs</code> are the same length.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; df_pd = pd.DataFrame({\"a\": [1, 2]}, index=[3, 4])\n&gt;&gt;&gt; s_pd = pd.Series([6, 7], index=[4, 3])\n&gt;&gt;&gt; df = nw.from_native(df_pd)\n&gt;&gt;&gt; s = nw.from_native(s_pd, series_only=True)\n&gt;&gt;&gt; nw.to_native(nw.maybe_align_index(df, s))\n   a\n4  2\n3  1\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.maybe_convert_dtypes","title":"<code>maybe_convert_dtypes(obj, *args, **kwargs)</code>","text":"<p>Convert columns or series to the best possible dtypes using dtypes supporting <code>pd.NA</code>, if df is pandas-like.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>FrameOrSeriesT</code> <p>DataFrame or Series.</p> required <code>*args</code> <code>bool</code> <p>Additional arguments which gets passed through.</p> <code>()</code> <code>**kwargs</code> <code>bool | str</code> <p>Additional arguments which gets passed through.</p> <code>{}</code> <p>Returns:</p> Type Description <code>FrameOrSeriesT</code> <p>Same type as input.</p> Notes <p>For non-pandas-like inputs, this is a no-op. Also, <code>args</code> and <code>kwargs</code> just get passed down to the underlying library as-is.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; df_pd = pd.DataFrame(\n...     {\n...         \"a\": pd.Series([1, 2, 3], dtype=np.dtype(\"int32\")),\n...         \"b\": pd.Series([True, False, np.nan], dtype=np.dtype(\"O\")),\n...     }\n... )\n&gt;&gt;&gt; df = nw.from_native(df_pd)\n&gt;&gt;&gt; nw.to_native(nw.maybe_convert_dtypes(df)).dtypes\na             Int32\nb           boolean\ndtype: object\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.maybe_get_index","title":"<code>maybe_get_index(obj)</code>","text":"<p>Get the index of a DataFrame or a Series, if it's pandas-like.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>DataFrame[Any] | LazyFrame[Any] | Series[Any]</code> <p>Dataframe or Series.</p> required <p>Returns:</p> Type Description <code>Any | None</code> <p>Same type as input.</p> Notes <p>This is only really intended for backwards-compatibility purposes, for example if your library already aligns indices for users. If you're designing a new library, we highly encourage you to not rely on the Index. For non-pandas-like inputs, this returns <code>None</code>.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; df_pd = pd.DataFrame({\"a\": [1, 2], \"b\": [4, 5]})\n&gt;&gt;&gt; df = nw.from_native(df_pd)\n&gt;&gt;&gt; nw.maybe_get_index(df)\nRangeIndex(start=0, stop=2, step=1)\n&gt;&gt;&gt; series_pd = pd.Series([1, 2])\n&gt;&gt;&gt; series = nw.from_native(series_pd, series_only=True)\n&gt;&gt;&gt; nw.maybe_get_index(series)\nRangeIndex(start=0, stop=2, step=1)\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.maybe_reset_index","title":"<code>maybe_reset_index(obj)</code>","text":"<p>Reset the index to the default integer index of a DataFrame or a Series, if it's pandas-like.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>FrameOrSeriesT</code> <p>Dataframe or Series.</p> required <p>Returns:</p> Type Description <code>FrameOrSeriesT</code> <p>Same type as input.</p> Notes <p>This is only really intended for backwards-compatibility purposes, for example if your library already resets the index for users. If you're designing a new library, we highly encourage you to not rely on the Index. For non-pandas-like inputs, this is a no-op.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; df_pd = pd.DataFrame({\"a\": [1, 2], \"b\": [4, 5]}, index=([6, 7]))\n&gt;&gt;&gt; df = nw.from_native(df_pd)\n&gt;&gt;&gt; nw.to_native(nw.maybe_reset_index(df))\n   a  b\n0  1  4\n1  2  5\n&gt;&gt;&gt; series_pd = pd.Series([1, 2])\n&gt;&gt;&gt; series = nw.from_native(series_pd, series_only=True)\n&gt;&gt;&gt; nw.maybe_get_index(series)\nRangeIndex(start=0, stop=2, step=1)\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.maybe_set_index","title":"<code>maybe_set_index(obj, column_names=None, *, index=None)</code>","text":"<p>Set the index of a DataFrame or a Series, if it's pandas-like.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>FrameOrSeriesT</code> <p>object for which maybe set the index (can be either a Narwhals <code>DataFrame</code> or <code>Series</code>).</p> required <code>column_names</code> <code>str | list[str] | None</code> <p>name or list of names of the columns to set as index. For dataframes, only one of <code>column_names</code> and <code>index</code> can be specified but not both. If <code>column_names</code> is passed and <code>df</code> is a Series, then a <code>ValueError</code> is raised.</p> <code>None</code> <code>index</code> <code>Series[IntoSeriesT] | list[Series[IntoSeriesT]] | None</code> <p>series or list of series to set as index.</p> <code>None</code> <p>Returns:</p> Type Description <code>FrameOrSeriesT</code> <p>Same type as input.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If one of the following condition happens:</p> <ul> <li>none of <code>column_names</code> and <code>index</code> are provided</li> <li>both <code>column_names</code> and <code>index</code> are provided</li> <li><code>column_names</code> is provided and <code>df</code> is a Series</li> </ul> Notes <p>This is only really intended for backwards-compatibility purposes, for example if your library already aligns indices for users. If you're designing a new library, we highly encourage you to not rely on the Index.</p> <p>For non-pandas-like inputs, this is a no-op.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; df_pd = pd.DataFrame({\"a\": [1, 2], \"b\": [4, 5]})\n&gt;&gt;&gt; df = nw.from_native(df_pd)\n&gt;&gt;&gt; nw.to_native(nw.maybe_set_index(df, \"b\"))\n   a\nb\n4  1\n5  2\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.mean","title":"<code>mean(*columns)</code>","text":"<p>Get the mean value.</p> Note <p>Syntactic sugar for <code>nw.col(columns).mean()</code></p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str</code> <p>Name(s) of the columns to use in the aggregation function</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 8, 3]}\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_mean(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.mean(\"a\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_mean</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_mean(df_pd)\n     a\n0  4.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mean(df_pl)\nshape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 4.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mean(df_pa)\npyarrow.Table\na: double\n----\na: [[4]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.mean_horizontal","title":"<code>mean_horizontal(*exprs)</code>","text":"<p>Compute the mean of all values horizontally across columns.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Name(s) of the columns to use in the aggregation function. Accepts expression input.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 8, 3],\n...     \"b\": [4, 5, None],\n...     \"c\": [\"x\", \"y\", \"z\"],\n... }\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function that computes the horizontal mean of \"a\" and \"b\" columns:</p> <pre><code>&gt;&gt;&gt; def agnostic_mean_horizontal(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.mean_horizontal(\"a\", \"b\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_mean_horizontal</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_mean_horizontal(df_pd)\n     a\n0  2.5\n1  6.5\n2  3.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mean_horizontal(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2.5 \u2502\n\u2502 6.5 \u2502\n\u2502 3.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mean_horizontal(df_pa)\npyarrow.Table\na: double\n----\na: [[2.5,6.5,3]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.median","title":"<code>median(*columns)</code>","text":"<p>Get the median value.</p> Notes <ul> <li>Syntactic sugar for <code>nw.col(columns).median()</code></li> <li>Results might slightly differ across backends due to differences in the     underlying algorithms used to compute the median.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str</code> <p>Name(s) of the columns to use in the aggregation function</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [4, 5, 2]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_median(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.median(\"a\")).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_median</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_median(df_pd)\n     a\n0  4.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_median(df_pl)\nshape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 4.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_median(df_pa)\npyarrow.Table\na: double\n----\na: [[4]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.min","title":"<code>min(*columns)</code>","text":"<p>Return the minimum value.</p> Note <p>Syntactic sugar for <code>nw.col(columns).min()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str</code> <p>Name(s) of the columns to use in the aggregation function.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [5, 10]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_min(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.min(\"b\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_min</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_min(df_pd)\n   b\n0  5\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min(df_pl)\nshape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 b   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 5   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min(df_pa)\npyarrow.Table\nb: int64\n----\nb: [[5]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.min_horizontal","title":"<code>min_horizontal(*exprs)</code>","text":"<p>Get the minimum value horizontally across columns.</p> Notes <p>We support <code>min_horizontal</code> over numeric columns only.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Name(s) of the columns to use in the aggregation function. Accepts expression input.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"a\": [1, 8, 3],\n...     \"b\": [4, 5, None],\n...     \"c\": [\"x\", \"y\", \"z\"],\n... }\n</code></pre> <p>We define a dataframe-agnostic function that computes the horizontal min of \"a\" and \"b\" columns:</p> <pre><code>&gt;&gt;&gt; def agnostic_min_horizontal(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.min_horizontal(\"a\", \"b\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_min_horizontal</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_min_horizontal(pd.DataFrame(data))\n     a\n0  1.0\n1  5.0\n2  3.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min_horizontal(pl.DataFrame(data))\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2502 5   \u2502\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min_horizontal(pa.table(data))\npyarrow.Table\na: int64\n----\na: [[1,5,3]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.narwhalify","title":"<code>narwhalify(func=None, *, strict=None, pass_through=None, eager_only=False, series_only=False, allow_series=True)</code>","text":"<p>Decorate function so it becomes dataframe-agnostic.</p> <p>This will try to convert any dataframe/series-like object into the Narwhals respective DataFrame/Series, while leaving the other parameters as they are. Similarly, if the output of the function is a Narwhals DataFrame or Series, it will be converted back to the original dataframe/series type, while if the output is another type it will be left as is. By setting <code>pass_through=False</code>, then every input and every output will be required to be a dataframe/series-like object.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable[..., Any] | None</code> <p>Function to wrap in a <code>from_native</code>-<code>to_native</code> block.</p> <code>None</code> <code>strict</code> <code>bool | None</code> <p>Deprecated (v1.13.0): Please use <code>pass_through</code> instead. Note that <code>strict</code> is still available (and won't emit a deprecation warning) if you use <code>narwhals.stable.v1</code>, see perfect backwards compatibility policy.</p> <p>Determine what happens if the object can't be converted to Narwhals:</p> <ul> <li><code>True</code> or <code>None</code> (default): raise an error</li> <li><code>False</code>: pass object through as-is</li> </ul> <code>None</code> <code>pass_through</code> <code>bool | None</code> <p>Determine what happens if the object can't be converted to Narwhals:</p> <ul> <li><code>False</code> or <code>None</code> (default): raise an error</li> <li><code>True</code>: pass object through as-is</li> </ul> <code>None</code> <code>eager_only</code> <code>bool</code> <p>Whether to only allow eager objects:</p> <ul> <li><code>False</code> (default): don't require <code>native_object</code> to be eager</li> <li><code>True</code>: only convert to Narwhals if <code>native_object</code> is eager</li> </ul> <code>False</code> <code>series_only</code> <code>bool</code> <p>Whether to only allow Series:</p> <ul> <li><code>False</code> (default): don't require <code>native_object</code> to be a Series</li> <li><code>True</code>: only convert to Narwhals if <code>native_object</code> is a Series</li> </ul> <code>False</code> <code>allow_series</code> <code>bool | None</code> <p>Whether to allow Series (default is only Dataframe / Lazyframe):</p> <ul> <li><code>False</code> or <code>None</code>: don't convert to Narwhals if <code>native_object</code> is a Series</li> <li><code>True</code> (default): allow <code>native_object</code> to be a Series</li> </ul> <code>True</code> <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>Decorated function.</p> <p>Examples:</p> <p>Instead of writing</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; def agnostic_group_by_sum(df):\n...     df = nw.from_native(df, pass_through=True)\n...     df = df.group_by(\"a\").agg(nw.col(\"b\").sum())\n...     return nw.to_native(df)\n</code></pre> <p>you can just write</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def agnostic_group_by_sum(df):\n...     return df.group_by(\"a\").agg(nw.col(\"b\").sum())\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.new_series","title":"<code>new_series(name, values, dtype=None, *, native_namespace)</code>","text":"<p>Instantiate Narwhals Series from iterable (e.g. list or array).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Name of resulting Series.</p> required <code>values</code> <code>Any</code> <p>Values of make Series from.</p> required <code>dtype</code> <code>DType | type[DType] | None</code> <p>(Narwhals) dtype. If not provided, the native library may auto-infer it from <code>values</code>.</p> <code>None</code> <code>native_namespace</code> <code>ModuleType</code> <p>The native library to use for DataFrame creation.</p> required <p>Returns:</p> Type Description <code>Series[Any]</code> <p>A new Series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT, IntoSeriesT\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_new_series(df_native: IntoFrameT) -&gt; IntoSeriesT:\n...     values = [4, 1, 2, 3]\n...     native_namespace = nw.get_native_namespace(df_native)\n...     return nw.new_series(\n...         name=\"a\",\n...         values=values,\n...         dtype=nw.Int32,\n...         native_namespace=native_namespace,\n...     ).to_native()\n</code></pre> <p>We can then pass any supported eager library, such as pandas / Polars / PyArrow:</p> <pre><code>&gt;&gt;&gt; agnostic_new_series(pd.DataFrame(data))\n0    4\n1    1\n2    2\n3    3\nName: a, dtype: int32\n&gt;&gt;&gt; agnostic_new_series(pl.DataFrame(data))\nshape: (4,)\nSeries: 'a' [i32]\n[\n   4\n   1\n   2\n   3\n]\n&gt;&gt;&gt; agnostic_new_series(pa.table(data))\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    4,\n    1,\n    2,\n    3\n  ]\n]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.nth","title":"<code>nth(*indices)</code>","text":"<p>Creates an expression that references one or more columns by their index(es).</p> Notes <p><code>nth</code> is not supported for Polars version&lt;1.0.0. Please use <code>narwhals.col</code> instead.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>int | Sequence[int]</code> <p>One or more indices representing the columns to retrieve.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [3, 4]}\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_nth(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.nth(0) * 2).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_nth</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_nth(df_pd)\n   a\n0  2\n1  4\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_nth(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2502\n\u2502 4   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_nth(df_pa)\npyarrow.Table\na: int64\n----\na: [[2,4]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.read_csv","title":"<code>read_csv(source, *, native_namespace, **kwargs)</code>","text":"<p>Read a CSV file into a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Path to a file.</p> required <code>native_namespace</code> <code>ModuleType</code> <p>The native library to use for DataFrame creation.</p> required <code>kwargs</code> <code>Any</code> <p>Extra keyword arguments which are passed to the native CSV reader. For example, you could use <code>nw.read_csv('file.csv', native_namespace=pd, engine='pyarrow')</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame[Any]</code> <p>DataFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from types import ModuleType\n</code></pre> <p>Let's create an agnostic function that reads a csv file with a specified native namespace:</p> <pre><code>&gt;&gt;&gt; def agnostic_read_csv(native_namespace: ModuleType) -&gt; IntoDataFrame:\n...     return nw.read_csv(\"file.csv\", native_namespace=native_namespace).to_native()\n</code></pre> <p>Then we can read the file by passing pandas, Polars or PyArrow namespaces:</p> <pre><code>&gt;&gt;&gt; agnostic_read_csv(native_namespace=pd)\n   a  b\n0  1  4\n1  2  5\n2  3  6\n&gt;&gt;&gt; agnostic_read_csv(native_namespace=pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4   \u2502\n\u2502 2   \u2506 5   \u2502\n\u2502 3   \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_read_csv(native_namespace=pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[1,2,3]]\nb: [[4,5,6]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.read_parquet","title":"<code>read_parquet(source, *, native_namespace, **kwargs)</code>","text":"<p>Read into a DataFrame from a parquet file.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Path to a file.</p> required <code>native_namespace</code> <code>ModuleType</code> <p>The native library to use for DataFrame creation.</p> required <code>kwargs</code> <code>Any</code> <p>Extra keyword arguments which are passed to the native parquet reader. For example, you could use <code>nw.read_parquet('file.parquet', native_namespace=pd, engine='pyarrow')</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame[Any]</code> <p>DataFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from types import ModuleType\n</code></pre> <p>Let's create an agnostic function that reads a parquet file with a specified native namespace:</p> <pre><code>&gt;&gt;&gt; def agnostic_read_parquet(native_namespace: ModuleType) -&gt; IntoDataFrame:\n...     return nw.read_parquet(\n...         \"file.parquet\", native_namespace=native_namespace\n...     ).to_native()\n</code></pre> <p>Then we can read the file by passing pandas, Polars or PyArrow namespaces:</p> <pre><code>&gt;&gt;&gt; agnostic_read_parquet(native_namespace=pd)\n   a  b\n0  1  4\n1  2  5\n2  3  6\n&gt;&gt;&gt; agnostic_read_parquet(native_namespace=pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4   \u2502\n\u2502 2   \u2506 5   \u2502\n\u2502 3   \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_read_parquet(native_namespace=pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[1,2,3]]\nb: [[4,5,6]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.scan_csv","title":"<code>scan_csv(source, *, native_namespace, **kwargs)</code>","text":"<p>Lazily read from a CSV file.</p> <p>For the libraries that do not support lazy dataframes, the function reads a csv file eagerly and then converts the resulting dataframe to a lazyframe.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Path to a file.</p> required <code>native_namespace</code> <code>ModuleType</code> <p>The native library to use for DataFrame creation.</p> required <code>kwargs</code> <code>Any</code> <p>Extra keyword arguments which are passed to the native CSV reader. For example, you could use <code>nw.scan_csv('file.csv', native_namespace=pd, engine='pyarrow')</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LazyFrame[Any]</code> <p>LazyFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt; from types import ModuleType\n</code></pre> <p>Let's create an agnostic function that lazily reads a csv file with a specified native namespace:</p> <pre><code>&gt;&gt;&gt; def agnostic_scan_csv(native_namespace: ModuleType) -&gt; IntoFrame:\n...     return nw.scan_csv(\"file.csv\", native_namespace=native_namespace).to_native()\n</code></pre> <p>Then we can read the file by passing, for example, Polars or Dask namespaces:</p> <pre><code>&gt;&gt;&gt; agnostic_scan_csv(native_namespace=pl).collect()\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4   \u2502\n\u2502 2   \u2506 5   \u2502\n\u2502 3   \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_scan_csv(native_namespace=dd).compute()\n   a  b\n0  1  4\n1  2  5\n2  3  6\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.scan_parquet","title":"<code>scan_parquet(source, *, native_namespace, **kwargs)</code>","text":"<p>Lazily read from a parquet file.</p> <p>For the libraries that do not support lazy dataframes, the function reads a parquet file eagerly and then converts the resulting dataframe to a lazyframe.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>str</code> <p>Path to a file.</p> required <code>native_namespace</code> <code>ModuleType</code> <p>The native library to use for DataFrame creation.</p> required <code>kwargs</code> <code>Any</code> <p>Extra keyword arguments which are passed to the native parquet reader. For example, you could use <code>nw.scan_parquet('file.parquet', native_namespace=pd, engine='pyarrow')</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>LazyFrame[Any]</code> <p>LazyFrame.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import dask.dataframe as dd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt; from types import ModuleType\n</code></pre> <p>Let's create an agnostic function that lazily reads a parquet file with a specified native namespace:</p> <pre><code>&gt;&gt;&gt; def agnostic_scan_parquet(native_namespace: ModuleType) -&gt; IntoFrame:\n...     return nw.scan_parquet(\n...         \"file.parquet\", native_namespace=native_namespace\n...     ).to_native()\n</code></pre> <p>Then we can read the file by passing, for example, Polars or Dask namespaces:</p> <pre><code>&gt;&gt;&gt; agnostic_scan_parquet(native_namespace=pl).collect()\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4   \u2502\n\u2502 2   \u2506 5   \u2502\n\u2502 3   \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n&gt;&gt;&gt; agnostic_scan_parquet(native_namespace=dd).compute()\n   a  b\n0  1  4\n1  2  5\n2  3  6\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.sum","title":"<code>sum(*columns)</code>","text":"<p>Sum all values.</p> Note <p>Syntactic sugar for <code>nw.col(columns).sum()</code></p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str</code> <p>Name(s) of the columns to use in the aggregation function</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2]}\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_sum(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.sum(\"a\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_sum</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_sum(df_pd)\n   a\n0  3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sum(df_pl)\nshape: (1, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sum(df_pa)\npyarrow.Table\na: int64\n----\na: [[3]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.sum_horizontal","title":"<code>sum_horizontal(*exprs)</code>","text":"<p>Sum all values horizontally across columns.</p> Warning <p>Unlike Polars, we support horizontal sum over numeric columns only.</p> <p>Parameters:</p> Name Type Description Default <code>exprs</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Name(s) of the columns to use in the aggregation function. Accepts expression input.</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [5, 10, None]}\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_sum_horizontal(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.select(nw.sum_horizontal(\"a\", \"b\")).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_sum_horizontal</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_sum_horizontal(df_pd)\n      a\n0   6.0\n1  12.0\n2   3.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sum_horizontal(df_pl)\nshape: (3, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 6   \u2502\n\u2502 12  \u2502\n\u2502 3   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sum_horizontal(df_pa)\npyarrow.Table\na: int64\n----\na: [[6,12,3]]\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.show_versions","title":"<code>show_versions()</code>","text":"<p>Print useful debugging information.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from narwhals import show_versions\n&gt;&gt;&gt; show_versions()\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.to_native","title":"<code>to_native(narwhals_object, *, strict=None, pass_through=None)</code>","text":"<p>Convert Narwhals object to native one.</p> <p>Parameters:</p> Name Type Description Default <code>narwhals_object</code> <code>DataFrame[IntoFrameT] | LazyFrame[IntoFrameT] | Series[IntoSeriesT]</code> <p>Narwhals object.</p> required <code>strict</code> <code>bool | None</code> <p>Determine what happens if <code>narwhals_object</code> isn't a Narwhals class:</p> <ul> <li><code>True</code> (default): raise an error</li> <li><code>False</code>: pass object through as-is</li> </ul> <p>Deprecated (v1.13.0):     Please use <code>pass_through</code> instead. Note that <code>strict</code> is still available     (and won't emit a deprecation warning) if you use <code>narwhals.stable.v1</code>,     see perfect backwards compatibility policy.</p> <code>None</code> <code>pass_through</code> <code>bool | None</code> <p>Determine what happens if <code>narwhals_object</code> isn't a Narwhals class:</p> <ul> <li><code>False</code> (default): raise an error</li> <li><code>True</code>: pass object through as-is</li> </ul> <code>None</code> <p>Returns:</p> Type Description <code>IntoFrameT | Any</code> <p>Object of class that user started with.</p>"},{"location":"api-reference/narwhals/#narwhals.to_py_scalar","title":"<code>to_py_scalar(scalar_like)</code>","text":"<p>If a scalar is not Python native, converts it to Python native.</p> <p>Parameters:</p> Name Type Description Default <code>scalar_like</code> <code>Any</code> <p>Scalar-like value.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>Python scalar.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the object is not convertible to a scalar.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; df = nw.from_native(pd.DataFrame({\"a\": [1, 2, 3]}))\n&gt;&gt;&gt; nw.to_py_scalar(df[\"a\"].item(0))\n1\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; df = nw.from_native(pa.table({\"a\": [1, 2, 3]}))\n&gt;&gt;&gt; nw.to_py_scalar(df[\"a\"].item(0))\n1\n&gt;&gt;&gt; nw.to_py_scalar(1)\n1\n</code></pre>"},{"location":"api-reference/narwhals/#narwhals.when","title":"<code>when(*predicates)</code>","text":"<p>Start a <code>when-then-otherwise</code> expression.</p> <p>Expression similar to an <code>if-else</code> statement in Python. Always initiated by a <code>pl.when(&lt;condition&gt;).then(&lt;value if condition&gt;)</code>, and optionally followed by chaining one or more <code>.when(&lt;condition&gt;).then(&lt;value&gt;)</code> statements. Chained when-then operations should be read as Python <code>if, elif, ... elif</code> blocks, not as <code>if, if, ... if</code>, i.e. the first condition that evaluates to <code>True</code> will be picked. If none of the conditions are <code>True</code>, an optional <code>.otherwise(&lt;value if all statements are false&gt;)</code> can be appended at the end. If not appended, and none of the conditions are <code>True</code>, <code>None</code> will be returned.</p> <p>Parameters:</p> Name Type Description Default <code>predicates</code> <code>IntoExpr | Iterable[IntoExpr]</code> <p>Condition(s) that must be met in order to apply the subsequent statement. Accepts one or more boolean expressions, which are implicitly combined with <code>&amp;</code>. String input is parsed as a column name.</p> <code>()</code> <p>Returns:</p> Type Description <code>When</code> <p>A \"when\" object, which <code>.then</code> can be called on.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [5, 10, 15]}\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_when_then_otherwise(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(\n...         nw.when(nw.col(\"a\") &lt; 3).then(5).otherwise(6).alias(\"a_when\")\n...     ).to_native()\n</code></pre> <p>We can pass any supported library such as Pandas, Polars, or PyArrow to <code>agnostic_when_then_otherwise</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_when_then_otherwise(df_pd)\n   a   b  a_when\n0  1   5       5\n1  2  10       5\n2  3  15       6\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_when_then_otherwise(df_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 a_when \u2502\n\u2502 --- \u2506 --- \u2506 ---    \u2502\n\u2502 i64 \u2506 i64 \u2506 i32    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 5   \u2506 5      \u2502\n\u2502 2   \u2506 10  \u2506 5      \u2502\n\u2502 3   \u2506 15  \u2506 6      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_when_then_otherwise(df_pa)\npyarrow.Table\na: int64\nb: int64\na_when: int64\n----\na: [[1,2,3]]\nb: [[5,10,15]]\na_when: [[5,5,6]]\n</code></pre>"},{"location":"api-reference/schema/","title":"<code>narwhals.Schema</code>","text":"<p>Ordered mapping of column names to their data type.</p> <p>Parameters:</p> Name Type Description Default <code>schema</code> <code>Mapping[str, DType] | Iterable[tuple[str, DType]] | None</code> <p>Mapping[str, DType] | Iterable[tuple[str, DType]] | None The schema definition given by column names and their associated. instantiated Narwhals data type. Accepts a mapping or an iterable of tuples.</p> <code>None</code> <p>Examples:</p> <p>Define a schema by passing instantiated data types.</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; schema = nw.Schema({\"foo\": nw.Int8(), \"bar\": nw.String()})\n&gt;&gt;&gt; schema\nSchema({'foo': Int8, 'bar': String})\n</code></pre> <p>Access the data type associated with a specific column name.</p> <pre><code>&gt;&gt;&gt; schema[\"foo\"]\nInt8\n</code></pre> <p>Access various schema properties using the <code>names</code>, <code>dtypes</code>, and <code>len</code> methods.</p> <pre><code>&gt;&gt;&gt; schema.names()\n['foo', 'bar']\n&gt;&gt;&gt; schema.dtypes()\n[Int8, String]\n&gt;&gt;&gt; schema.len()\n2\n</code></pre>"},{"location":"api-reference/schema/#narwhals.schema.Schema.names","title":"<code>names()</code>","text":"<p>Get the column names of the schema.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>Column names.</p>"},{"location":"api-reference/schema/#narwhals.schema.Schema.dtypes","title":"<code>dtypes()</code>","text":"<p>Get the data types of the schema.</p> <p>Returns:</p> Type Description <code>list[DType]</code> <p>Data types of schema.</p>"},{"location":"api-reference/schema/#narwhals.schema.Schema.len","title":"<code>len()</code>","text":"<p>Get the number of columns in the schema.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of columns.</p>"},{"location":"api-reference/selectors/","title":"<code>narwhals.selectors</code>","text":"<p>The following selectors are all supported. In addition, just like in Polars, the following set operations are supported:</p> <ul> <li>set intersection: <code>&amp;</code></li> <li>set union: <code>|</code></li> <li>set difference: <code>-</code></li> <li>complement: <code>~</code></li> </ul>"},{"location":"api-reference/selectors/#narwhals.selectors.boolean","title":"<code>boolean()</code>","text":"<p>Select boolean columns.</p> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import narwhals.selectors as ncs\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [\"x\", \"y\"], \"c\": [False, True]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n</code></pre> <p>Let's define a dataframe-agnostic function to select boolean dtypes:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def func(df):\n...     return df.select(ncs.boolean())\n</code></pre> <p>We can then pass either pandas or Polars dataframes:</p> <pre><code>&gt;&gt;&gt; func(df_pd)\n       c\n0  False\n1   True\n&gt;&gt;&gt; func(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 c     \u2502\n\u2502 ---   \u2502\n\u2502 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 false \u2502\n\u2502 true  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/selectors/#narwhals.selectors.by_dtype","title":"<code>by_dtype(*dtypes)</code>","text":"<p>Select columns based on their dtype.</p> <p>Parameters:</p> Name Type Description Default <code>dtypes</code> <code>Any</code> <p>one or data types to select</p> <code>()</code> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import narwhals.selectors as ncs\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [\"x\", \"y\"], \"c\": [4.1, 2.3]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n</code></pre> <p>Let's define a dataframe-agnostic function to select int64 and float64 dtypes and multiplies each value by 2:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def func(df):\n...     return df.select(ncs.by_dtype(nw.Int64, nw.Float64) * 2)\n</code></pre> <p>We can then pass either pandas or Polars dataframes:</p> <pre><code>&gt;&gt;&gt; func(df_pd)\n   a    c\n0  2  8.2\n1  4  4.6\n&gt;&gt;&gt; func(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 8.2 \u2502\n\u2502 4   \u2506 4.6 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/selectors/#narwhals.selectors.categorical","title":"<code>categorical()</code>","text":"<p>Select categorical columns.</p> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import narwhals.selectors as ncs\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [\"x\", \"y\"], \"c\": [False, True]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data).astype({\"b\": \"category\"})\n&gt;&gt;&gt; df_pl = pl.DataFrame(data, schema_overrides={\"b\": pl.Categorical})\n</code></pre> <p>Let's define a dataframe-agnostic function to select string dtypes:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def func(df):\n...     return df.select(ncs.categorical())\n</code></pre> <p>We can then pass either pandas or Polars dataframes:</p> <pre><code>&gt;&gt;&gt; func(df_pd)\n   b\n0  x\n1  y\n&gt;&gt;&gt; func(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 b   \u2502\n\u2502 --- \u2502\n\u2502 cat \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 x   \u2502\n\u2502 y   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/selectors/#narwhals.selectors.matches","title":"<code>matches(pattern)</code>","text":"<p>Select all columns that match the given regex pattern.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>A valid regular expression pattern.</p> required <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import narwhals.selectors as ncs\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\n...     \"foo\": [\"x\", \"y\"],\n...     \"bar\": [123, 456],\n...     \"baz\": [2.0, 5.5],\n...     \"zap\": [0, 1],\n... }\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n</code></pre> <p>Let's define a dataframe-agnostic function to select column names containing an 'a', preceded by a character that is not 'z':</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def func(df):\n...     return df.select(ncs.matches(\"[^z]a\"))\n</code></pre> <p>We can then pass either pandas or Polars dataframes:</p> <pre><code>&gt;&gt;&gt; func(df_pd)\n   bar  baz\n0  123  2.0\n1  456  5.5\n&gt;&gt;&gt; func(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 bar \u2506 baz \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 123 \u2506 2.0 \u2502\n\u2502 456 \u2506 5.5 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/selectors/#narwhals.selectors.numeric","title":"<code>numeric()</code>","text":"<p>Select numeric columns.</p> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import narwhals.selectors as ncs\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [\"x\", \"y\"], \"c\": [4.1, 2.3]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n</code></pre> <p>Let's define a dataframe-agnostic function to select numeric dtypes and multiplies each value by 2:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def func(df):\n...     return df.select(ncs.numeric() * 2)\n</code></pre> <p>We can then pass either pandas or Polars dataframes:</p> <pre><code>&gt;&gt;&gt; func(df_pd)\n   a    c\n0  2  8.2\n1  4  4.6\n&gt;&gt;&gt; func(df_pl)\nshape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 2   \u2506 8.2 \u2502\n\u2502 4   \u2506 4.6 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/selectors/#narwhals.selectors.string","title":"<code>string()</code>","text":"<p>Select string columns.</p> <p>Returns:</p> Type Description <code>Expr</code> <p>A new expression.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import narwhals.selectors as ncs\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = {\"a\": [1, 2], \"b\": [\"x\", \"y\"], \"c\": [False, True]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n</code></pre> <p>Let's define a dataframe-agnostic function to select string dtypes:</p> <pre><code>&gt;&gt;&gt; @nw.narwhalify\n... def func(df):\n...     return df.select(ncs.string())\n</code></pre> <p>We can then pass either pandas or Polars dataframes:</p> <pre><code>&gt;&gt;&gt; func(df_pd)\n   b\n0  x\n1  y\n&gt;&gt;&gt; func(df_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 b   \u2502\n\u2502 --- \u2502\n\u2502 str \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 x   \u2502\n\u2502 y   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api-reference/series/","title":"<code>narwhals.Series</code>","text":"<p>Narwhals Series, backed by a native series.</p> <p>Warning</p> <p>This class is not meant to be instantiated directly - instead:</p> <ul> <li> <p>If the native object is a series from one of the supported backend (e.g.     pandas.Series, polars.Series, pyarrow.ChunkedArray), you can use     <code>narwhals.from_native</code>:     <pre><code>narwhals.from_native(native_series, allow_series=True)\nnarwhals.from_native(native_series, series_only=True)\n</code></pre></p> </li> <li> <p>If the object is a generic sequence (e.g. a list or a tuple of values), you can     create a series via <code>narwhals.new_series</code>:     <pre><code>narwhals.new_series(\n    name=name,\n    values=values,\n    native_namespace=narwhals.get_native_namespace(another_object),\n)\n</code></pre></p> </li> </ul>"},{"location":"api-reference/series/#narwhals.series.Series.dtype","title":"<code>dtype</code>  <code>property</code>","text":"<p>Get the data type of the Series.</p> <p>Returns:</p> Type Description <code>DType</code> <p>The data type of the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_dtype(s_native: IntoSeriesT) -&gt; nw.dtypes.DType:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dtype\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dtype</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dtype(s_pd)\nInt64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dtype(s_pl)\nInt64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dtype(s_pa)\nInt64\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.implementation","title":"<code>implementation</code>  <code>property</code>","text":"<p>Return implementation of native Series.</p> <p>This can be useful when you need to use special-casing for features outside of Narwhals' scope - for example, when dealing with pandas' Period Dtype.</p> <p>Returns:</p> Type Description <code>Implementation</code> <p>Implementation.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; import pandas as pd\n</code></pre> <pre><code>&gt;&gt;&gt; s_native = pd.Series([1, 2, 3])\n&gt;&gt;&gt; s = nw.from_native(s_native, series_only=True)\n</code></pre> <pre><code>&gt;&gt;&gt; s.implementation\n&lt;Implementation.PANDAS: 1&gt;\n</code></pre> <pre><code>&gt;&gt;&gt; s.implementation.is_pandas()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; s.implementation.is_pandas_like()\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; s.implementation.is_polars()\nFalse\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.name","title":"<code>name</code>  <code>property</code>","text":"<p>Get the name of the Series.</p> <p>Returns:</p> Type Description <code>str</code> <p>The name of the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data, name=\"foo\")\n&gt;&gt;&gt; s_pl = pl.Series(\"foo\", data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_name(s_native: IntoSeries) -&gt; str:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.name\n</code></pre> <p>We can then pass any supported library such as pandas or Polars to <code>agnostic_name</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_name(s_pd)\n'foo'\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_name(s_pl)\n'foo'\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.shape","title":"<code>shape</code>  <code>property</code>","text":"<p>Get the shape of the Series.</p> <p>Returns:</p> Type Description <code>tuple[int]</code> <p>A tuple containing the length of the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_shape(s_native: IntoSeries) -&gt; tuple[int]:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.shape\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_shape</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_shape(s_pd)\n(3,)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_shape(s_pl)\n(3,)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_shape(s_pa)\n(3,)\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.__arrow_c_stream__","title":"<code>__arrow_c_stream__(requested_schema=None)</code>","text":"<p>Export a Series via the Arrow PyCapsule Interface.</p> <p>Narwhals doesn't implement anything itself here:</p> <ul> <li>if the underlying series implements the interface, it'll return that</li> <li>else, it'll call <code>to_arrow</code> and then defer to PyArrow's implementation</li> </ul> <p>See PyCapsule Interface for more.</p>"},{"location":"api-reference/series/#narwhals.series.Series.__getitem__","title":"<code>__getitem__(idx)</code>","text":"<p>Retrieve elements from the object using integer indexing or slicing.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int | slice | Sequence[int]</code> <p>The index, slice, or sequence of indices to retrieve.</p> <ul> <li>If <code>idx</code> is an integer, a single element is returned.</li> <li>If <code>idx</code> is a slice or a sequence of integers,   a subset of the Series is returned.</li> </ul> required <p>Returns:</p> Type Description <code>Any | Self</code> <p>A single element if <code>idx</code> is an integer, else a subset of the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from typing import Any\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_get_first_item(s_native: IntoSeriesT) -&gt; Any:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s[0]\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_get_first_item</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_get_first_item(s_pd)\nnp.int64(1)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_get_first_item(s_pl)\n1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_get_first_item(s_pa)\n1\n</code></pre> <p>We can also make a function to slice the Series:</p> <pre><code>&gt;&gt;&gt; def agnostic_slice(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s[:2].to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_slice(s_pd)\n0    1\n1    2\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_slice(s_pl)\nshape: (2,)\nSeries: '' [i64]\n[\n    1\n    2\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_slice(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    2\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.__iter__","title":"<code>__iter__()</code>","text":""},{"location":"api-reference/series/#narwhals.series.Series.abs","title":"<code>abs()</code>","text":"<p>Calculate the absolute value of each element.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the absolute values of the original elements.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [2, -4, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_abs(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.abs().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_abs</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_abs(s_pd)\n0    2\n1    4\n2    3\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_abs(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   2\n   4\n   3\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_abs(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2,\n    4,\n    3\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.alias","title":"<code>alias(name)</code>","text":"<p>Rename the Series.</p> Notes <p>This method is very cheap, but does not guarantee that data will be copied. For example:</p> <pre><code>s1: nw.Series\ns2 = s1.alias(\"foo\")\narr = s2.to_numpy()\narr[0] = 999\n</code></pre> <p>may (depending on the backend, and on the version) result in <code>s1</code>'s data being modified. We recommend:</p> <pre><code>- if you need to alias an object and don't need the original\n  one around any more, just use `alias` without worrying about it.\n- if you were expecting `alias` to copy data, then explicily call\n  `.clone` before calling `alias`.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The new name.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the updated name.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data, name=\"foo\")\n&gt;&gt;&gt; s_pl = pl.Series(\"foo\", data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_alias(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.alias(\"bar\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas or Polars, or PyArrow to <code>agnostic_alias</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_alias(s_pd)\n0    1\n1    2\n2    3\nName: bar, dtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_alias(s_pl)\nshape: (3,)\nSeries: 'bar' [i64]\n[\n   1\n   2\n   3\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_alias(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at 0x...&gt;\n[\n  [\n    1,\n    2,\n    3\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.all","title":"<code>all()</code>","text":"<p>Return whether all values in the Series are True.</p> <p>Returns:</p> Type Description <code>bool</code> <p>A boolean indicating if all values in the Series are True.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [False, True, False]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_all(s_native: IntoSeries) -&gt; bool:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.all()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_all</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_all(s_pd)\nnp.False_\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_all(s_pl)\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_all(s_pa)\nFalse\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.any","title":"<code>any()</code>","text":"<p>Return whether any of the values in the Series are True.</p> Notes <p>Only works on Series of data type Boolean.</p> <p>Returns:</p> Type Description <code>bool</code> <p>A boolean indicating if any values in the Series are True.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [False, True, False]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_any(s_native: IntoSeries) -&gt; bool:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.any()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_any</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_any(s_pd)\nnp.True_\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_any(s_pl)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_any(s_pa)\nTrue\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.arg_max","title":"<code>arg_max()</code>","text":"<p>Returns the index of the maximum value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_arg_max(s_native: IntoSeries):\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.arg_max()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_arg_max</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_arg_max(s_pd)\nnp.int64(2)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_max(s_pl)\n2\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_max(s_pa)\n2\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.arg_min","title":"<code>arg_min()</code>","text":"<p>Returns the index of the minimum value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_arg_min(s_native: IntoSeries):\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.arg_min()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_arg_min</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_arg_min(s_pd)\nnp.int64(0)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_min(s_pl)\n0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_min(s_pa)\n0\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.arg_true","title":"<code>arg_true()</code>","text":"<p>Find elements where boolean Series is True.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the indices of elements that are True.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, None, None, 2]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_arg_true(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_null().arg_true().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_arg_true</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_arg_true(s_pd)\n1    1\n2    2\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_true(s_pl)\nshape: (2,)\nSeries: '' [u32]\n[\n   1\n   2\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_arg_true(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    2\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.cast","title":"<code>cast(dtype)</code>","text":"<p>Cast between data types.</p> <p>Parameters:</p> Name Type Description Default <code>dtype</code> <code>DType | type[DType]</code> <p>Data type that the object will be cast into.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the specified data type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [True, False, True]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cast(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.cast(nw.Int64).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cast</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cast(s_pd)\n0    1\n1    0\n2    1\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cast(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   1\n   0\n   1\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cast(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    0,\n    1\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.clip","title":"<code>clip(lower_bound=None, upper_bound=None)</code>","text":"<p>Clip values in the Series.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bound</code> <code>Self | Any | None</code> <p>Lower bound value.</p> <code>None</code> <code>upper_bound</code> <code>Self | Any | None</code> <p>Upper bound value.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with values clipped to the specified bounds.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_clip_lower(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.clip(2).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_clip_lower</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_clip_lower(s_pd)\n0    2\n1    2\n2    3\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_clip_lower(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   2\n   2\n   3\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_clip_lower(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2,\n    2,\n    3\n  ]\n]\n</code></pre> <p>We define another library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_clip_upper(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.clip(upper_bound=2).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or     PyArrow to <code>agnostic_clip_upper</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_clip_upper(s_pd)\n0    1\n1    2\n2    2\ndtype: int64\n\n&gt;&gt;&gt; agnostic_clip_upper(s_pl)  # doctest: +NORMALIZE_WHITESPACE\nshape: (3,)\nSeries: '' [i64]\n[\n   1\n   2\n   2\n]\n\n&gt;&gt;&gt; agnostic_clip_upper(s_pa)  # doctest: +ELLIPSIS\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    2,\n    2\n  ]\n]\n\nWe can have both at the same time\n\n&gt;&gt;&gt; data = [-1, 1, -3, 3, -5, 5]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n\nWe define a library agnostic function:\n\n&gt;&gt;&gt; def agnostic_clip(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.clip(-1, 3).to_native()\n\nWe can then pass any supported library such as pandas, Polars, or\nPyArrow to `agnostic_clip`:\n\n&gt;&gt;&gt; agnostic_clip(s_pd)\n0   -1\n1    1\n2   -1\n3    3\n4   -1\n5    3\ndtype: int64\n\n&gt;&gt;&gt; agnostic_clip(s_pl)  # doctest: +NORMALIZE_WHITESPACE\nshape: (6,)\nSeries: '' [i64]\n[\n   -1\n    1\n   -1\n    3\n   -1\n    3\n]\n\n&gt;&gt;&gt; agnostic_clip_upper(s_pa)  # doctest: +ELLIPSIS\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    -1,\n    1,\n    -3,\n    2,\n    -5,\n    2\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.count","title":"<code>count()</code>","text":"<p>Returns the number of non-null elements in the Series.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of non-null elements in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_count(s_native: IntoSeries) -&gt; int:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.count()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_count</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_count(s_pd)\nnp.int64(3)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_count(s_pl)\n3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_count(s_pa)\n3\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.cum_count","title":"<code>cum_count(*, reverse=False)</code>","text":"<p>Return the cumulative count of the non-null values in the series.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the cumulative count of non-null values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"x\", \"k\", None, \"d\"]\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_count(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.cum_count(reverse=True).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cum_count</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_count(pd.Series(data))\n0    3\n1    2\n2    1\n3    1\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_count(pl.Series(data))\nshape: (4,)\nSeries: '' [u32]\n[\n    3\n    2\n    1\n    1\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_count(pa.chunked_array([data]))\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    3,\n    2,\n    1,\n    1\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.cum_max","title":"<code>cum_max(*, reverse=False)</code>","text":"<p>Return the cumulative max of the non-null values in the series.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the cumulative max of non-null values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 3, None, 2]\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_max(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.cum_max().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cum_max</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_max(pd.Series(data))\n0    1.0\n1    3.0\n2    NaN\n3    3.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_max(pl.Series(data))\nshape: (4,)\nSeries: '' [i64]\n[\n   1\n   3\n   null\n   3\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_max(pa.chunked_array([data]))\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    3,\n    null,\n    3\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.cum_min","title":"<code>cum_min(*, reverse=False)</code>","text":"<p>Return the cumulative min of the non-null values in the series.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the cumulative min of non-null values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [3, 1, None, 2]\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_min(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.cum_min().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cum_min</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_min(pd.Series(data))\n0    3.0\n1    1.0\n2    NaN\n3    1.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_min(pl.Series(data))\nshape: (4,)\nSeries: '' [i64]\n[\n   3\n   1\n   null\n   1\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_min(pa.chunked_array([data]))\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    3,\n    1,\n    null,\n    1\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.cum_prod","title":"<code>cum_prod(*, reverse=False)</code>","text":"<p>Return the cumulative product of the non-null values in the series.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the cumulative product of non-null values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 3, None, 2]\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_prod(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.cum_prod().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cum_prod</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_prod(pd.Series(data))\n0    1.0\n1    3.0\n2    NaN\n3    6.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_prod(pl.Series(data))\nshape: (4,)\nSeries: '' [i64]\n[\n   1\n   3\n   null\n   6\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_prod(pa.chunked_array([data]))\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    3,\n    null,\n    6\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.cum_sum","title":"<code>cum_sum(*, reverse=False)</code>","text":"<p>Calculate the cumulative sum.</p> <p>Parameters:</p> Name Type Description Default <code>reverse</code> <code>bool</code> <p>reverse the operation</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the cumulative sum of non-null values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [2, 4, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_cum_sum(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.cum_sum().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_cum_sum</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_cum_sum(s_pd)\n0    2\n1    6\n2    9\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_sum(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   2\n   6\n   9\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_cum_sum(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2,\n    6,\n    9\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.diff","title":"<code>diff()</code>","text":"<p>Calculate the difference with the previous element, for each element.</p> Notes <p>pandas may change the dtype here, for example when introducing missing values in an integer column. To ensure, that the dtype doesn't change, you may want to use <code>fill_null</code> and <code>cast</code>. For example, to calculate the diff and fill missing values with <code>0</code> in a Int64 column, you could do:</p> <pre><code>s.diff().fill_null(0).cast(nw.Int64)\n</code></pre> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the difference between each element and its predecessor.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [2, 4, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_diff(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.diff().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_diff</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_diff(s_pd)\n0    NaN\n1    2.0\n2   -1.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_diff(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   null\n   2\n   -1\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_diff(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    null,\n    2,\n    -1\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.drop_nulls","title":"<code>drop_nulls()</code>","text":"<p>Drop null values.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with null values removed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [2, 4, None, 3, 5]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_drop_nulls(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.drop_nulls().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_drop_nulls</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_drop_nulls(s_pd)\n0    2.0\n1    4.0\n3    3.0\n4    5.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_drop_nulls(s_pl)\nshape: (4,)\nSeries: '' [i64]\n[\n    2\n    4\n    3\n    5\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_drop_nulls(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2,\n    4,\n    3,\n    5\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.ewm_mean","title":"<code>ewm_mean(*, com=None, span=None, half_life=None, alpha=None, adjust=True, min_samples=1, ignore_nulls=False)</code>","text":"<p>Compute exponentially-weighted moving average.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>Parameters:</p> Name Type Description Default <code>com</code> <code>float | None</code> <p>Specify decay in terms of center of mass, \\(\\gamma\\), with  \\(\\alpha = \\frac{1}{1+\\gamma}\\forall\\gamma\\geq0\\)</p> <code>None</code> <code>span</code> <code>float | None</code> <p>Specify decay in terms of span, \\(\\theta\\), with  \\(\\alpha = \\frac{2}{\\theta + 1} \\forall \\theta \\geq 1\\)</p> <code>None</code> <code>half_life</code> <code>float | None</code> <p>Specify decay in terms of half-life, \\(\\tau\\), with  \\(\\alpha = 1 - \\exp \\left\\{ \\frac{ -\\ln(2) }{ \\tau } \\right\\} \\forall \\tau &gt; 0\\)</p> <code>None</code> <code>alpha</code> <code>float | None</code> <p>Specify smoothing factor alpha directly, \\(0 &lt; \\alpha \\leq 1\\).</p> <code>None</code> <code>adjust</code> <code>bool</code> <p>Divide by decaying adjustment factor in beginning periods to account for imbalance in relative weightings</p> <ul> <li>When <code>adjust=True</code> (the default) the EW function is calculated   using weights \\(w_i = (1 - \\alpha)^i\\)</li> <li>When <code>adjust=False</code> the EW function is calculated recursively by   $$   y_0=x_0   $$   $$   y_t = (1 - \\alpha)y_{t - 1} + \\alpha x_t   $$</li> </ul> <code>True</code> <code>min_samples</code> <code>int</code> <p>Minimum number of observations in window required to have a value (otherwise result is null).</p> <code>1</code> <code>ignore_nulls</code> <code>bool</code> <p>Ignore missing values when calculating weights.</p> <ul> <li>When <code>ignore_nulls=False</code> (default), weights are based on absolute   positions.   For example, the weights of \\(x_0\\) and \\(x_2\\) used in   calculating the final weighted average of \\([x_0, None, x_2]\\) are   \\((1-\\alpha)^2\\) and \\(1\\) if <code>adjust=True</code>, and   \\((1-\\alpha)^2\\) and \\(\\alpha\\) if <code>adjust=False</code>.</li> <li>When <code>ignore_nulls=True</code>, weights are based   on relative positions. For example, the weights of   \\(x_0\\) and \\(x_2\\) used in calculating the final weighted   average of \\([x_0, None, x_2]\\) are   \\(1-\\alpha\\) and \\(1\\) if <code>adjust=True</code>,   and \\(1-\\alpha\\) and \\(\\alpha\\) if <code>adjust=False</code>.</li> </ul> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>Series</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(name=\"a\", data=data)\n&gt;&gt;&gt; s_pl = pl.Series(name=\"a\", values=data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_ewm_mean(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.ewm_mean(com=1, ignore_nulls=False).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas or Polars to <code>agnostic_ewm_mean</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_ewm_mean(s_pd)\n0    1.000000\n1    1.666667\n2    2.428571\nName: a, dtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_ewm_mean(s_pl)\nshape: (3,)\nSeries: 'a' [f64]\n[\n   1.0\n   1.666667\n   2.428571\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.fill_null","title":"<code>fill_null(value=None, strategy=None, limit=None)</code>","text":"<p>Fill null values using the specified value.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any | None</code> <p>Value used to fill null values.</p> <code>None</code> <code>strategy</code> <code>Literal['forward', 'backward'] | None</code> <p>Strategy used to fill null values.</p> <code>None</code> <code>limit</code> <code>int | None</code> <p>Number of consecutive null values to fill when using the 'forward' or 'backward' strategy.</p> <code>None</code> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with null values filled according to the specified value or strategy.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_fill_null(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.fill_null(5).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_fill_null</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_fill_null(s_pd)\n0    1.0\n1    2.0\n2    5.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   1\n   2\n   5\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    2,\n    5\n  ]\n]\n</code></pre> <p>Using a strategy:</p> <pre><code>&gt;&gt;&gt; def agnostic_fill_null_with_strategy(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.fill_null(strategy=\"forward\", limit=1).to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null_with_strategy(s_pd)\n0    1.0\n1    2.0\n2    2.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null_with_strategy(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   1\n   2\n   2\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_fill_null_with_strategy(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    2,\n    2\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.filter","title":"<code>filter(other)</code>","text":"<p>Filter elements in the Series based on a condition.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with elements that satisfy the condition.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [4, 10, 15, 34, 50]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_filter(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.filter(s &gt; 10).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_filter</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_filter(s_pd)\n2    15\n3    34\n4    50\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_filter(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   15\n   34\n   50\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_filter(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    15,\n    34,\n    50\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.gather_every","title":"<code>gather_every(n, offset=0)</code>","text":"<p>Take every nth value in the Series and return as new Series.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Gather every n-th row.</p> required <code>offset</code> <code>int</code> <p>Starting index.</p> <code>0</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with every nth value starting from the offset.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3, 4]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function in which gather every 2 rows, starting from a offset of 1:</p> <pre><code>&gt;&gt;&gt; def agnostic_gather_every(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.gather_every(n=2, offset=1).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_gather_every</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_gather_every(s_pd)\n1    2\n3    4\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_gather_every(s_pl)\nshape: (2,)\nSeries: '' [i64]\n[\n   2\n   4\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_gather_every(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2,\n    4\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.head","title":"<code>head(n=10)</code>","text":"<p>Get the first <code>n</code> rows.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to return.</p> <code>10</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series containing the first n characters of each string.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = list(range(10))\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function that returns the first 3 rows:</p> <pre><code>&gt;&gt;&gt; def agnostic_head(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.head(3).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_head</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_head(s_pd)\n0    0\n1    1\n2    2\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_head(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   0\n   1\n   2\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_head(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    0,\n    1,\n    2\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_between","title":"<code>is_between(lower_bound, upper_bound, closed='both')</code>","text":"<p>Get a boolean mask of the values that are between the given lower/upper bounds.</p> <p>Parameters:</p> Name Type Description Default <code>lower_bound</code> <code>Any | Self</code> <p>Lower bound value.</p> required <code>upper_bound</code> <code>Any | Self</code> <p>Upper bound value.</p> required <code>closed</code> <code>Literal['left', 'right', 'none', 'both']</code> <p>Define which sides of the interval are closed (inclusive).</p> <code>'both'</code> Notes <p>If the value of the <code>lower_bound</code> is greater than that of the <code>upper_bound</code>, then the values will be False, as no value can satisfy the condition.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A boolean Series indicating which values are between the given bounds.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_between(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_between(2, 4, \"right\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_between</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_between(s_pd)\n0    False\n1    False\n2     True\n3     True\n4    False\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_between(s_pl)\nshape: (5,)\nSeries: '' [bool]\n[\n   false\n   false\n   true\n   true\n   false\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_between(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    false,\n    false,\n    true,\n    true,\n    false\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_duplicated","title":"<code>is_duplicated()</code>","text":"<p>Get a mask of all duplicated rows in the Series.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with boolean values indicating duplicated rows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3, 1]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_duplicated(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_duplicated().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_duplicated</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_duplicated(s_pd)\n0     True\n1    False\n2    False\n3     True\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_duplicated(s_pl)\nshape: (4,)\nSeries: '' [bool]\n[\n    true\n    false\n    false\n    true\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_duplicated(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    true,\n    false,\n    false,\n    true\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_empty","title":"<code>is_empty()</code>","text":"<p>Check if the series is empty.</p> <p>Returns:</p> Type Description <code>bool</code> <p>A boolean indicating if the series is empty.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <p>Let's define a dataframe-agnostic function that filters rows in which \"foo\" values are greater than 10, and then checks if the result is empty or not:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_empty(s_native: IntoSeries) -&gt; bool:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.filter(s &gt; 10).is_empty()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_empty</code>:</p> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n&gt;&gt;&gt; agnostic_is_empty(s_pd), agnostic_is_empty(s_pl), agnostic_is_empty(s_pa)\n(True, True, True)\n</code></pre> <pre><code>&gt;&gt;&gt; data = [100, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n&gt;&gt;&gt; agnostic_is_empty(s_pd), agnostic_is_empty(s_pl), agnostic_is_empty(s_pa)\n(False, False, False)\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_finite","title":"<code>is_finite()</code>","text":"<p>Returns a boolean Series indicating which values are finite.</p> Warning <p>Different backend handle null values differently. <code>is_finite</code> will return False for NaN and Null's in the Dask and pandas non-nullable backend, while for Polars, PyArrow and pandas nullable backends null values are kept as such.</p> <p>Returns:</p> Type Description <code>Self</code> <p>Expression of <code>Boolean</code> data type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [float(\"nan\"), float(\"inf\"), 2.0, None]\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_finite(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_finite().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_finite</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_finite(pd.Series(data))\n0    False\n1    False\n2     True\n3    False\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_finite(pl.Series(data))\nshape: (4,)\nSeries: '' [bool]\n[\n   false\n   false\n   true\n   null\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_finite(pa.chunked_array([data]))\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    false,\n    false,\n    true,\n    null\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_first_distinct","title":"<code>is_first_distinct()</code>","text":"<p>Return a boolean mask indicating the first occurrence of each distinct value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with boolean values indicating the first occurrence of each distinct value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 1, 2, 3, 2]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_first_distinct(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_first_distinct().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_first_distinct</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_first_distinct(s_pd)\n0     True\n1    False\n2     True\n3     True\n4    False\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_first_distinct(s_pl)\nshape: (5,)\nSeries: '' [bool]\n[\n    true\n    false\n    true\n    true\n    false\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_first_distinct(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    true,\n    false,\n    true,\n    true,\n    false\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_in","title":"<code>is_in(other)</code>","text":"<p>Check if the elements of this Series are in the other sequence.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>Sequence of primitive type.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with boolean values indicating if the elements are in the other sequence.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_in(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_in([3, 2, 8]).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_in</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_in(s_pd)\n0    False\n1     True\n2     True\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_in(s_pl)\nshape: (3,)\nSeries: '' [bool]\n[\n   false\n   true\n   true\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_in(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    false,\n    true,\n    true\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_last_distinct","title":"<code>is_last_distinct()</code>","text":"<p>Return a boolean mask indicating the last occurrence of each distinct value.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with boolean values indicating the last occurrence of each distinct value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 1, 2, 3, 2]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_last_distinct(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_last_distinct().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_last_distinct</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_last_distinct(s_pd)\n0    False\n1     True\n2    False\n3     True\n4     True\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_last_distinct(s_pl)\nshape: (5,)\nSeries: '' [bool]\n[\n    false\n    true\n    false\n    true\n    true\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_last_distinct(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    false,\n    true,\n    false,\n    true,\n    true\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_nan","title":"<code>is_nan()</code>","text":"<p>Returns a boolean Series indicating which values are NaN.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A boolean Series indicating which values are NaN.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [0.0, None, 2.0]\n&gt;&gt;&gt; s_pd = pd.Series(data, dtype=\"Float64\")\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data], type=pa.float64())\n</code></pre> <pre><code>&gt;&gt;&gt; def agnostic_self_div_is_nan(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_nan().to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; print(agnostic_self_div_is_nan(s_pd))\n0    False\n1     &lt;NA&gt;\n2    False\ndtype: boolean\n</code></pre> <pre><code>&gt;&gt;&gt; print(agnostic_self_div_is_nan(s_pl))\nshape: (3,)\nSeries: '' [bool]\n[\n        false\n        null\n        false\n]\n</code></pre> <pre><code>&gt;&gt;&gt; print(agnostic_self_div_is_nan(s_pa))\n[\n  [\n    false,\n    null,\n    false\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_null","title":"<code>is_null()</code>","text":"<p>Returns a boolean Series indicating which values are null.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A boolean Series indicating which values are null.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_null(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_null().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_null</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_null(s_pd)\n0    False\n1    False\n2     True\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_null(s_pl)\nshape: (3,)\nSeries: '' [bool]\n[\n   false\n   false\n   true\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_null(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    false,\n    false,\n    true\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_sorted","title":"<code>is_sorted(*, descending=False)</code>","text":"<p>Check if the Series is sorted.</p> <p>Parameters:</p> Name Type Description Default <code>descending</code> <code>bool</code> <p>Check if the Series is sorted in descending order.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>A boolean indicating if the Series is sorted.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; unsorted_data = [1, 3, 2]\n&gt;&gt;&gt; sorted_data = [3, 2, 1]\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_sorted(s_native: IntoSeries, descending: bool = False):\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_sorted(descending=descending)\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_sorted</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_sorted(pd.Series(unsorted_data))\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_sorted(pd.Series(sorted_data), descending=True)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_sorted(pl.Series(unsorted_data))\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_sorted(pl.Series(sorted_data), descending=True)\nTrue\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_sorted(pa.chunked_array([unsorted_data]))\nFalse\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_sorted(pa.chunked_array([sorted_data]), descending=True)\nTrue\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.is_unique","title":"<code>is_unique()</code>","text":"<p>Get a mask of all unique rows in the Series.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with boolean values indicating unique rows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3, 1]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_is_unique(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.is_unique().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_is_unique</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_is_unique(s_pd)\n0    False\n1     True\n2     True\n3    False\ndtype: bool\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_is_unique(s_pl)\nshape: (4,)\nSeries: '' [bool]\n[\n    false\n     true\n     true\n    false\n]\n&gt;&gt;&gt; agnostic_is_unique(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    false,\n    true,\n    true,\n    false\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.item","title":"<code>item(index=None)</code>","text":"<p>Return the Series as a scalar, or return the element at the given index.</p> <p>If no index is provided, this is equivalent to <code>s[0]</code>, with a check that the shape is (1,). With an index, this is equivalent to <code>s[index]</code>.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The scalar value of the Series or the element at the given index.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <p>Let's define a dataframe-agnostic function that returns item at given index</p> <pre><code>&gt;&gt;&gt; def agnostic_item(s_native: IntoSeries, index=None):\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.item(index)\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_item</code>:</p> <pre><code>&gt;&gt;&gt; (\n...     agnostic_item(pl.Series(\"a\", [1]), None),\n...     agnostic_item(pd.Series([1]), None),\n...     agnostic_item(pa.chunked_array([[1]]), None),\n... )\n(1, np.int64(1), 1)\n</code></pre> <pre><code>&gt;&gt;&gt; (\n...     agnostic_item(pl.Series(\"a\", [9, 8, 7]), -1),\n...     agnostic_item(pl.Series([9, 8, 7]), -2),\n...     agnostic_item(pa.chunked_array([[9, 8, 7]]), -3),\n... )\n(7, 8, 9)\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.len","title":"<code>len()</code>","text":"<p>Return the number of elements in the Series.</p> <p>Null values count towards the total.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of elements in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function that computes the len of the series:</p> <pre><code>&gt;&gt;&gt; def agnostic_len(s_native: IntoSeries) -&gt; int:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.len()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_len</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_len(s_pd)\n3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_len(s_pl)\n3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_len(s_pa)\n3\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.max","title":"<code>max()</code>","text":"<p>Get the maximum value in this Series.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The maximum value in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_max(s_native: IntoSeries):\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.max()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_max</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_max(s_pd)\nnp.int64(3)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_max(s_pl)\n3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_max(s_pa)\n3\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.mean","title":"<code>mean()</code>","text":"<p>Reduce this Series to the mean value.</p> <p>Returns:</p> Type Description <code>float</code> <p>The average of all elements in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_mean(s_native: IntoSeries) -&gt; float:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.mean()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_mean</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_mean(s_pd)\nnp.float64(2.0)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mean(s_pl)\n2.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mean(s_pa)\n2.0\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.median","title":"<code>median()</code>","text":"<p>Reduce this Series to the median value.</p> Notes <p>Results might slightly differ across backends due to differences in the underlying algorithms used to compute the median.</p> <p>Returns:</p> Type Description <code>float</code> <p>The median value of all elements in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [5, 3, 8]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_median(s_native: IntoSeries) -&gt; float:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.median()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_median</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_median(s_pd)\nnp.float64(5.0)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_median(s_pl)\n5.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_median(s_pa)\n5.0\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.min","title":"<code>min()</code>","text":"<p>Get the minimal value in this Series.</p> <p>Returns:</p> Type Description <code>Any</code> <p>The minimum value in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_min(s_native: IntoSeries):\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.min()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_min</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_min(s_pd)\nnp.int64(1)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min(s_pl)\n1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_min(s_pa)\n1\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.mode","title":"<code>mode()</code>","text":"<p>Compute the most occurring value(s).</p> <p>Can return multiple values.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series containing the mode(s) (values that appear most frequently).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 1, 2, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_mode(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.mode().sort().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_mode</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_mode(s_pd)\n0    1\n1    2\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mode(s_pl)\nshape: (2,)\nSeries: '' [i64]\n[\n   1\n   2\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_mode(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    2\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.n_unique","title":"<code>n_unique()</code>","text":"<p>Count the number of unique values.</p> <p>Returns:</p> Type Description <code>int</code> <p>Number of unique values in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_n_unique(s_native: IntoSeries) -&gt; int:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.n_unique()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_n_unique</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_n_unique(s_pd)\n3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_n_unique(s_pl)\n3\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_n_unique(s_pa)\n3\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.null_count","title":"<code>null_count()</code>","text":"<p>Create a new Series that shows the null counts per column.</p> Notes <p>pandas handles null values differently from Polars and PyArrow. See null_handling for reference.</p> <p>Returns:</p> Type Description <code>int</code> <p>The number of null values in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, None, None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function that returns the null count of the series:</p> <pre><code>&gt;&gt;&gt; def agnostic_null_count(s_native: IntoSeries) -&gt; int:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.null_count()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_null_count</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_null_count(s_pd)\nnp.int64(2)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_null_count(s_pl)\n2\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_null_count(s_pa)\n2\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.pipe","title":"<code>pipe(function, *args, **kwargs)</code>","text":"<p>Pipe function call.</p> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the results of the piped function applied.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a function to pipe into:</p> <pre><code>&gt;&gt;&gt; def agnostic_pipe(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.pipe(lambda x: x + 2).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_pipe</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_pipe(s_pd)\n0    3\n1    4\n2    5\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_pipe(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   3\n   4\n   5\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_pipe(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    3,\n    4,\n    5\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.quantile","title":"<code>quantile(quantile, interpolation)</code>","text":"<p>Get quantile value of the series.</p> Note <p>pandas and Polars may have implementation differences for a given interpolation method.</p> <p>Parameters:</p> Name Type Description Default <code>quantile</code> <code>float</code> <p>Quantile between 0.0 and 1.0.</p> required <code>interpolation</code> <code>Literal['nearest', 'higher', 'lower', 'midpoint', 'linear']</code> <p>Interpolation method.</p> required <p>Returns:</p> Type Description <code>float</code> <p>The quantile value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = list(range(50))\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_quantile(s_native: IntoSeries) -&gt; list[float]:\n...     s = nw.from_native(s_native, series_only=True)\n...     return [\n...         s.quantile(quantile=q, interpolation=\"nearest\")\n...         for q in (0.1, 0.25, 0.5, 0.75, 0.9)\n...     ]\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_quantile</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_quantile(s_pd)\n[np.int64(5), np.int64(12), np.int64(24), np.int64(37), np.int64(44)]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_quantile(s_pl)\n[5.0, 12.0, 25.0, 37.0, 44.0]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_quantile(s_pa)\n[5, 12, 24, 37, 44]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.rank","title":"<code>rank(method='average', *, descending=False)</code>","text":"<p>Assign ranks to data, dealing with ties appropriately.</p> Notes <p>The resulting dtype may differ between backends.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>Literal['average', 'min', 'max', 'dense', 'ordinal']</code> <p>The method used to assign ranks to tied elements. The following methods are available (default is 'average'):</p> <ul> <li>'average' : The average of the ranks that would have been assigned to   all the tied values is assigned to each value.</li> <li>'min' : The minimum of the ranks that would have been assigned to all     the tied values is assigned to each value. (This is also referred to     as \"competition\" ranking.)</li> <li>'max' : The maximum of the ranks that would have been assigned to all     the tied values is assigned to each value.</li> <li>'dense' : Like 'min', but the rank of the next highest element is    assigned the rank immediately after those assigned to the tied    elements.</li> <li>'ordinal' : All values are given a distinct rank, corresponding to the     order that the values occur in the Series.</li> </ul> <code>'average'</code> <code>descending</code> <code>bool</code> <p>Rank in descending order.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new series with rank data as values.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n&gt;&gt;&gt;\n&gt;&gt;&gt; data = [3, 6, 1, 1, 6]\n</code></pre> <p>We define a dataframe-agnostic function that computes the dense rank for the data:</p> <pre><code>&gt;&gt;&gt; def agnostic_dense_rank(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.rank(method=\"dense\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_dense_rank</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_dense_rank(pd.Series(data))\n0    2.0\n1    3.0\n2    1.0\n3    1.0\n4    3.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dense_rank(pl.Series(data))\nshape: (5,)\nSeries: '' [u32]\n[\n   2\n   3\n   1\n   1\n   3\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_dense_rank(pa.chunked_array([data]))\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2,\n    3,\n    1,\n    1,\n    3\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.rename","title":"<code>rename(name)</code>","text":"<p>Rename the Series.</p> <p>Alias for <code>Series.alias()</code>.</p> Notes <p>This method is very cheap, but does not guarantee that data will be copied. For example:</p> <pre><code>s1: nw.Series\ns2 = s1.rename(\"foo\")\narr = s2.to_numpy()\narr[0] = 999\n</code></pre> <p>may (depending on the backend, and on the version) result in <code>s1</code>'s data being modified. We recommend:</p> <pre><code>- if you need to rename an object and don't need the original\n  one around any more, just use `rename` without worrying about it.\n- if you were expecting `rename` to copy data, then explicily call\n  `.clone` before calling `rename`.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The new name.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the updated name.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data, name=\"foo\")\n&gt;&gt;&gt; s_pl = pl.Series(\"foo\", data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rename(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.rename(\"bar\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_rename</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rename(s_pd)\n0    1\n1    2\n2    3\nName: bar, dtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rename(s_pl)\nshape: (3,)\nSeries: 'bar' [i64]\n[\n   1\n   2\n   3\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rename(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at 0x...&gt;\n[\n  [\n    1,\n    2,\n    3\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.replace_strict","title":"<code>replace_strict(old, new=None, *, return_dtype=None)</code>","text":"<p>Replace all values by different values.</p> <p>This function must replace all non-null input values (else it raises an error).</p> <p>Parameters:</p> Name Type Description Default <code>old</code> <code>Sequence[Any] | Mapping[Any, Any]</code> <p>Sequence of values to replace. It also accepts a mapping of values to their replacement as syntactic sugar for <code>replace_all(old=list(mapping.keys()), new=list(mapping.values()))</code>.</p> required <code>new</code> <code>Sequence[Any] | None</code> <p>Sequence of values to replace by. Length must match the length of <code>old</code>.</p> <code>None</code> <code>return_dtype</code> <code>DType | type[DType] | None</code> <p>The data type of the resulting expression. If set to <code>None</code> (default), the data type is determined automatically based on the other inputs.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with values replaced according to the mapping.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = {\"a\": [3, 0, 1, 2]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>Let's define dataframe-agnostic functions:</p> <pre><code>&gt;&gt;&gt; def agnostic_replace_strict(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.replace_strict(\n...         [0, 1, 2, 3], [\"zero\", \"one\", \"two\", \"three\"], return_dtype=nw.String\n...     ).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_replace_strict</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_replace_strict(df_pd[\"a\"])\n0    three\n1     zero\n2      one\n3      two\nName: a, dtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace_strict(df_pl[\"a\"])\nshape: (4,)\nSeries: 'a' [str]\n[\n    \"three\"\n    \"zero\"\n    \"one\"\n    \"two\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace_strict(df_pa[\"a\"])\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"three\",\n    \"zero\",\n    \"one\",\n    \"two\"\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.rolling_mean","title":"<code>rolling_mean(window_size, *, min_samples=None, center=False)</code>","text":"<p>Apply a rolling mean (moving mean) over the values.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>A window of length <code>window_size</code> will traverse the values. The resulting values will be aggregated to their mean.</p> <p>The window at a given row will include the row itself and the <code>window_size - 1</code> elements before it.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>The length of the window in number of elements. It must be a strictly positive integer.</p> required <code>min_samples</code> <code>int | None</code> <p>The number of values in the window that should be non-null before computing a result. If set to <code>None</code> (default), it will be set equal to <code>window_size</code>. If provided, it must be a strictly positive integer, and less than or equal to <code>window_size</code></p> <code>None</code> <code>center</code> <code>bool</code> <p>Set the labels at the center of the window.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1.0, 2.0, 3.0, 4.0]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rolling_mean(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.rolling_mean(window_size=2).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_rolling_mean</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rolling_mean(s_pd)\n0    NaN\n1    1.5\n2    2.5\n3    3.5\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_mean(s_pl)\nshape: (4,)\nSeries: '' [f64]\n[\n   null\n   1.5\n   2.5\n   3.5\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_mean(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    null,\n    1.5,\n    2.5,\n    3.5\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.rolling_std","title":"<code>rolling_std(window_size, *, min_samples=None, center=False, ddof=1)</code>","text":"<p>Apply a rolling standard deviation (moving standard deviation) over the values.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>A window of length <code>window_size</code> will traverse the values. The resulting values will be aggregated to their standard deviation.</p> <p>The window at a given row will include the row itself and the <code>window_size - 1</code> elements before it.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>The length of the window in number of elements. It must be a strictly positive integer.</p> required <code>min_samples</code> <code>int | None</code> <p>The number of values in the window that should be non-null before computing a result. If set to <code>None</code> (default), it will be set equal to <code>window_size</code>. If provided, it must be a strictly positive integer, and less than or equal to <code>window_size</code>.</p> <code>None</code> <code>center</code> <code>bool</code> <p>Set the labels at the center of the window.</p> <code>False</code> <code>ddof</code> <code>int</code> <p>Delta Degrees of Freedom; the divisor for a length N window is N - ddof.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1.0, 3.0, 1.0, 4.0]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rolling_std(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.rolling_std(window_size=2, min_samples=1).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_rolling_std</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rolling_std(s_pd)\n0         NaN\n1    1.414214\n2    1.414214\n3    2.121320\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_std(s_pl)\nshape: (4,)\nSeries: '' [f64]\n[\n   null\n   1.414214\n   1.414214\n   2.12132\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_std(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    nan,\n    1.4142135623730951,\n    1.4142135623730951,\n    2.1213203435596424\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.rolling_sum","title":"<code>rolling_sum(window_size, *, min_samples=None, center=False)</code>","text":"<p>Apply a rolling sum (moving sum) over the values.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>A window of length <code>window_size</code> will traverse the values. The resulting values will be aggregated to their sum.</p> <p>The window at a given row will include the row itself and the <code>window_size - 1</code> elements before it.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>The length of the window in number of elements. It must be a strictly positive integer.</p> required <code>min_samples</code> <code>int | None</code> <p>The number of values in the window that should be non-null before computing a result. If set to <code>None</code> (default), it will be set equal to <code>window_size</code>. If provided, it must be a strictly positive integer, and less than or equal to <code>window_size</code></p> <code>None</code> <code>center</code> <code>bool</code> <p>Set the labels at the center of the window.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1.0, 2.0, 3.0, 4.0]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rolling_sum(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.rolling_sum(window_size=2).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_rolling_sum</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rolling_sum(s_pd)\n0    NaN\n1    3.0\n2    5.0\n3    7.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_sum(s_pl)\nshape: (4,)\nSeries: '' [f64]\n[\n   null\n   3.0\n   5.0\n   7.0\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_sum(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    null,\n    3,\n    5,\n    7\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.rolling_var","title":"<code>rolling_var(window_size, *, min_samples=None, center=False, ddof=1)</code>","text":"<p>Apply a rolling variance (moving variance) over the values.</p> <p>Warning</p> <p>This functionality is considered unstable. It may be changed at any point without it being considered a breaking change.</p> <p>A window of length <code>window_size</code> will traverse the values. The resulting values will be aggregated to their variance.</p> <p>The window at a given row will include the row itself and the <code>window_size - 1</code> elements before it.</p> <p>Parameters:</p> Name Type Description Default <code>window_size</code> <code>int</code> <p>The length of the window in number of elements. It must be a strictly positive integer.</p> required <code>min_samples</code> <code>int | None</code> <p>The number of values in the window that should be non-null before computing a result. If set to <code>None</code> (default), it will be set equal to <code>window_size</code>. If provided, it must be a strictly positive integer, and less than or equal to <code>window_size</code>.</p> <code>None</code> <code>center</code> <code>bool</code> <p>Set the labels at the center of the window.</p> <code>False</code> <code>ddof</code> <code>int</code> <p>Delta Degrees of Freedom; the divisor for a length N window is N - ddof.</p> <code>1</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1.0, 3.0, 1.0, 4.0]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_rolling_var(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.rolling_var(window_size=2, min_samples=1).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_rolling_var</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_rolling_var(s_pd)\n0    NaN\n1    2.0\n2    2.0\n3    4.5\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_var(s_pl)\nshape: (4,)\nSeries: '' [f64]\n[\n   null\n   2.0\n   2.0\n   4.5\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_rolling_var(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    nan,\n    2,\n    2,\n    4.5\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.round","title":"<code>round(decimals=0)</code>","text":"<p>Round underlying floating point data by <code>decimals</code> digits.</p> <p>Parameters:</p> Name Type Description Default <code>decimals</code> <code>int</code> <p>Number of decimals to round by.</p> <code>0</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with rounded values.</p> Notes <p>For values exactly halfway between rounded decimal values pandas behaves differently than Polars and Arrow.</p> <p>pandas rounds to the nearest even value (e.g. -0.5 and 0.5 round to 0.0, 1.5 and 2.5 round to 2.0, 3.5 and 4.5 to 4.0, etc..).</p> <p>Polars and Arrow round away from 0 (e.g. -0.5 to -1.0, 0.5 to 1.0, 1.5 to 2.0, 2.5 to 3.0, etc..).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1.12345, 2.56789, 3.901234]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function that rounds to the first decimal:</p> <pre><code>&gt;&gt;&gt; def agnostic_round(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.round(1).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_round</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_round(s_pd)\n0    1.1\n1    2.6\n2    3.9\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_round(s_pl)\nshape: (3,)\nSeries: '' [f64]\n[\n   1.1\n   2.6\n   3.9\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_round(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1.1,\n    2.6,\n    3.9\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.sample","title":"<code>sample(n=None, *, fraction=None, with_replacement=False, seed=None)</code>","text":"<p>Sample randomly from this Series.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int | None</code> <p>Number of items to return. Cannot be used with fraction.</p> <code>None</code> <code>fraction</code> <code>float | None</code> <p>Fraction of items to return. Cannot be used with n.</p> <code>None</code> <code>with_replacement</code> <code>bool</code> <p>Allow values to be sampled more than once.</p> <code>False</code> <code>seed</code> <code>int | None</code> <p>Seed for the random number generator. If set to None (default), a random seed is generated for each sample operation.</p> <code>None</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series containing randomly sampled values from the original Series.</p> Notes <p>The <code>sample</code> method returns a Series with a specified number of randomly selected items chosen from this Series. The results are not consistent across libraries.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3, 4]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_sample(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.sample(fraction=1.0, with_replacement=True).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_sample</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_sample(s_pd)\n   a\n2  3\n1  2\n3  4\n3  4\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sample(s_pl)\nshape: (4,)\nSeries: '' [i64]\n[\n   1\n   4\n   3\n   4\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sample(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    4,\n    3,\n    4\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.scatter","title":"<code>scatter(indices, values)</code>","text":"<p>Set value(s) at given position(s).</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>int | Sequence[int]</code> <p>Position(s) to set items at.</p> required <code>values</code> <code>Any</code> <p>Values to set.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with values set at given positions.</p> Note <p>This method always returns a new Series, without modifying the original one. Using this function in a for-loop is an anti-pattern, we recommend building up your positions and values beforehand and doing an update in one go.</p> <p>For example, instead of</p> <pre><code>for i in [1, 3, 2]:\n    value = some_function(i)\n    s = s.scatter(i, value)\n</code></pre> <p>prefer</p> <pre><code>positions = [1, 3, 2]\nvalues = [some_function(x) for x in positions]\ns = s.scatter(positions, values)\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n</code></pre> <pre><code>&gt;&gt;&gt; data = {\"a\": [1, 2, 3], \"b\": [4, 5, 6]}\n&gt;&gt;&gt; df_pd = pd.DataFrame(data)\n&gt;&gt;&gt; df_pl = pl.DataFrame(data)\n&gt;&gt;&gt; df_pa = pa.table(data)\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_scatter(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(df[\"a\"].scatter([0, 1], [999, 888])).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_scatter</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_scatter(df_pd)\n     a  b\n0  999  4\n1  888  5\n2    3  6\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_scatter(df_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 999 \u2506 4   \u2502\n\u2502 888 \u2506 5   \u2502\n\u2502 3   \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_scatter(df_pa)\npyarrow.Table\na: int64\nb: int64\n----\na: [[999,888,3]]\nb: [[4,5,6]]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.shift","title":"<code>shift(n)</code>","text":"<p>Shift values by <code>n</code> positions.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of indices to shift forward. If a negative value is passed, values are shifted in the opposite direction instead.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with values shifted by n positions.</p> Notes <p>pandas may change the dtype here, for example when introducing missing values in an integer column. To ensure, that the dtype doesn't change, you may want to use <code>fill_null</code> and <code>cast</code>. For example, to shift and fill missing values with <code>0</code> in a Int64 column, you could do:</p> <pre><code>s.shift(1).fill_null(0).cast(nw.Int64)\n</code></pre> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [2, 4, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_shift(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.shift(1).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_shift</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_shift(s_pd)\n0    NaN\n1    2.0\n2    4.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_shift(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   null\n   2\n   4\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_shift(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    null,\n    2,\n    4\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.sort","title":"<code>sort(*, descending=False, nulls_last=False)</code>","text":"<p>Sort this Series. Place null values first.</p> <p>Parameters:</p> Name Type Description Default <code>descending</code> <code>bool</code> <p>Sort in descending order.</p> <code>False</code> <code>nulls_last</code> <code>bool</code> <p>Place null values last instead of first.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new sorted Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [5, None, 1, 2]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define library agnostic functions:</p> <pre><code>&gt;&gt;&gt; def agnostic_sort(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.sort().to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; def agnostic_sort_descending(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.sort(descending=True).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_sort</code> and <code>agnostic_sort_descending</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_sort(s_pd)\n1    NaN\n2    1.0\n3    2.0\n0    5.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sort(s_pl)\nshape: (4,)\nSeries: '' [i64]\n[\n   null\n   1\n   2\n   5\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sort(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    null,\n    1,\n    2,\n    5\n  ]\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sort_descending(s_pd)\n1    NaN\n0    5.0\n3    2.0\n2    1.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sort_descending(s_pl)\nshape: (4,)\nSeries: '' [i64]\n[\n   null\n   5\n   2\n   1\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sort_descending(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    null,\n    5,\n    2,\n    1\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.skew","title":"<code>skew()</code>","text":"<p>Calculate the sample skewness of the Series.</p> <p>Returns:</p> Type Description <code>float | None</code> <p>The sample skewness of the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 1, 2, 10, 100]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_skew(s_native: IntoSeries) -&gt; float:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.skew()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_skew</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_skew(s_pd)\nnp.float64(1.4724267269058975)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_skew(s_pl)\n1.4724267269058975\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_skew(s_pa)\n1.4724267269058975\n</code></pre> Notes <p>The skewness is a measure of the asymmetry of the probability distribution. A perfectly symmetric distribution has a skewness of 0.</p>"},{"location":"api-reference/series/#narwhals.series.Series.std","title":"<code>std(*, ddof=1)</code>","text":"<p>Get the standard deviation of this Series.</p> <p>Parameters:</p> Name Type Description Default <code>ddof</code> <code>int</code> <p>\"Delta Degrees of Freedom\": the divisor used in the calculation is N - ddof,      where N represents the number of elements.</p> <code>1</code> <p>Returns:</p> Type Description <code>float</code> <p>The standard deviation of all elements in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_std(s_native: IntoSeries) -&gt; float:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.std()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_std</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_std(s_pd)\nnp.float64(1.0)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_std(s_pl)\n1.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_std(s_pa)\n1.0\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.sum","title":"<code>sum()</code>","text":"<p>Reduce this Series to the sum value.</p> <p>Returns:</p> Type Description <code>float</code> <p>The sum of all elements in the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_sum(s_native: IntoSeries):\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.sum()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_sum</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_sum(s_pd)\nnp.int64(6)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sum(s_pl)\n6\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_sum(s_pa)\n6\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.tail","title":"<code>tail(n=10)</code>","text":"<p>Get the last <code>n</code> rows.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of rows to return.</p> <code>10</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with the last n rows.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = list(range(10))\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function that returns the last 3 rows:</p> <pre><code>&gt;&gt;&gt; def agnostic_tail(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.tail(3).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_tail</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_tail(s_pd)\n7    7\n8    8\n9    9\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_tail(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   7\n   8\n   9\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_tail(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    7,\n    8,\n    9\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.to_arrow","title":"<code>to_arrow()</code>","text":"<p>Convert to arrow.</p> <p>Returns:</p> Type Description <code>Array</code> <p>A PyArrow Array containing the data from the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3, 4]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function that converts to arrow:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_arrow(s_native: IntoSeries) -&gt; pa.Array:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.to_arrow()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_arrow</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_arrow(s_pd)\n&lt;pyarrow.lib.Int64Array object at ...&gt;\n[\n    1,\n    2,\n    3,\n    4\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_arrow(s_pl)\n&lt;pyarrow.lib.Int64Array object at ...&gt;\n[\n    1,\n    2,\n    3,\n    4\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_arrow(s_pa)\n&lt;pyarrow.lib.Int64Array object at ...&gt;\n[\n    1,\n    2,\n    3,\n    4\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.to_dummies","title":"<code>to_dummies(*, separator='_', drop_first=False)</code>","text":"<p>Get dummy/indicator variables.</p> <p>Parameters:</p> Name Type Description Default <code>separator</code> <code>str</code> <p>Separator/delimiter used when generating column names.</p> <code>'_'</code> <code>drop_first</code> <code>bool</code> <p>Remove the first category from the variable being encoded.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame[Any]</code> <p>A new DataFrame containing the dummy/indicator variables.</p> Notes <p>pandas and Polars handle null values differently. Polars distinguishes between NaN and Null, whereas pandas doesn't.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data, name=\"a\")\n&gt;&gt;&gt; s_pl = pl.Series(\"a\", data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_dummies(\n...     s_native: IntoSeries, drop_first: bool = False\n... ) -&gt; IntoDataFrame:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.to_dummies(drop_first=drop_first).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_dummies</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_dummies(s_pd)\n   a_1  a_2  a_3\n0    1    0    0\n1    0    1    0\n2    0    0    1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_dummies(s_pd, drop_first=True)\n   a_2  a_3\n0    0    0\n1    1    0\n2    0    1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_dummies(s_pl)\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a_1 \u2506 a_2 \u2506 a_3 \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i8  \u2506 i8  \u2506 i8  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 0   \u2506 0   \u2502\n\u2502 0   \u2506 1   \u2506 0   \u2502\n\u2502 0   \u2506 0   \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_dummies(s_pl, drop_first=True)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a_2 \u2506 a_3 \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i8  \u2506 i8  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0   \u2506 0   \u2502\n\u2502 1   \u2506 0   \u2502\n\u2502 0   \u2506 1   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_dummies(s_pa)\npyarrow.Table\n_1: int8\n_2: int8\n_3: int8\n----\n_1: [[1,0,0]]\n_2: [[0,1,0]]\n_3: [[0,0,1]]\n&gt;&gt;&gt; agnostic_to_dummies(s_pa, drop_first=True)\npyarrow.Table\n_2: int8\n_3: int8\n----\n_2: [[0,1,0]]\n_3: [[0,0,1]]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.to_frame","title":"<code>to_frame()</code>","text":"<p>Convert to dataframe.</p> <p>Returns:</p> Type Description <code>DataFrame[Any]</code> <p>A DataFrame containing this Series as a single column.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2]\n&gt;&gt;&gt; s_pd = pd.Series(data, name=\"a\")\n&gt;&gt;&gt; s_pl = pl.Series(\"a\", data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_frame(s_native: IntoSeries) -&gt; IntoDataFrame:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.to_frame().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_frame</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_frame(s_pd)\n   a\n0  1\n1  2\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_frame(s_pl)\nshape: (2, 1)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2502\n\u2502 --- \u2502\n\u2502 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2502\n\u2502 2   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_frame(s_pa)\npyarrow.Table\n: int64\n----\n: [[1,2]]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.to_list","title":"<code>to_list()</code>","text":"<p>Convert to list.</p> Notes <p>This function converts to Python scalars. It's typically more efficient to keep your data in the format native to your original dataframe, so we recommend only calling this when you absolutely need to.</p> <p>Returns:</p> Type Description <code>list[Any]</code> <p>A list of Python objects.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_list(s_native: IntoSeries):\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.to_list()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_list</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_list(s_pd)\n[1, 2, 3]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_list(s_pl)\n[1, 2, 3]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_list(s_pa)\n[1, 2, 3]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.to_numpy","title":"<code>to_numpy()</code>","text":"<p>Convert to numpy.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>NumPy ndarray representation of the Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data, name=\"a\")\n&gt;&gt;&gt; s_pl = pl.Series(\"a\", data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_numpy(s_native: IntoSeries) -&gt; np.ndarray:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.to_numpy()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_numpy</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_numpy(s_pd)\narray([1, 2, 3]...)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_numpy(s_pl)\narray([1, 2, 3]...)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_numpy(s_pa)\narray([1, 2, 3]...)\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.to_pandas","title":"<code>to_pandas()</code>","text":"<p>Convert to pandas Series.</p> <p>Returns:</p> Type Description <code>Series</code> <p>A pandas Series containing the data from this Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data, name=\"a\")\n&gt;&gt;&gt; s_pl = pl.Series(\"a\", data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_pandas(s_native: IntoSeries) -&gt; pd.Series:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.to_pandas()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_pandas</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_pandas(s_pd)\n0    1\n1    2\n2    3\nName: a, dtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_pandas(s_pl)\n0    1\n1    2\n2    3\nName: a, dtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_pandas(s_pa)\n0    1\n1    2\n2    3\nName: , dtype: int64\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.to_polars","title":"<code>to_polars()</code>","text":"<p>Convert to polars Series.</p> <p>Returns:</p> Type Description <code>Series</code> <p>A polars Series containing the data from this Series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data, name=\"a\")\n&gt;&gt;&gt; s_pl = pl.Series(\"a\", data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_polars(s_native: IntoSeries) -&gt; pd.Series:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.to_polars()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_polars</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_polars(s_pd)\nshape: (3,)\nSeries: 'a' [i64]\n[\n    1\n    2\n    3\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_polars(s_pl)\nshape: (3,)\nSeries: 'a' [i64]\n[\n    1\n    2\n    3\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_polars(s_pa)\nshape: (3,)\nSeries: '' [i64]\n[\n    1\n    2\n    3\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.to_native","title":"<code>to_native()</code>","text":"<p>Convert Narwhals series to native series.</p> <p>Returns:</p> Type Description <code>IntoSeriesT</code> <p>Series of class that user started with.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_native(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_native</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_native(s_pd)\n0    1\n1    2\n2    3\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_native(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n    1\n    2\n    3\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_native(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    2,\n    3\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.unique","title":"<code>unique(*, maintain_order=False)</code>","text":"<p>Returns unique values of the series.</p> <p>Parameters:</p> Name Type Description Default <code>maintain_order</code> <code>bool</code> <p>Keep the same order as the original series. This may be more expensive to compute. Settings this to <code>True</code> blocks the possibility to run on the streaming engine for Polars.</p> <code>False</code> <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with duplicate values removed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [2, 4, 4, 6]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_unique(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.unique(maintain_order=True).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_unique</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_unique(s_pd)\n0    2\n1    4\n2    6\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_unique(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n   2\n   4\n   6\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_unique(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2,\n    4,\n    6\n  ]\n]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.value_counts","title":"<code>value_counts(*, sort=False, parallel=False, name=None, normalize=False)</code>","text":"<p>Count the occurrences of unique values.</p> <p>Parameters:</p> Name Type Description Default <code>sort</code> <code>bool</code> <p>Sort the output by count in descending order. If set to False (default), the order of the output is random.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Execute the computation in parallel. Used for Polars only.</p> <code>False</code> <code>name</code> <code>str | None</code> <p>Give the resulting count column a specific name; if <code>normalize</code> is True defaults to \"proportion\", otherwise defaults to \"count\".</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>If true gives relative frequencies of the unique values</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame[Any]</code> <p>A DataFrame with two columns:</p> <code>DataFrame[Any]</code> <ul> <li>The original values as first column</li> </ul> <code>DataFrame[Any]</code> <ul> <li>Either count or proportion as second column, depending on normalize parameter.</li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 1, 2, 3, 2]\n&gt;&gt;&gt; s_pd = pd.Series(data, name=\"s\")\n&gt;&gt;&gt; s_pl = pl.Series(values=data, name=\"s\")\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_value_counts(s_native: IntoSeries) -&gt; IntoDataFrame:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.value_counts(sort=True).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_value_counts</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_value_counts(s_pd)\n   s  count\n0  1      2\n1  2      2\n2  3      1\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_value_counts(s_pl)\nshape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 s   \u2506 count \u2502\n\u2502 --- \u2506 ---   \u2502\n\u2502 i64 \u2506 u32   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 2     \u2502\n\u2502 2   \u2506 2     \u2502\n\u2502 3   \u2506 1     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_value_counts(s_pa)\npyarrow.Table\n: int64\ncount: int64\n----\n: [[1,2,3]]\ncount: [[2,2,1]]\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.var","title":"<code>var(*, ddof=1)</code>","text":"<p>Get the variance of this Series.</p> <p>Parameters:</p> Name Type Description Default <code>ddof</code> <code>int</code> <p>\"Delta Degrees of Freedom\": the divisor used in the calculation is N - ddof,      where N represents the number of elements.</p> <code>1</code> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_var(s_native: IntoSeries) -&gt; float:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.var()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_var</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_var(s_pd)\nnp.float64(1.0)\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_var(s_pl)\n1.0\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_var(s_pa)\n1.0\n</code></pre>"},{"location":"api-reference/series/#narwhals.series.Series.zip_with","title":"<code>zip_with(mask, other)</code>","text":"<p>Take values from self or other based on the given mask.</p> <p>Where mask evaluates true, take values from self. Where mask evaluates false, take values from other.</p> <p>Parameters:</p> Name Type Description Default <code>mask</code> <code>Self</code> <p>Boolean Series</p> required <code>other</code> <code>Self</code> <p>Series of same type.</p> required <p>Returns:</p> Type Description <code>Self</code> <p>A new Series with values selected from self or other based on the mask.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [1, 2, 3, 4, 5]\n&gt;&gt;&gt; other = [5, 4, 3, 2, 1]\n&gt;&gt;&gt; mask = [True, False, True, False, True]\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_zip_with(\n...     s1_native: IntoSeriesT, mask_native: IntoSeriesT, s2_native: IntoSeriesT\n... ) -&gt; IntoSeriesT:\n...     s1 = nw.from_native(s1_native, series_only=True)\n...     mask = nw.from_native(mask_native, series_only=True)\n...     s2 = nw.from_native(s2_native, series_only=True)\n...     return s1.zip_with(mask, s2).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_zip_with</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_zip_with(\n...     s1_native=pl.Series(data),\n...     mask_native=pl.Series(mask),\n...     s2_native=pl.Series(other),\n... )\nshape: (5,)\nSeries: '' [i64]\n[\n   1\n   4\n   3\n   2\n   5\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_zip_with(\n...     s1_native=pd.Series(data),\n...     mask_native=pd.Series(mask),\n...     s2_native=pd.Series(other),\n... )\n0    1\n1    4\n2    3\n3    2\n4    5\ndtype: int64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_zip_with(\n...     s1_native=pa.chunked_array([data]),\n...     mask_native=pa.chunked_array([mask]),\n...     s2_native=pa.chunked_array([other]),\n... )\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    4,\n    3,\n    2,\n    5\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_cat/","title":"<code>narwhals.Series.cat</code>","text":""},{"location":"api-reference/series_cat/#narwhals.series.SeriesCatNamespace.get_categories","title":"<code>get_categories()</code>","text":"<p>Get unique categories from column.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the unique categories.</p> <p>Examples:</p> <p>Let's create some series:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"apple\", \"mango\", \"mango\"]\n&gt;&gt;&gt; s_pd = pd.Series(data, dtype=\"category\")\n&gt;&gt;&gt; s_pl = pl.Series(data, dtype=pl.Categorical)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data]).dictionary_encode()\n</code></pre> <p>We define a dataframe-agnostic function to get unique categories from column 'fruits':</p> <pre><code>&gt;&gt;&gt; def agnostic_get_categories(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.cat.get_categories().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_get_categories</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_get_categories(s_pd)\n0    apple\n1    mango\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_get_categories(s_pl)\nshape: (2,)\nSeries: '' [str]\n[\n   \"apple\"\n   \"mango\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_get_categories(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"apple\",\n    \"mango\"\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/","title":"<code>narwhals.Series.dt</code>","text":""},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.convert_time_zone","title":"<code>convert_time_zone(time_zone)</code>","text":"<p>Convert time zone.</p> <p>If converting from a time-zone-naive column, then conversion happens as if converting from UTC.</p> <p>Parameters:</p> Name Type Description Default <code>time_zone</code> <code>str</code> <p>Target time zone.</p> required <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with the specified time zone.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\n...     datetime(2024, 1, 1, tzinfo=timezone.utc),\n...     datetime(2024, 1, 2, tzinfo=timezone.utc),\n... ]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_convert_time_zone(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.convert_time_zone(\"Asia/Kathmandu\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_convert_time_zone</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_convert_time_zone(s_pd)\n0   2024-01-01 05:45:00+05:45\n1   2024-01-02 05:45:00+05:45\ndtype: datetime64[ns, Asia/Kathmandu]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_convert_time_zone(s_pl)\nshape: (2,)\nSeries: '' [datetime[\u03bcs, Asia/Kathmandu]]\n[\n    2024-01-01 05:45:00 +0545\n    2024-01-02 05:45:00 +0545\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_convert_time_zone(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2024-01-01 00:00:00.000000Z,\n    2024-01-02 00:00:00.000000Z\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.date","title":"<code>date()</code>","text":"<p>Get the date in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with the date portion of the datetime values.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If pandas default backend is being used.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [datetime(2012, 1, 7, 10, 20), datetime(2023, 3, 10, 11, 32)]\n&gt;&gt;&gt; s_pd = pd.Series(dates).convert_dtypes(dtype_backend=\"pyarrow\")\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_date(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.date().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_date</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_date(s_pd)\n0    2012-01-07\n1    2023-03-10\ndtype: date32[day][pyarrow]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_date(s_pl)\nshape: (2,)\nSeries: '' [date]\n[\n   2012-01-07\n   2023-03-10\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_date(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2012-01-07,\n    2023-03-10\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.day","title":"<code>day()</code>","text":"<p>Extracts the day in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the day component of each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [datetime(2022, 1, 1), datetime(2022, 1, 5)]\n&gt;&gt;&gt; s_pd = pd.Series(dates)\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_day(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.day().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_day</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_day(s_pd)\n0    1\n1    5\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_day(s_pl)\nshape: (2,)\nSeries: '' [i8]\n[\n   1\n   5\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_day(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    5\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.hour","title":"<code>hour()</code>","text":"<p>Extracts the hour in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the hour component of each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [datetime(2022, 1, 1, 5, 3), datetime(2022, 1, 5, 9, 12)]\n&gt;&gt;&gt; s_pd = pd.Series(dates)\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_hour(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.hour().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_hour</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_hour(s_pd)\n0    5\n1    9\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_hour(s_pl)\nshape: (2,)\nSeries: '' [i8]\n[\n   5\n   9\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_hour(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    5,\n    9\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.microsecond","title":"<code>microsecond()</code>","text":"<p>Extracts the microseconds in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the microsecond component of each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [\n...     datetime(2023, 5, 21, 12, 55, 10, 400000),\n...     datetime(2023, 5, 21, 12, 55, 10, 600000),\n...     datetime(2023, 5, 21, 12, 55, 10, 800000),\n...     datetime(2023, 5, 21, 12, 55, 11, 0),\n...     datetime(2023, 5, 21, 12, 55, 11, 200000),\n... ]\n&gt;&gt;&gt; s_pd = pd.Series(dates)\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_microsecond(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.microsecond().alias(\"datetime\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_microsecond</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_microsecond(s_pd)\n0    400000\n1    600000\n2    800000\n3         0\n4    200000\nName: datetime, dtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_microsecond(s_pl)\nshape: (5,)\nSeries: 'datetime' [i32]\n[\n   400000\n   600000\n   800000\n   0\n   200000\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_microsecond(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    400000,\n    600000,\n    800000,\n    0,\n    200000\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.millisecond","title":"<code>millisecond()</code>","text":"<p>Extracts the milliseconds in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the millisecond component of each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [\n...     datetime(2023, 5, 21, 12, 55, 10, 400000),\n...     datetime(2023, 5, 21, 12, 55, 10, 600000),\n...     datetime(2023, 5, 21, 12, 55, 10, 800000),\n...     datetime(2023, 5, 21, 12, 55, 11, 0),\n...     datetime(2023, 5, 21, 12, 55, 11, 200000),\n... ]\n&gt;&gt;&gt; s_pd = pd.Series(dates)\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_millisecond(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.millisecond().alias(\"datetime\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_millisecond</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_millisecond(s_pd)\n0    400\n1    600\n2    800\n3      0\n4    200\nName: datetime, dtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_millisecond(s_pl)\nshape: (5,)\nSeries: 'datetime' [i32]\n[\n    400\n    600\n    800\n    0\n    200\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_millisecond(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    400,\n    600,\n    800,\n    0,\n    200\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.minute","title":"<code>minute()</code>","text":"<p>Extracts the minute in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the minute component of each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [datetime(2022, 1, 1, 5, 3), datetime(2022, 1, 5, 9, 12)]\n&gt;&gt;&gt; s_pd = pd.Series(dates)\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_minute(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.minute().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_minute</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_minute(s_pd)\n0     3\n1    12\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_minute(s_pl)\nshape: (2,)\nSeries: '' [i8]\n[\n   3\n   12\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_minute(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    3,\n    12\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.month","title":"<code>month()</code>","text":"<p>Gets the month in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the month component of each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [datetime(2023, 2, 1), datetime(2023, 8, 3)]\n&gt;&gt;&gt; s_pd = pd.Series(dates)\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_month(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.month().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_month</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_month(s_pd)\n0    2\n1    8\ndtype: int...\n&gt;&gt;&gt; agnostic_month(s_pl)\nshape: (2,)\nSeries: '' [i8]\n[\n   2\n   8\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_month(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2,\n    8\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.nanosecond","title":"<code>nanosecond()</code>","text":"<p>Extract the nanoseconds in a date series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the nanosecond component of each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [\n...     datetime(2022, 1, 1, 5, 3, 10, 500000),\n...     datetime(2022, 1, 5, 9, 12, 4, 60000),\n... ]\n&gt;&gt;&gt; s_pd = pd.Series(dates)\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_nanosecond(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.nanosecond().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_nanosecond</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_nanosecond(s_pd)\n0    500000000\n1     60000000\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_nanosecond(s_pl)\nshape: (2,)\nSeries: '' [i32]\n[\n   500000000\n   60000000\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_nanosecond(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    500000000,\n    60000000\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.ordinal_day","title":"<code>ordinal_day()</code>","text":"<p>Get ordinal day.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the ordinal day (day of year) for each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [datetime(2020, 1, 1), datetime(2020, 8, 3)]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_ordinal_day(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.ordinal_day().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_ordinal_day</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_ordinal_day(s_pd)\n0      1\n1    216\ndtype: int32\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_ordinal_day(s_pl)\nshape: (2,)\nSeries: '' [i16]\n[\n   1\n   216\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_ordinal_day(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    1,\n    216\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.replace_time_zone","title":"<code>replace_time_zone(time_zone)</code>","text":"<p>Replace time zone.</p> <p>Parameters:</p> Name Type Description Default <code>time_zone</code> <code>str | None</code> <p>Target time zone.</p> required <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with the specified time zone.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\n...     datetime(2024, 1, 1, tzinfo=timezone.utc),\n...     datetime(2024, 1, 2, tzinfo=timezone.utc),\n... ]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_replace_time_zone(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.replace_time_zone(\"Asia/Kathmandu\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_replace_time_zone</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_replace_time_zone(s_pd)\n0   2024-01-01 00:00:00+05:45\n1   2024-01-02 00:00:00+05:45\ndtype: datetime64[ns, Asia/Kathmandu]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace_time_zone(s_pl)\nshape: (2,)\nSeries: '' [datetime[\u03bcs, Asia/Kathmandu]]\n[\n    2024-01-01 00:00:00 +0545\n    2024-01-02 00:00:00 +0545\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace_time_zone(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2023-12-31 18:15:00.000000Z,\n    2024-01-01 18:15:00.000000Z\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.second","title":"<code>second()</code>","text":"<p>Extracts the seconds in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the second component of each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [datetime(2022, 1, 1, 5, 3, 10), datetime(2022, 1, 5, 9, 12, 4)]\n&gt;&gt;&gt; s_pd = pd.Series(dates)\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_second(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.second().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_second</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_second(s_pd)\n0    10\n1     4\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_second(s_pl)\nshape: (2,)\nSeries: '' [i8]\n[\n   10\n    4\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_second(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    10,\n    4\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.timestamp","title":"<code>timestamp(time_unit='us')</code>","text":"<p>Return a timestamp in the given time unit.</p> <p>Parameters:</p> Name Type Description Default <code>time_unit</code> <code>Literal['ns', 'us', 'ms']</code> <p>{'ns', 'us', 'ms'} Time unit.</p> <code>'us'</code> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with timestamps in the specified time unit.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import date\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [date(2001, 1, 1), None, date(2001, 1, 3)]\n&gt;&gt;&gt; s_pd = pd.Series(data, dtype=\"datetime64[ns]\")\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_timestamp(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.timestamp(\"ms\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_timestamp</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_timestamp(s_pd)\n0    9.783072e+11\n1             NaN\n2    9.784800e+11\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_timestamp(s_pl)\nshape: (3,)\nSeries: '' [i64]\n[\n        978307200000\n        null\n        978480000000\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_timestamp(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    978307200000,\n    null,\n    978480000000\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.total_microseconds","title":"<code>total_microseconds()</code>","text":"<p>Get total microseconds.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the total number of microseconds for each timedelta value.</p> Notes <p>The function outputs the total microseconds in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> in this case.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\n...     timedelta(microseconds=10),\n...     timedelta(milliseconds=1, microseconds=200),\n... ]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_total_microseconds(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.total_microseconds().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_total_microseconds</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_total_microseconds(s_pd)\n0      10\n1    1200\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_total_microseconds(s_pl)\nshape: (2,)\nSeries: '' [i64]\n[\n    10\n    1200\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_total_microseconds(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    10,\n    1200\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.total_milliseconds","title":"<code>total_milliseconds()</code>","text":"<p>Get total milliseconds.</p> Notes <p>The function outputs the total milliseconds in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> in this case.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the total number of milliseconds for each timedelta value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\n...     timedelta(milliseconds=10),\n...     timedelta(milliseconds=20, microseconds=40),\n... ]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_total_milliseconds(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.total_milliseconds().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_total_milliseconds</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_total_milliseconds(s_pd)\n0    10\n1    20\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_total_milliseconds(s_pl)\nshape: (2,)\nSeries: '' [i64]\n[\n        10\n        20\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_total_milliseconds(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    10,\n    20\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.total_minutes","title":"<code>total_minutes()</code>","text":"<p>Get total minutes.</p> Notes <p>The function outputs the total minutes in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> in this case.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the total number of minutes for each timedelta value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [timedelta(minutes=10), timedelta(minutes=20, seconds=40)]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_total_minutes(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.total_minutes().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_total_minutes</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_total_minutes(s_pd)\n0    10\n1    20\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_total_minutes(s_pl)\nshape: (2,)\nSeries: '' [i64]\n[\n        10\n        20\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_total_minutes(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    10,\n    20\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.total_nanoseconds","title":"<code>total_nanoseconds()</code>","text":"<p>Get total nanoseconds.</p> Notes <p>The function outputs the total nanoseconds in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> in this case.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the total number of nanoseconds for each timedelta value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"2024-01-01 00:00:00.000000001\", \"2024-01-01 00:00:00.000000002\"]\n&gt;&gt;&gt; s_pd = pd.to_datetime(pd.Series(data))\n&gt;&gt;&gt; s_pl = pl.Series(data).str.to_datetime(time_unit=\"ns\")\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_total_nanoseconds(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.diff().dt.total_nanoseconds().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_total_nanoseconds</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_total_nanoseconds(s_pd)\n0    NaN\n1    1.0\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_total_nanoseconds(s_pl)\nshape: (2,)\nSeries: '' [i64]\n[\n        null\n        1\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.total_seconds","title":"<code>total_seconds()</code>","text":"<p>Get total seconds.</p> Notes <p>The function outputs the total seconds in the int dtype by default, however, pandas may change the dtype to float when there are missing values, consider using <code>fill_null()</code> in this case.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the total number of seconds for each timedelta value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import timedelta\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [timedelta(seconds=10), timedelta(seconds=20, milliseconds=40)]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_total_seconds(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.total_seconds().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_total_seconds</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_total_seconds(s_pd)\n0    10\n1    20\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_total_seconds(s_pl)\nshape: (2,)\nSeries: '' [i64]\n[\n        10\n        20\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_total_seconds(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    10,\n    20\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.to_string","title":"<code>to_string(format)</code>","text":"<p>Convert a Date/Time/Datetime series into a String series with the given format.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str</code> <p>Format string for converting the datetime to string.</p> required <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with the datetime values formatted as strings according to the specified format.</p> Notes <p>Unfortunately, different libraries interpret format directives a bit differently.</p> <ul> <li>Chrono, the library used by Polars, uses <code>\"%.f\"</code> for fractional seconds,   whereas pandas and Python stdlib use <code>\".%f\"</code>.</li> <li>PyArrow interprets <code>\"%S\"</code> as \"seconds, including fractional seconds\"   whereas most other tools interpret it as \"just seconds, as 2 digits\".</li> </ul> <p>Therefore, we make the following adjustments:</p> <ul> <li>for pandas-like libraries, we replace <code>\"%S.%f\"</code> with <code>\"%S%.f\"</code>.</li> <li>for PyArrow, we replace <code>\"%S.%f\"</code> with <code>\"%S\"</code>.</li> </ul> <p>Workarounds like these don't make us happy, and we try to avoid them as much as possible, but here we feel like it's the best compromise.</p> <p>If you just want to format a date/datetime Series as a local datetime string, and have it work as consistently as possible across libraries, we suggest using:</p> <ul> <li><code>\"%Y-%m-%dT%H:%M:%S%.f\"</code> for datetimes</li> <li><code>\"%Y-%m-%d\"</code> for dates</li> </ul> <p>though note that, even then, different tools may return a different number of trailing zeros. Nonetheless, this is probably consistent enough for most applications.</p> <p>If you have an application where this is not enough, please open an issue and let us know.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\n...     datetime(2020, 3, 1),\n...     datetime(2020, 4, 1),\n...     datetime(2020, 5, 1),\n... ]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_string(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.to_string(\"%Y/%m/%d\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_string</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_string(s_pd)\n0    2020/03/01\n1    2020/04/01\n2    2020/05/01\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_string(s_pl)\nshape: (3,)\nSeries: '' [str]\n[\n   \"2020/03/01\"\n   \"2020/04/01\"\n   \"2020/05/01\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_string(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"2020/03/01\",\n    \"2020/04/01\",\n    \"2020/05/01\"\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.weekday","title":"<code>weekday()</code>","text":"<p>Extract the week day in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the week day for each datetime value.</p> <code>SeriesT</code> <p>Returns the ISO weekday number where monday = 1 and sunday = 7</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n&gt;&gt;&gt; data = [datetime(2020, 1, 1), datetime(2020, 8, 3)]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_weekday(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.weekday().to_native()\n</code></pre> <p>We can then pass either pandas, Polars, PyArrow, and other supported libraries to <code>agnostic_weekday</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_weekday(s_pd)\n0    3\n1    1\ndtype: int32\n&gt;&gt;&gt; agnostic_weekday(s_pl)\nshape: (2,)\nSeries: '' [i8]\n[\n   3\n   1\n]\n&gt;&gt;&gt; agnostic_weekday(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    3,\n    1\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_dt/#narwhals.series.SeriesDateTimeNamespace.year","title":"<code>year()</code>","text":"<p>Get the year in a datetime series.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the year component of each datetime value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime\n&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; dates = [datetime(2012, 1, 7), datetime(2023, 3, 10)]\n&gt;&gt;&gt; s_pd = pd.Series(dates)\n&gt;&gt;&gt; s_pl = pl.Series(dates)\n&gt;&gt;&gt; s_pa = pa.chunked_array([dates])\n</code></pre> <p>We define a library agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_year(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.dt.year().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_year</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_year(s_pd)\n0    2012\n1    2023\ndtype: int...\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_year(s_pl)\nshape: (2,)\nSeries: '' [i32]\n[\n   2012\n   2023\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_year(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2012,\n    2023\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_list/","title":"<code>narwhals.Series.list</code>","text":""},{"location":"api-reference/series_list/#narwhals.series.SeriesListNamespace.len","title":"<code>len()</code>","text":"<p>Return the number of elements in each list.</p> <p>Null values count towards the total.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new series.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [[1, 2], [3, 4, None], None, []]\n</code></pre> <p>Let's define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_list_len(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.list.len().to_native()\n</code></pre> <p>We can then pass pandas / PyArrow / Polars / any other supported library:</p> <pre><code>&gt;&gt;&gt; agnostic_list_len(\n...     pd.Series(data, dtype=pd.ArrowDtype(pa.list_(pa.int64())))\n... )\n0       2\n1       3\n2    &lt;NA&gt;\n3       0\ndtype: int32[pyarrow]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_list_len(pl.Series(data))\nshape: (4,)\nSeries: '' [u32]\n[\n   2\n   3\n   null\n   0\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_list_len(pa.chunked_array([data]))\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    2,\n    3,\n    null,\n    0\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/","title":"<code>narwhals.Series.str</code>","text":""},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.contains","title":"<code>contains(pattern, *, literal=False)</code>","text":"<p>Check if string contains a substring that matches a pattern.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>A Character sequence or valid regular expression pattern.</p> required <code>literal</code> <code>bool</code> <p>If True, treats the pattern as a literal string.      If False, assumes the pattern is a regular expression.</p> <code>False</code> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with boolean values indicating if each string contains the pattern.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"cat\", \"dog\", \"rabbit and parrot\", \"dove\", None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_contains(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.contains(\"parrot|dove\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_contains</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_contains(s_pd)\n0    False\n1    False\n2     True\n3     True\n4     None\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_contains(s_pl)\nshape: (5,)\nSeries: '' [bool]\n[\n   false\n   false\n   true\n   true\n   null\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_contains(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    false,\n    false,\n    true,\n    true,\n    null\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.ends_with","title":"<code>ends_with(suffix)</code>","text":"<p>Check if string values end with a substring.</p> <p>Parameters:</p> Name Type Description Default <code>suffix</code> <code>str</code> <p>suffix substring</p> required <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with boolean values indicating if each string ends with the suffix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"apple\", \"mango\", None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_ends_with(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.ends_with(\"ngo\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_ends_with</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_ends_with(s_pd)\n0    False\n1     True\n2     None\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_ends_with(s_pl)\nshape: (3,)\nSeries: '' [bool]\n[\n   false\n   true\n   null\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_ends_with(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    false,\n    true,\n    null\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.head","title":"<code>head(n=5)</code>","text":"<p>Take the first n elements of each string.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of elements to take. Negative indexing is supported (see note (1.))</p> <code>5</code> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the first n characters of each string.</p> Notes <ol> <li>When the <code>n</code> input is negative, <code>head</code> returns characters up to the n-th from the end of the string.     For example, if <code>n = -3</code>, then all characters except the last three are returned.</li> <li>If the length of the string has fewer than <code>n</code> characters, the full string is returned.</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"Atatata\", \"taata\", \"taatatata\", \"zukkyun\"]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_head(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.head().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_head</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_head(s_pd)\n0    Atata\n1    taata\n2    taata\n3    zukky\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_head(s_pl)\nshape: (4,)\nSeries: '' [str]\n[\n   \"Atata\"\n   \"taata\"\n   \"taata\"\n   \"zukky\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_head(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"Atata\",\n    \"taata\",\n    \"taata\",\n    \"zukky\"\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.len_chars","title":"<code>len_chars()</code>","text":"<p>Return the length of each string as the number of characters.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the length of each string in characters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"foo\", \"Caf\u00e9\", \"345\", \"\u6771\u4eac\", None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_len_chars(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.len_chars().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_len_chars</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_len_chars(s_pd)\n0    3.0\n1    4.0\n2    3.0\n3    2.0\n4    NaN\ndtype: float64\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_len_chars(s_pl)\nshape: (5,)\nSeries: '' [u32]\n[\n   3\n   4\n   3\n   2\n   null\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_len_chars(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    3,\n    4,\n    3,\n    2,\n    null\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.replace","title":"<code>replace(pattern, value, *, literal=False, n=1)</code>","text":"<p>Replace first matching regex/literal substring with a new string value.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>A valid regular expression pattern.</p> required <code>value</code> <code>str</code> <p>String that will replace the matched substring.</p> required <code>literal</code> <code>bool</code> <p>Treat <code>pattern</code> as a literal string.</p> <code>False</code> <code>n</code> <code>int</code> <p>Number of matches to replace.</p> <code>1</code> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with the regex/literal pattern replaced with the specified value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"123abc\", \"abc abc123\"]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_replace(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     s = s.str.replace(\"abc\", \"\")\n...     return s.to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_replace</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_replace(s_pd)\n0        123\n1     abc123\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace(s_pl)\nshape: (2,)\nSeries: '' [str]\n[\n    \"123\"\n    \" abc123\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"123\",\n    \" abc123\"\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.replace_all","title":"<code>replace_all(pattern, value, *, literal=False)</code>","text":"<p>Replace all matching regex/literal substring with a new string value.</p> <p>Parameters:</p> Name Type Description Default <code>pattern</code> <code>str</code> <p>A valid regular expression pattern.</p> required <code>value</code> <code>str</code> <p>String that will replace the matched substring.</p> required <code>literal</code> <code>bool</code> <p>Treat <code>pattern</code> as a literal string.</p> <code>False</code> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with all occurrences of pattern replaced with the specified value.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"123abc\", \"abc abc123\"]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_replace_all(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     s = s.str.replace_all(\"abc\", \"\")\n...     return s.to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_replace_all</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_replace_all(s_pd)\n0     123\n1     123\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace_all(s_pl)\nshape: (2,)\nSeries: '' [str]\n[\n    \"123\"\n    \" 123\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_replace_all(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"123\",\n    \" 123\"\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.slice","title":"<code>slice(offset, length=None)</code>","text":"<p>Create subslices of the string values of a Series.</p> <p>Parameters:</p> Name Type Description Default <code>offset</code> <code>int</code> <p>Start index. Negative indexing is supported.</p> required <code>length</code> <code>int | None</code> <p>Length of the slice. If set to <code>None</code> (default), the slice is taken to the end of the string.</p> <code>None</code> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing subslices of each string.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"pear\", None, \"papaya\", \"dragonfruit\"]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_slice(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.slice(4, length=3).to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_slice</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_slice(s_pd)\n0\n1    None\n2      ya\n3     onf\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_slice(s_pl)\nshape: (4,)\nSeries: '' [str]\n[\n   \"\"\n   null\n   \"ya\"\n   \"onf\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_slice(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"\",\n    null,\n    \"ya\",\n    \"onf\"\n  ]\n]\n</code></pre> <p>Using negative indexes:</p> <pre><code>&gt;&gt;&gt; def agnostic_slice(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.slice(-3).to_native()\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_slice(s_pd)\n0     ear\n1    None\n2     aya\n3     uit\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_slice(s_pl)\nshape: (4,)\nSeries: '' [str]\n[\n    \"ear\"\n    null\n    \"aya\"\n    \"uit\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_slice(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"ear\",\n    null,\n    \"aya\",\n    \"uit\"\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.starts_with","title":"<code>starts_with(prefix)</code>","text":"<p>Check if string values start with a substring.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>prefix substring</p> required <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with boolean values indicating if each string starts with the prefix.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"apple\", \"mango\", None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_starts_with(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.starts_with(\"app\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_starts_with</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_starts_with(s_pd)\n0     True\n1    False\n2     None\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_starts_with(s_pl)\nshape: (3,)\nSeries: '' [bool]\n[\n   true\n   false\n   null\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_starts_with(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    true,\n    false,\n    null\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.strip_chars","title":"<code>strip_chars(characters=None)</code>","text":"<p>Remove leading and trailing characters.</p> <p>Parameters:</p> Name Type Description Default <code>characters</code> <code>str | None</code> <p>The set of characters to be removed. All combinations of this set of characters will be stripped from the start and end of the string. If set to None (default), all leading and trailing whitespace is removed instead.</p> <code>None</code> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with leading and trailing characters removed.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"apple\", \"\\nmango\"]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_strip_chars(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     s = s.str.strip_chars()\n...     return s.to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_strip_chars</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_strip_chars(s_pd)\n0    apple\n1    mango\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_strip_chars(s_pl)\nshape: (2,)\nSeries: '' [str]\n[\n    \"apple\"\n    \"mango\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_strip_chars(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"apple\",\n    \"mango\"\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.tail","title":"<code>tail(n=5)</code>","text":"<p>Take the last n elements of each string.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of elements to take. Negative indexing is supported (see note (1.))</p> <code>5</code> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series containing the last n characters of each string.</p> Notes <ol> <li>When the <code>n</code> input is negative, <code>tail</code> returns characters starting from the n-th from the beginning of     the string. For example, if <code>n = -3</code>, then all characters except the first three are returned.</li> <li>If the length of the string has fewer than <code>n</code> characters, the full string is returned.</li> </ol> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"Atatata\", \"taata\", \"taatatata\", \"zukkyun\"]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_tail(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.tail().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_tail</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_tail(s_pd)\n0    atata\n1    taata\n2    atata\n3    kkyun\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_tail(s_pl)\nshape: (4,)\nSeries: '' [str]\n[\n   \"atata\"\n   \"taata\"\n   \"atata\"\n   \"kkyun\"\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_tail(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"atata\",\n    \"taata\",\n    \"atata\",\n    \"kkyun\"\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.to_datetime","title":"<code>to_datetime(format=None)</code>","text":"<p>Parse Series with strings to a Series with Datetime dtype.</p> Notes <p>pandas defaults to nanosecond time unit, Polars to microsecond. Prior to pandas 2.0, nanoseconds were the only time unit supported in pandas, with no ability to set any other one. The ability to set the time unit in pandas, if the version permits, will arrive.</p> Warning <p>As different backends auto-infer format in different ways, if <code>format=None</code> there is no guarantee that the result will be equal.</p> <p>Parameters:</p> Name Type Description Default <code>format</code> <code>str | None</code> <p>Format to use for conversion. If set to None (default), the format is inferred from the data.</p> <code>None</code> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with datetime dtype.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"2020-01-01\", \"2020-01-02\"]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_datetime(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.to_datetime(format=\"%Y-%m-%d\").to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_datetime</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_datetime(s_pd)\n0   2020-01-01\n1   2020-01-02\ndtype: datetime64[ns]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_datetime(s_pl)\nshape: (2,)\nSeries: '' [datetime[\u03bcs]]\n[\n   2020-01-01 00:00:00\n   2020-01-02 00:00:00\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_datetime(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at 0x...&gt;\n[\n  [\n    2020-01-01 00:00:00.000000,\n    2020-01-02 00:00:00.000000\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.to_lowercase","title":"<code>to_lowercase()</code>","text":"<p>Transform string to lowercase variant.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with values converted to lowercase.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"APPLE\", \"MANGO\", None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_lowercase(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.to_lowercase().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_lowercase</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_lowercase(s_pd)\n0    apple\n1    mango\n2     None\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_lowercase(s_pl)\nshape: (3,)\nSeries: '' [str]\n[\n   \"apple\"\n   \"mango\"\n   null\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_lowercase(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"apple\",\n    \"mango\",\n    null\n  ]\n]\n</code></pre>"},{"location":"api-reference/series_str/#narwhals.series.SeriesStringNamespace.to_uppercase","title":"<code>to_uppercase()</code>","text":"<p>Transform string to uppercase variant.</p> <p>Returns:</p> Type Description <code>SeriesT</code> <p>A new Series with values converted to uppercase.</p> Notes <p>The PyArrow backend will convert '\u00df' to '\u1e9e' instead of 'SS'. For more info see: https://github.com/apache/arrow/issues/34599 There may be other unicode-edge-case-related variations across implementations.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import pandas as pd\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; import pyarrow as pa\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n</code></pre> <pre><code>&gt;&gt;&gt; data = [\"apple\", \"mango\", None]\n&gt;&gt;&gt; s_pd = pd.Series(data)\n&gt;&gt;&gt; s_pl = pl.Series(data)\n&gt;&gt;&gt; s_pa = pa.chunked_array([data])\n</code></pre> <p>We define a dataframe-agnostic function:</p> <pre><code>&gt;&gt;&gt; def agnostic_to_uppercase(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.str.to_uppercase().to_native()\n</code></pre> <p>We can then pass any supported library such as pandas, Polars, or PyArrow to <code>agnostic_to_uppercase</code>:</p> <pre><code>&gt;&gt;&gt; agnostic_to_uppercase(s_pd)\n0    APPLE\n1    MANGO\n2     None\ndtype: object\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_uppercase(s_pl)\nshape: (3,)\nSeries: '' [str]\n[\n   \"APPLE\"\n   \"MANGO\"\n   null\n]\n</code></pre> <pre><code>&gt;&gt;&gt; agnostic_to_uppercase(s_pa)\n&lt;pyarrow.lib.ChunkedArray object at ...&gt;\n[\n  [\n    \"APPLE\",\n    \"MANGO\",\n    null\n  ]\n]\n</code></pre>"},{"location":"api-reference/typing/","title":"<code>narwhals.typing</code>","text":"<p>Narwhals comes fully statically typed. In addition to <code>nw.DataFrame</code>, <code>nw.Expr</code>, <code>nw.Series</code>, <code>nw.LazyFrame</code>, we also provide the following type hints:</p>"},{"location":"api-reference/typing/#narwhals.typing.DataFrameT","title":"<code>DataFrameT = TypeVar('DataFrameT', bound='DataFrame[Any]')</code>  <code>module-attribute</code>","text":"<p>TypeVar bound to Narwhals DataFrame.</p> <p>Use this if your function can accept a Narwhals DataFrame and returns a Narwhals DataFrame backed by the same backend.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import DataFrameT\n&gt;&gt;&gt; @nw.narwhalify\n&gt;&gt;&gt; def func(df: DataFrameT) -&gt; DataFrameT:\n...     return df.with_columns(c=df[\"a\"] + 1)\n</code></pre>"},{"location":"api-reference/typing/#narwhals.typing.Frame","title":"<code>Frame = Union['DataFrame[Any]', 'LazyFrame[Any]']</code>  <code>module-attribute</code>","text":"<p>Narwhals DataFrame or Narwhals LazyFrame.</p> <p>Use this if your function can work with either and your function doesn't care about its backend.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import Frame\n&gt;&gt;&gt; @nw.narwhalify\n... def agnostic_columns(df: Frame) -&gt; list[str]:\n...     return df.columns\n</code></pre>"},{"location":"api-reference/typing/#narwhals.typing.FrameT","title":"<code>FrameT = TypeVar('FrameT', bound='Frame')</code>  <code>module-attribute</code>","text":"<p>TypeVar bound to Narwhals DataFrame or Narwhals LazyFrame.</p> <p>Use this if your function accepts either <code>nw.DataFrame</code> or <code>nw.LazyFrame</code> and returns an object of the same kind.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import FrameT\n&gt;&gt;&gt; @nw.narwhalify\n... def agnostic_func(df: FrameT) -&gt; FrameT:\n...     return df.with_columns(c=nw.col(\"a\") + 1)\n</code></pre>"},{"location":"api-reference/typing/#narwhals.typing.IntoDataFrame","title":"<code>IntoDataFrame = Union['NativeFrame', 'DataFrame[Any]', 'DataFrameLike']</code>  <code>module-attribute</code>","text":"<p>Anything which can be converted to a Narwhals DataFrame.</p> <p>Use this if your function accepts a narwhalifiable object but doesn't care about its backend.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrame\n&gt;&gt;&gt; def agnostic_shape(df_native: IntoDataFrame) -&gt; tuple[int, int]:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.shape\n</code></pre>"},{"location":"api-reference/typing/#narwhals.typing.IntoDataFrameT","title":"<code>IntoDataFrameT = TypeVar('IntoDataFrameT', bound='IntoDataFrame')</code>  <code>module-attribute</code>","text":"<p>TypeVar bound to object convertible to Narwhals DataFrame.</p> <p>Use this if your function accepts an object which can be converted to <code>nw.DataFrame</code> and returns an object of the same class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoDataFrameT\n&gt;&gt;&gt; def agnostic_func(df_native: IntoDataFrameT) -&gt; IntoDataFrameT:\n...     df = nw.from_native(df_native, eager_only=True)\n...     return df.with_columns(c=df[\"a\"] + 1).to_native()\n</code></pre>"},{"location":"api-reference/typing/#narwhals.typing.IntoExpr","title":"<code>IntoExpr = Union['Expr', str, 'Series[Any]']</code>  <code>module-attribute</code>","text":"<p>Anything which can be converted to an expression.</p> <p>Use this to mean \"either a Narwhals expression, or something which can be converted into one\". For example, <code>exprs</code> in <code>DataFrame.select</code> is typed to accept <code>IntoExpr</code>, as it can either accept a <code>nw.Expr</code> (e.g. <code>df.select(nw.col('a'))</code>) or a string which will be interpreted as a <code>nw.Expr</code>, e.g. <code>df.select('a')</code>.</p>"},{"location":"api-reference/typing/#narwhals.typing.IntoFrame","title":"<code>IntoFrame = Union['NativeFrame', 'DataFrame[Any]', 'LazyFrame[Any]', 'DataFrameLike']</code>  <code>module-attribute</code>","text":"<p>Anything which can be converted to a Narwhals DataFrame or LazyFrame.</p> <p>Use this if your function can accept an object which can be converted to either <code>nw.DataFrame</code> or <code>nw.LazyFrame</code> and it doesn't care about its backend.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrame\n&gt;&gt;&gt; def agnostic_columns(df_native: IntoFrame) -&gt; list[str]:\n...     df = nw.from_native(df_native)\n...     return df.collect_schema().names()\n</code></pre>"},{"location":"api-reference/typing/#narwhals.typing.IntoFrameT","title":"<code>IntoFrameT = TypeVar('IntoFrameT', bound='IntoFrame')</code>  <code>module-attribute</code>","text":"<p>TypeVar bound to object convertible to Narwhals DataFrame or Narwhals LazyFrame.</p> <p>Use this if your function accepts an object which is convertible to <code>nw.DataFrame</code> or <code>nw.LazyFrame</code> and returns an object of the same type.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoFrameT\n&gt;&gt;&gt; def agnostic_func(df_native: IntoFrameT) -&gt; IntoFrameT:\n...     df = nw.from_native(df_native)\n...     return df.with_columns(c=nw.col(\"a\") + 1).to_native()\n</code></pre>"},{"location":"api-reference/typing/#narwhals.typing.IntoSeries","title":"<code>IntoSeries = Union['Series[Any]', 'NativeSeries']</code>  <code>module-attribute</code>","text":"<p>Anything which can be converted to a Narwhals Series.</p> <p>Use this if your function can accept an object which can be converted to <code>nw.Series</code> and it doesn't care about its backend.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from typing import Any\n&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeries\n&gt;&gt;&gt; def agnostic_to_list(s_native: IntoSeries) -&gt; list[Any]:\n...     s = nw.from_native(s_native)\n...     return s.to_list()\n</code></pre>"},{"location":"api-reference/typing/#narwhals.typing.IntoSeriesT","title":"<code>IntoSeriesT = TypeVar('IntoSeriesT', bound='IntoSeries')</code>  <code>module-attribute</code>","text":"<p>TypeVar bound to object convertible to Narwhals Series.</p> <p>Use this if your function accepts an object which can be converted to <code>nw.Series</code> and returns an object of the same class.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import narwhals as nw\n&gt;&gt;&gt; from narwhals.typing import IntoSeriesT\n&gt;&gt;&gt; def agnostic_abs(s_native: IntoSeriesT) -&gt; IntoSeriesT:\n...     s = nw.from_native(s_native, series_only=True)\n...     return s.abs().to_native()\n</code></pre>"},{"location":"api-reference/typing/#nwnarwhalify-or-nwfrom_native","title":"<code>nw.narwhalify</code>, or <code>nw.from_native</code>?","text":"<p>Although some people find the former more readable, the latter is better at preserving type hints.</p> <p>Here's an example: <pre><code>import polars as pl\nimport narwhals as nw\nfrom narwhals.typing import IntoDataFrameT, DataFrameT\n\ndf = pl.DataFrame({\"a\": [1, 2, 3]})\n\n\ndef func(df_native: IntoDataFrameT) -&gt; IntoDataFrameT:\n    df = nw.from_native(df_native, eager_only=True)\n    return df.select(b=nw.col(\"a\")).to_native()\n\n\nreveal_type(func(df))\n\n\n@nw.narwhalify(strict=True)\ndef func_2(df: DataFrameT) -&gt; DataFrameT:\n    return df.select(b=nw.col(\"a\"))\n\n\nreveal_type(func_2(df))\n</code></pre></p> <p>Running <code>mypy</code> on it gives: <pre><code>$ mypy t.py \nt.py:13: note: Revealed type is \"polars.dataframe.frame.DataFrame\"\nt.py:21: note: Revealed type is \"Any\"\nSuccess: no issues found in 1 source file\n</code></pre></p> <p>In the first case, mypy can infer that <code>df</code> is a <code>polars.DataFrame</code>. In the second case, it can't.</p> <p>If you want to make the most out of type hints and preserve them as much as possible, we recommend <code>nw.from_native</code> and <code>nw.to_native</code>. Type hints will still be respected inside the function body if you type the arguments.</p>"},{"location":"basics/complete_example/","title":"Complete example","text":"<p>We're going to write a dataframe-agnostic \"Standard Scaler\". This class will have <code>fit</code> and <code>transform</code> methods (like <code>scikit-learn</code> transformers), and will work agnostically for pandas and Polars.</p> <p>We'll need to write two methods:</p> <ul> <li><code>fit</code>: find the mean and standard deviation for each column from a given training set;</li> <li><code>transform</code>: scale a given dataset with the mean and standard deviations calculated   during <code>fit</code>.</li> </ul>"},{"location":"basics/complete_example/#fit-method","title":"Fit method","text":"<p>Unlike the <code>transform</code> method, which we'll write below, <code>fit</code> cannot stay lazy, as we need to compute concrete values for the means and standard deviations.</p> <p>To be able to get <code>Series</code> out of our <code>DataFrame</code>, we'll pass <code>eager_only=True</code> to <code>nw.from_native</code>. This is because Polars doesn't have a concept of lazy <code>Series</code>, and so Narwhals doesn't either.</p> <p>We can specify that in the <code>@nw.narwhalify</code> decorator by setting <code>eager_only=True</code>, and the argument will be propagated to <code>nw.from_native</code>.</p> from/to_native@narwhalify <pre><code>from typing import Self\nimport narwhals as nw\nfrom narwhals.typing import IntoDataFrameT\n\n\nclass StandardScaler:\n    def fit(self: Self, df: IntoDataFrameT) -&gt; Self:\n        df_nw = nw.from_native(df, eager_only=True)\n        self._means = {col: df_nw[col].mean() for col in df_nw.columns}\n        self._std_devs = {col: df_nw[col].std() for col in df_nw.columns}\n        self._columns = df_nw.columns\n        return self\n</code></pre> <pre><code>from typing import Self\nimport narwhals as nw\nfrom narwhals.typing import DataFrameT\n\n\nclass StandardScaler:\n    @nw.narwhalify(eager_only=True)\n    def fit(self: Self, df: DataFrameT) -&gt; Self:\n        self._means = {col: df[col].mean() for col in df.columns}\n        self._std_devs = {col: df[col].std() for col in df.columns}\n        self._columns = df.columns\n        return self\n</code></pre>"},{"location":"basics/complete_example/#transform-method","title":"Transform method","text":"<p>We're going to take in a dataframe, and return a dataframe of the same type:</p> from/to_native@narwhalify <pre><code>from typing import Self\nimport narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\n\nclass StandardScaler:\n    ...\n\n    def transform(self: Self, df: IntoFrameT) -&gt; IntoFrameT:\n        df_nw = nw.from_native(df)\n        return df_nw.with_columns(\n            (nw.col(col) - self._means[col]) / self._std_devs[col]\n            for col in self._columns\n        ).to_native()\n</code></pre> <pre><code>from typing import Self\nimport narwhals as nw\nfrom narwhals.typing import FrameT\n\n\nclass StandardScaler:\n    ...\n\n    @nw.narwhalify\n    def transform(self: Self, df: FrameT) -&gt; FrameT:\n        return df.with_columns(\n            (nw.col(col) - self._means[col]) / self._std_devs[col]\n            for col in self._columns\n        )\n</code></pre> <p>Note that all the calculations here can stay lazy if the underlying library permits it, so we don't pass in any extra keyword-arguments such as <code>eager_only</code>, we just use the default <code>eager_only=False</code>.</p>"},{"location":"basics/complete_example/#putting-it-all-together","title":"Putting it all together","text":"<p>Here is our dataframe-agnostic standard scaler:</p> from/to_native@narwhalify <pre><code>from typing import Self\nimport narwhals as nw\nfrom narwhals.typing import IntoDataFrameT\nfrom narwhals.typing import IntoFrameT\n\n\nclass StandardScaler:\n    def fit(self: Self, df: IntoDataFrameT) -&gt; Self:\n        df_nw = nw.from_native(df, eager_only=True)\n        self._means = {col: df_nw[col].mean() for col in df_nw.columns}\n        self._std_devs = {col: df_nw[col].std() for col in df_nw.columns}\n        self._columns = df_nw.columns\n        return self\n\n    def transform(self: Self, df: IntoFrameT) -&gt; IntoFrameT:\n        df_nw = nw.from_native(df)\n        return df_nw.with_columns(\n            (nw.col(col) - self._means[col]) / self._std_devs[col]\n            for col in self._columns\n        ).to_native()\n</code></pre> <pre><code>from typing import Self\nimport narwhals as nw\nfrom narwhals.typing import DataFrameT\nfrom narwhals.typing import FrameT\n\n\nclass StandardScaler:\n    @nw.narwhalify(eager_only=True)\n    def fit(self: Self, df: DataFrameT) -&gt; Self:\n        self._means = {col: df[col].mean() for col in df.columns}\n        self._std_devs = {col: df[col].std() for col in df.columns}\n        self._columns = df.columns\n        return self\n\n    @nw.narwhalify\n    def transform(self: Self, df: FrameT) -&gt; FrameT:\n        return df.with_columns(\n            (nw.col(col) - self._means[col]) / self._std_devs[col]\n            for col in self._columns\n        )\n</code></pre> <p>Next, let's try running it. Notice how, as <code>transform</code> doesn't use any eager-only features, so we can pass a Polars LazyFrame to it and have it stay lazy!</p> pandasPolars <pre><code>import pandas as pd\n\ndf_train = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 7]})\ndf_test = pd.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 7]})\nscaler = StandardScaler()\nscaler.fit(df_train)\nprint(scaler.transform(df_test))\n</code></pre> <pre><code>     a         b\n0 -1.0 -0.872872\n1  0.0 -0.218218\n2  1.0  1.091089\n</code></pre> <pre><code>import polars as pl\n\ndf_train = pl.DataFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 7]})\ndf_test = pl.LazyFrame({\"a\": [1, 2, 3], \"b\": [4, 5, 7]})\nscaler = StandardScaler()\nscaler.fit(df_train)\nprint(scaler.transform(df_test).collect())\n</code></pre> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 b         \u2502\n\u2502 ---  \u2506 ---       \u2502\n\u2502 f64  \u2506 f64       \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -1.0 \u2506 -0.872872 \u2502\n\u2502 0.0  \u2506 -0.218218 \u2502\n\u2502 1.0  \u2506 1.091089  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"basics/dataframe/","title":"DataFrame","text":"<p>To write a dataframe-agnostic function, the steps you'll want to follow are:</p> <ol> <li> <p>Initialise a Narwhals DataFrame or LazyFrame by passing your dataframe to <code>nw.from_native</code>.     All the calculations stay lazy if we start with a lazy dataframe - Narwhals will never automatically trigger computation without you asking it to.</p> <p>Note: if you need eager execution, make sure to pass <code>eager_only=True</code> to <code>nw.from_native</code>.</p> </li> <li> <p>Express your logic using the subset of the Polars API supported by Narwhals.</p> </li> <li>If you need to return a dataframe to the user in its original library, call <code>nw.to_native</code>.</li> </ol> <p>Steps 1 and 3 are so common that we provide a utility <code>@nw.narwhalify</code> decorator, which allows you to only explicitly write step 2.</p> <p>Let's explore this with some simple examples.</p>"},{"location":"basics/dataframe/#example-1-descriptive-statistics","title":"Example 1: descriptive statistics","text":"<p>Just like in Polars, we can pass expressions to <code>DataFrame.select</code> or <code>LazyFrame.select</code>.</p> <p>Make a Python file with the following content:</p> from/to_native@narwhalify <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\n\ndef func(df: IntoFrameT) -&gt; IntoFrameT:\n    return (\n        nw.from_native(df)\n        .select(\n            a_sum=nw.col(\"a\").sum(),\n            a_mean=nw.col(\"a\").mean(),\n            a_std=nw.col(\"a\").std(),\n        )\n        .to_native()\n    )\n</code></pre> <pre><code>import narwhals as nw\nfrom narwhals.typing import FrameT\n\n\n@nw.narwhalify\ndef func(df: FrameT) -&gt; FrameT:\n    return df.select(\n        a_sum=nw.col(\"a\").sum(),\n        a_mean=nw.col(\"a\").mean(),\n        a_std=nw.col(\"a\").std(),\n    )\n</code></pre> <p>Let's try it out:</p> pandasPolars (eager)Polars (lazy)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"a\": [1, 1, 2]})\nprint(func(df))\n</code></pre> <pre><code>   a_sum    a_mean    a_std\n0      4  1.333333  0.57735\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame({\"a\": [1, 1, 2]})\nprint(func(df))\n</code></pre> <pre><code>shape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a_sum \u2506 a_mean   \u2506 a_std   \u2502\n\u2502 ---   \u2506 ---      \u2506 ---     \u2502\n\u2502 i64   \u2506 f64      \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 4     \u2506 1.333333 \u2506 0.57735 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.LazyFrame({\"a\": [1, 1, 2]})\nprint(func(df).collect())\n</code></pre> <pre><code>shape: (1, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a_sum \u2506 a_mean   \u2506 a_std   \u2502\n\u2502 ---   \u2506 ---      \u2506 ---     \u2502\n\u2502 i64   \u2506 f64      \u2506 f64     \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 4     \u2506 1.333333 \u2506 0.57735 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table({\"a\": [1, 1, 2]})\nprint(func(table))\n</code></pre> <pre><code>pyarrow.Table\na_sum: int64\na_mean: double\na_std: double\n----\na_sum: [[4]]\na_mean: [[1.3333333333333333]]\na_std: [[0.5773502691896257]]\n</code></pre>"},{"location":"basics/dataframe/#example-2-group-by-and-mean","title":"Example 2: group-by and mean","text":"<p>Just like in Polars, we can pass expressions to <code>GroupBy.agg</code>. Make a Python file with the following content:</p> from/to_native@narwhalify <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\n\ndef func(df: IntoFrameT) -&gt; IntoFrameT:\n    return (\n        nw.from_native(df).group_by(\"a\").agg(nw.col(\"b\").mean()).sort(\"a\").to_native()\n    )\n</code></pre> <pre><code>import narwhals as nw\nfrom narwhals.typing import FrameT\n\n\n@nw.narwhalify\ndef func(df: FrameT) -&gt; FrameT:\n    return df.group_by(\"a\").agg(nw.col(\"b\").mean()).sort(\"a\")\n</code></pre> <p>Let's try it out:</p> pandasPolars (eager)Polars (lazy)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"a\": [1, 1, 2], \"b\": [4, 5, 6]})\nprint(func(df))\n</code></pre> <pre><code>   a    b\n0  1  4.5\n1  2  6.0\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame({\"a\": [1, 1, 2], \"b\": [4, 5, 6]})\nprint(func(df))\n</code></pre> <pre><code>shape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4.5 \u2502\n\u2502 2   \u2506 6.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.LazyFrame({\"a\": [1, 1, 2], \"b\": [4, 5, 6]})\nprint(func(df).collect())\n</code></pre> <pre><code>shape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 f64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4.5 \u2502\n\u2502 2   \u2506 6.0 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table({\"a\": [1, 1, 2], \"b\": [4, 5, 6]})\nprint(func(table))\n</code></pre> <pre><code>pyarrow.Table\na: int64\nb: double\n----\na: [[1,2]]\nb: [[4.5,6]]\n</code></pre>"},{"location":"basics/dataframe/#example-3-horizontal-sum","title":"Example 3: horizontal sum","text":"<p>Expressions can be free-standing functions which accept other expressions as inputs. For example, we can compute a horizontal sum using <code>nw.sum_horizontal</code>.</p> <p>Make a Python file with the following content:</p> from/to_native@narwhalify <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\n\ndef func(df: IntoFrameT) -&gt; IntoFrameT:\n    return (\n        nw.from_native(df)\n        .with_columns(a_plus_b=nw.sum_horizontal(\"a\", \"b\"))\n        .to_native()\n    )\n</code></pre> <pre><code>import narwhals as nw\nfrom narwhals.typing import FrameT\n\n\n@nw.narwhalify\ndef func(df: FrameT) -&gt; FrameT:\n    return df.with_columns(a_plus_b=nw.sum_horizontal(\"a\", \"b\"))\n</code></pre> <p>Let's try it out:</p> pandasPolars (eager)Polars (lazy)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"a\": [1, 1, 2], \"b\": [4, 5, 6]})\nprint(func(df))\n</code></pre> <pre><code>   a  b  a_plus_b\n0  1  4         5\n1  1  5         6\n2  2  6         8\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame({\"a\": [1, 1, 2], \"b\": [4, 5, 6]})\nprint(func(df))\n</code></pre> <pre><code>shape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 a_plus_b \u2502\n\u2502 --- \u2506 --- \u2506 ---      \u2502\n\u2502 i64 \u2506 i64 \u2506 i64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4   \u2506 5        \u2502\n\u2502 1   \u2506 5   \u2506 6        \u2502\n\u2502 2   \u2506 6   \u2506 8        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.LazyFrame({\"a\": [1, 1, 2], \"b\": [4, 5, 6]})\nprint(func(df).collect())\n</code></pre> <pre><code>shape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 a_plus_b \u2502\n\u2502 --- \u2506 --- \u2506 ---      \u2502\n\u2502 i64 \u2506 i64 \u2506 i64      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 4   \u2506 5        \u2502\n\u2502 1   \u2506 5   \u2506 6        \u2502\n\u2502 2   \u2506 6   \u2506 8        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table({\"a\": [1, 1, 2], \"b\": [4, 5, 6]})\nprint(func(table))\n</code></pre> <pre><code>pyarrow.Table\na: int64\nb: int64\na_plus_b: int64\n----\na: [[1,1,2]]\nb: [[4,5,6]]\na_plus_b: [[5,6,8]]\n</code></pre>"},{"location":"basics/dataframe/#example-4-multiple-inputs","title":"Example 4: multiple inputs","text":"<p><code>nw.narwhalify</code> can be used to decorate functions that take multiple inputs as well and return a non dataframe/series-like object.</p> <p>For example, let's compute how many rows are left in a dataframe after filtering it based on a series.</p> <p>Make a Python file with the following content:</p> <pre><code>import narwhals as nw\nfrom narwhals.typing import DataFrameT\n\n\n@nw.narwhalify(eager_only=True)\ndef func(df: DataFrameT, s: nw.Series, col_name: str) -&gt; int:\n    return df.filter(nw.col(col_name).is_in(s)).shape[0]\n</code></pre> <p>We require <code>eager_only=True</code> here because lazyframe doesn't support <code>.shape</code>.</p> <p>Let's try it out:</p> pandasPolars (eager)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"a\": [1, 1, 2, 2, 3], \"b\": [4, 5, 6, 7, 8]})\ns = pd.Series([1, 3])\nprint(func(df, s.to_numpy(), \"a\"))\n</code></pre> <pre><code>3\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame({\"a\": [1, 1, 2, 2, 3], \"b\": [4, 5, 6, 7, 8]})\ns = pl.Series([1, 3])\nprint(func(df, s.to_numpy(), \"a\"))\n</code></pre> <pre><code>3\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table({\"a\": [1, 1, 2, 2, 3], \"b\": [4, 5, 6, 7, 8]})\na = pa.array([1, 3])\nprint(func(table, a.to_numpy(), \"a\"))\n</code></pre> <pre><code>3\n</code></pre>"},{"location":"basics/dataframe_conversion/","title":"Conversion between libraries","text":"<p>Some library maintainers must apply complex dataframe operations, using methods and functions that may not (yet) be implemented in Narwhals. In such cases, Narwhals can still be highly beneficial, by allowing easy dataframe conversion.</p>"},{"location":"basics/dataframe_conversion/#dataframe-x-in-pandas-out","title":"Dataframe X in, pandas out","text":"<p>Imagine that you maintain a library with a function that operates on pandas dataframes to produce automated reports. You want to allow users to supply a dataframe in any format to that function (pandas, Polars, DuckDB, cuDF, Modin, etc.) without adding all those dependencies to your own project and without special-casing each input library's variation of <code>to_pandas</code> / <code>toPandas</code> / <code>to_pandas_df</code> / <code>df</code> ...</p> <p>One solution is to use Narwhals as a thin Dataframe ingestion layer, to convert user-supplied dataframe to the format that your library uses internally. Since Narwhals is zero-dependency, this is a much more lightweight solution than including all the dataframe libraries as dependencies, and easier to write than special casing each input library's <code>to_pandas</code> method (if it even exists!).</p> <p>To illustrate, we create dataframes in various formats:</p> <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoDataFrame\nfrom typing import Any\n\nimport duckdb\nimport polars as pl\nimport pandas as pd\n\ndf_polars = pl.DataFrame(\n    {\n        \"A\": [1, 2, 3, 4, 5],\n        \"fruits\": [\"banana\", \"banana\", \"apple\", \"apple\", \"banana\"],\n        \"B\": [5, 4, 3, 2, 1],\n        \"cars\": [\"beetle\", \"audi\", \"beetle\", \"beetle\", \"beetle\"],\n    }\n)\ndf_pandas = df_polars.to_pandas()\ndf_duckdb = duckdb.sql(\"SELECT * FROM df_polars\")\n</code></pre> <p>Now, we define a function that can ingest any dataframe type supported by Narwhals, and convert it to a pandas DataFrame for internal use:</p> <pre><code>def df_to_pandas(df: IntoDataFrame) -&gt; pd.DataFrame:\n    return nw.from_native(df).to_pandas()\n\n\nprint(df_to_pandas(df_polars))\n</code></pre> <pre><code>   A  fruits  B    cars\n0  1  banana  5  beetle\n1  2  banana  4    audi\n2  3   apple  3  beetle\n3  4   apple  2  beetle\n4  5  banana  1  beetle\n</code></pre>"},{"location":"basics/dataframe_conversion/#dataframe-x-in-polars-out","title":"Dataframe X in, Polars out","text":""},{"location":"basics/dataframe_conversion/#via-pycapsule-interface","title":"Via PyCapsule Interface","text":"<p>Similarly, if your library uses Polars internally, you can convert any user-supplied dataframe which implements <code>__arrow_c_stream__</code>:</p> <pre><code>def df_to_polars(df_native: Any) -&gt; pl.DataFrame:\n    if hasattr(df_native, \"__arrow_c_stream__\"):\n        return nw.from_arrow(df_native, native_namespace=pl).to_native()\n    msg = (\n        f\"Expected object which implements '__arrow_c_stream__' got: {type(df_native)}\"\n    )\n    raise TypeError(msg)\n\n\nprint(df_to_polars(df_duckdb))  # You can only execute this line of code once.\n</code></pre> <pre><code>shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 A   \u2506 fruits \u2506 B   \u2506 cars   \u2502\n\u2502 --- \u2506 ---    \u2506 --- \u2506 ---    \u2502\n\u2502 i64 \u2506 str    \u2506 i64 \u2506 str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 banana \u2506 5   \u2506 beetle \u2502\n\u2502 2   \u2506 banana \u2506 4   \u2506 audi   \u2502\n\u2502 3   \u2506 apple  \u2506 3   \u2506 beetle \u2502\n\u2502 4   \u2506 apple  \u2506 2   \u2506 beetle \u2502\n\u2502 5   \u2506 banana \u2506 1   \u2506 beetle \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>It works to pass Polars to <code>native_namespace</code> here because Polars supports the PyCapsule Interface for import.</p> <p>Note that the PyCapsule Interface makes no guarantee that you can call it repeatedly, so the approach above only works if you only expect to perform the conversion a single time on each input object.</p>"},{"location":"basics/dataframe_conversion/#via-pyarrow","title":"Via PyArrow","text":"<p>If you need to ingest the same dataframe multiple times, then you may want to go via PyArrow instead. This may be less efficient than the PyCapsule approach above (and always requires PyArrow!), but is more forgiving:</p> <pre><code>def df_to_polars(df_native: IntoDataFrame) -&gt; pl.DataFrame:\n    df = nw.from_native(df_native).lazy().collect()\n    return pl.DataFrame(nw.from_native(df, eager_only=True).to_arrow())\n\n\ndf_duckdb = duckdb.sql(\"SELECT * FROM df_polars\")\nprint(df_to_polars(df_duckdb))  # We can execute this...\nprint(df_to_polars(df_duckdb))  # ...as many times as we like!\n</code></pre> <pre><code>shape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 A   \u2506 fruits \u2506 B   \u2506 cars   \u2502\n\u2502 --- \u2506 ---    \u2506 --- \u2506 ---    \u2502\n\u2502 i64 \u2506 str    \u2506 i64 \u2506 str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 banana \u2506 5   \u2506 beetle \u2502\n\u2502 2   \u2506 banana \u2506 4   \u2506 audi   \u2502\n\u2502 3   \u2506 apple  \u2506 3   \u2506 beetle \u2502\n\u2502 4   \u2506 apple  \u2506 2   \u2506 beetle \u2502\n\u2502 5   \u2506 banana \u2506 1   \u2506 beetle \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\nshape: (5, 4)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 A   \u2506 fruits \u2506 B   \u2506 cars   \u2502\n\u2502 --- \u2506 ---    \u2506 --- \u2506 ---    \u2502\n\u2502 i64 \u2506 str    \u2506 i64 \u2506 str    \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 banana \u2506 5   \u2506 beetle \u2502\n\u2502 2   \u2506 banana \u2506 4   \u2506 audi   \u2502\n\u2502 3   \u2506 apple  \u2506 3   \u2506 beetle \u2502\n\u2502 4   \u2506 apple  \u2506 2   \u2506 beetle \u2502\n\u2502 5   \u2506 banana \u2506 1   \u2506 beetle \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"basics/series/","title":"Series","text":"<p>In dataframe, you learned how to write a dataframe-agnostic function.</p> <p>We only used DataFrame methods there - but what if we need to operate on its columns?</p> <p>Note that Polars does not have lazy columns. If you need to operate on columns as part of a dataframe operation, you should use expressions - but if you need to extract a single column, you need to ensure that you start with an eager <code>DataFrame</code>. To do that, you need to pass <code>eager_only=True</code> to <code>nw.from_native</code>.</p>"},{"location":"basics/series/#example-1-filter-based-on-a-columns-values","title":"Example 1: filter based on a column's values","text":"<p>This can stay lazy, so we just use expressions:</p> from/to_native@narwhalify <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\n\ndef my_func(df: IntoFrameT) -&gt; IntoFrameT:\n    return nw.from_native(df).filter(nw.col(\"a\") &gt; 0).to_native()\n</code></pre> <pre><code>import narwhals as nw\nfrom narwhals.typing import FrameT\n\n\n@nw.narwhalify\ndef my_func(df: FrameT) -&gt; FrameT:\n    return df.filter(nw.col(\"a\") &gt; 0)\n</code></pre> <p>and call it either on a eager or lazy dataframe:</p> pandasPolars (eager)Polars (lazy)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>   a  b\n1  1  5\n2  3 -3\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>shape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 5   \u2502\n\u2502 3   \u2506 -3  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.LazyFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df).collect())\n</code></pre> <pre><code>shape: (2, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1   \u2506 5   \u2502\n\u2502 3   \u2506 -3  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(table))\n</code></pre> <pre><code>pyarrow.Table\na: int64\nb: int64\n----\na: [[1,3]]\nb: [[5,-3]]\n</code></pre>"},{"location":"basics/series/#example-2-multiply-a-columns-values-by-a-constant","title":"Example 2: multiply a column's values by a constant","text":"<p>Let's write a dataframe-agnostic function which multiplies the values in column <code>'a'</code> by 2. This can also stay lazy, and can use expressions:</p> from/to_native@narwhalify <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\n\ndef my_func(df: IntoFrameT) -&gt; IntoFrameT:\n    return nw.from_native(df).with_columns(nw.col(\"a\") * 2).to_native()\n</code></pre> <pre><code>import narwhals as nw\nfrom narwhals.typing import FrameT\n\n\n@nw.narwhalify\ndef my_func(df: FrameT) -&gt; FrameT:\n    return df.with_columns(nw.col(\"a\") * 2)\n</code></pre> <p>and call it either on a eager or lazy dataframe:</p> pandasPolars (eager)Polars (lazy)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>   a  b\n0 -2  3\n1  2  5\n2  6 -3\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -2  \u2506 3   \u2502\n\u2502 2   \u2506 5   \u2502\n\u2502 6   \u2506 -3  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.LazyFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df).collect())\n</code></pre> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2502\n\u2502 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -2  \u2506 3   \u2502\n\u2502 2   \u2506 5   \u2502\n\u2502 6   \u2506 -3  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(table))\n</code></pre> <pre><code>pyarrow.Table\na: int64\nb: int64\n----\na: [[-2,2,6]]\nb: [[3,5,-3]]\n</code></pre> <p>Note that column <code>'a'</code> was overwritten. If we had wanted to add a new column called <code>'c'</code> containing column <code>'a'</code>'s values multiplied by 2, we could have used <code>Expr.alias</code>:</p> <pre><code>import narwhals as nw\nfrom narwhals.typing import FrameT\n\n\n@nw.narwhalify\ndef my_func(df: FrameT) -&gt; FrameT:\n    return df.with_columns((nw.col(\"a\") * 2).alias(\"c\"))\n</code></pre> pandasPolars (eager)Polars (lazy)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>   a  b  c\n0 -1  3 -2\n1  1  5  2\n2  3 -3  6\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>shape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -1  \u2506 3   \u2506 -2  \u2502\n\u2502 1   \u2506 5   \u2506 2   \u2502\n\u2502 3   \u2506 -3  \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.LazyFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df).collect())\n</code></pre> <pre><code>shape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a   \u2506 b   \u2506 c   \u2502\n\u2502 --- \u2506 --- \u2506 --- \u2502\n\u2502 i64 \u2506 i64 \u2506 i64 \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 -1  \u2506 3   \u2506 -2  \u2502\n\u2502 1   \u2506 5   \u2506 2   \u2502\n\u2502 3   \u2506 -3  \u2506 6   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(table))\n</code></pre> <pre><code>pyarrow.Table\na: int64\nb: int64\nc: int64\n----\na: [[-1,1,3]]\nb: [[3,5,-3]]\nc: [[-2,2,6]]\n</code></pre>"},{"location":"basics/series/#example-3-finding-the-mean-of-a-column-as-a-scalar","title":"Example 3: finding the mean of a column as a scalar","text":"<p>Now, we want to find the mean of column <code>'a'</code>, and we need it as a Python scalar. This means that computation cannot stay lazy - it must execute! Therefore, we'll pass <code>eager_only=True</code> to <code>nw.from_native</code> (or <code>nw.narwhalify</code>), and then, instead of using expressions, we'll extract a <code>Series</code>.</p> from/to_native@narwhalify <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoDataFrameT\n\n\ndef my_func(df: IntoDataFrameT) -&gt; float | None:\n    return nw.from_native(df, eager_only=True)[\"a\"].mean()\n</code></pre> <pre><code>import narwhals as nw\nfrom narwhals.typing import DataFrameT\n\n\n@nw.narwhalify(eager_only=True)\ndef my_func(df: DataFrameT) -&gt; float | None:\n    return df[\"a\"].mean()\n</code></pre> <p>Now we can call it on a eager dataframe only:</p> pandasPolars (eager)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>1.0\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(df))\n</code></pre> <pre><code>1.0\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table({\"a\": [-1, 1, 3], \"b\": [3, 5, -3]})\nprint(my_func(table))\n</code></pre> <pre><code>1.0\n</code></pre> <p>Note that, even though the output of our function is not a dataframe nor a series, we can still use <code>narwhalify</code>.</p>"},{"location":"pandas_like_concepts/boolean/","title":"Boolean columns","text":"<p>Generally speaking, Narwhals operations preserve null values. For example, if you do <code>nw.col('a')*2</code>, then:</p> <ul> <li>Values which were non-null get multiplied by 2.</li> <li>Null values stay null.</li> </ul> <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\ndata = {\"a\": [1.4, None, 4.2]}\n\n\ndef multiplication(df: IntoFrameT) -&gt; IntoFrameT:\n    return nw.from_native(df).with_columns((nw.col(\"a\") * 2).alias(\"a*2\")).to_native()\n</code></pre> pandasPolars (eager)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame(data)\nprint(multiplication(df))\n</code></pre> <pre><code>     a  a*2\n0  1.4  2.8\n1  NaN  NaN\n2  4.2  8.4\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame(data)\nprint(multiplication(df))\n</code></pre> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 a*2  \u2502\n\u2502 ---  \u2506 ---  \u2502\n\u2502 f64  \u2506 f64  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.4  \u2506 2.8  \u2502\n\u2502 null \u2506 null \u2502\n\u2502 4.2  \u2506 8.4  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table(data)\nprint(multiplication(table))\n</code></pre> <pre><code>pyarrow.Table\na: double\na*2: double\n----\na: [[1.4,null,4.2]]\na*2: [[2.8,null,8.4]]\n</code></pre> <p>What do we do, however, when the result column is boolean? For example, <code>nw.col('a') &gt; 0</code>? Unfortunately, this is backend-dependent:</p> <ul> <li>for all backends except pandas, null values are preserved</li> <li>for pandas, this depends on the dtype backend:<ul> <li>for PyArrow dtypes and pandas nullable dtypes, null values are preserved</li> <li>for the classic NumPy dtypes, null values are typically filled in with <code>False</code>.</li> </ul> </li> </ul> <p>pandas is generally moving towards nullable dtypes, and they may become the default in the future, so we hope that the classical NumPy dtypes not supporting null values will just be a temporary legacy pandas issue which will eventually go away anyway.</p> <pre><code>from narwhals.typing import FrameT\n\n\ndef comparison(df: FrameT) -&gt; FrameT:\n    return nw.from_native(df).with_columns((nw.col(\"a\") &gt; 2).alias(\"a&gt;2\")).to_native()\n</code></pre> pandasPolars (eager)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame(data)\nprint(comparison(df))\n</code></pre> <pre><code>     a    a&gt;2\n0  1.4  False\n1  NaN  False\n2  4.2   True\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame(data)\nprint(comparison(df))\n</code></pre> <pre><code>shape: (3, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 a&gt;2   \u2502\n\u2502 ---  \u2506 ---   \u2502\n\u2502 f64  \u2506 bool  \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.4  \u2506 false \u2502\n\u2502 null \u2506 null  \u2502\n\u2502 4.2  \u2506 true  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ntable = pa.table(data)\nprint(comparison(table))\n</code></pre> <pre><code>pyarrow.Table\na: double\na&gt;2: bool\n----\na: [[1.4,null,4.2]]\na&gt;2: [[false,null,true]]\n</code></pre>"},{"location":"pandas_like_concepts/column_names/","title":"Column names","text":"<p>Polars and PyArrow only allow for string column names. What about pandas?</p> <pre><code>import pandas as pd\n\ndf = pd.concat([pd.Series([1, 2], name=0), pd.Series([1, 3], name=0)], axis=1)\nprint(df)\n</code></pre> <pre><code>   0  0\n0  1  1\n1  2  3\n</code></pre> <p>Oh...not only does it let us create a dataframe with a column named <code>0</code> - it lets us create one with two such columns!</p> <p>What does Narwhals do about this?</p> <ul> <li>In general, non-string column names are supported. In some places where this might   create ambiguity (such as <code>DataFrame.__getitem__</code> or <code>DataFrame.select</code>) we may be strict and only   allow passing in column names if they're strings.</li> <li>If you have a use-case that's   failing for non-string column names, please report it to https://github.com/narwhals-dev/narwhals/issues   and we'll see if we can support it.</li> <li>Duplicate column names are \ud83d\udeab banned \ud83d\udeab.</li> </ul>"},{"location":"pandas_like_concepts/improve_group_by_operation/","title":"Avoiding the <code>UserWarning</code> error while using Pandas <code>group_by</code>","text":""},{"location":"pandas_like_concepts/improve_group_by_operation/#introduction","title":"Introduction","text":"<p>If you have ever experienced the</p> <p>UserWarning: Found complex group-by expression, which can't be expressed efficiently with the pandas API. If you can, please rewrite your query such that group-by aggregations are simple (e.g. mean, std, min, max, ...)</p> <p>message while using the narwhals <code>group_by()</code> method, this is for you. If you haven't, this is also for you as you might experience it and you need to know how to avoid it.</p> <p>The pandas API most likely cannot efficiently handle the complexity of the aggregation operations you are trying to run. Take the following two codes as an example.</p> Approach 1Approach 2 <pre><code>import narwhals as nw\nimport pandas as pd\nfrom narwhals.typing import IntoFrameT\n\ndata = {\"a\": [1, 2, 3, 4, 5], \"b\": [5, 4, 3, 2, 1], \"c\": [10, 20, 30, 40, 50]}\n\ndf_pd = pd.DataFrame(data)\n\n\n@nw.narwhalify\ndef approach_1(df: IntoFrameT) -&gt; IntoFrameT:\n\n    # Pay attention to this next line\n    df = df.group_by(\"a\").agg(d=(nw.col(\"b\") + nw.col(\"c\")).sum())\n\n    return df\n\n\nprint(approach_1(df_pd))\n</code></pre> <pre><code>   a   d\n0  1  15\n1  2  24\n2  3  33\n3  4  42\n4  5  51\n</code></pre> <pre><code>import narwhals as nw\nimport pandas as pd\n\ndata = {\"a\": [1, 2, 3, 4, 5], \"b\": [5, 4, 3, 2, 1], \"c\": [10, 20, 30, 40, 50]}\n\ndf_pd = pd.DataFrame(data)\n\n\n@nw.narwhalify\ndef approach_2(df: IntoFrameT) -&gt; IntoFrameT:\n\n    # Pay attention to this next line\n    df = df.with_columns(d=nw.col(\"b\") + nw.col(\"c\")).group_by(\"a\").agg(nw.sum(\"d\"))\n\n    return df\n\n\nprint(approach_2(df_pd))\n</code></pre> <pre><code>   a   d\n0  1  15\n1  2  24\n2  3  33\n3  4  42\n4  5  51\n</code></pre> <p>Both Approaches shown above return the exact same result, but Approach 1 is inefficient and returns the warning message we showed at the top.</p> <p>What makes the first approach inefficient and the second approach efficient? It comes down to what the pandas API lets us express.</p>"},{"location":"pandas_like_concepts/improve_group_by_operation/#approach-1","title":"Approach 1","text":"<pre><code># From line 11\n\nreturn df.group_by(\"a\").agg((nw.col(\"b\") + nw.col(\"c\")).sum().alias(\"d\"))\n</code></pre> <p>To translate this to pandas, we would do:</p> <pre><code>df.groupby(\"a\").apply(\n    lambda df: pd.Series([(df[\"b\"] + df[\"c\"]).sum()], index=[\"d\"]), include_groups=False\n)\n</code></pre> <p>Any time you use <code>apply</code> in pandas, that's a performance footgun - best to avoid it and use vectorised operations instead. Let's take a look at how \"approach 2\" gets translated to pandas to see the difference.</p>"},{"location":"pandas_like_concepts/improve_group_by_operation/#approach-2","title":"Approach 2","text":"<pre><code># Line 11 in Approach 2\n\nreturn df.with_columns(d=nw.col(\"b\") + nw.col(\"c\")).group_by(\"a\").agg({\"d\": \"sum\"})\n</code></pre> <p>This gets roughly translated to:</p> <pre><code>df.assign(d=lambda df: df[\"b\"] + df[\"c\"]).groupby(\"a\").agg({\"d\": \"sum\"})\n</code></pre> <p>Because we're using pandas' own API, as opposed to <code>apply</code> and a custom <code>lambda</code> function, then this is going to be much more efficient.</p>"},{"location":"pandas_like_concepts/improve_group_by_operation/#tips-for-avoiding-the-userwarning","title":"Tips for Avoiding the <code>UserWarning</code>","text":"<p>To ensure efficiency and avoid warnings similar to those seen in Approach 1, we recommend that you follow these practices:</p> <ol> <li>Decompose complex operations: break down complex transformations into simpler steps. In this case, keep the <code>.agg</code> method simple. Compute new columns first, then use these columns in aggregation or other operations.</li> <li>Avoid redundant computations: if an operation (like addition) is used multiple times, compute it once and store the result in a new column.</li> <li>Leverage built-in functions: use built-in functions provided by the DataFrame library. In this case, using the <code>with_columns()</code> method allows you to pre-compute before grouping and aggregation.</li> </ol> <p>By following these guidelines, you can are sure to avoid the aforementioned warning.</p> <p>Happy grouping! \ud83e\udee1</p>"},{"location":"pandas_like_concepts/null_handling/","title":"Null/NaN handling","text":"<p>pandas doesn't distinguish between Null and NaN values as Polars and PyArrow do.</p> <p>Depending on the data type of the underlying data structure, <code>np.nan</code>, <code>pd.NaT</code>, <code>None</code> and <code>pd.NA</code> all encode missing data in pandas.</p> <p>Polars and PyArrow, instead, treat <code>NaN</code> as a valid floating point value which is rare to encounter and more often produced as the result of a computation than explicitly set during data initialization; they treat <code>null</code> as the missing data indicator, regardless of the data type.</p> <p>In Narwhals, then, <code>is_null</code> behaves differently across backends (and so do <code>drop_nulls</code>, <code>fill_null</code> and <code>null_count</code>):</p> <pre><code>import narwhals as nw\nimport numpy as np\nfrom narwhals.typing import IntoFrameT\n\ndata = {\"a\": [1.4, float(\"nan\"), np.nan, 4.2, None]}\n\n\ndef check_null_behavior(df: IntoFrameT) -&gt; IntoFrameT:\n    return nw.from_native(df).with_columns(a_is_null=nw.col(\"a\").is_null()).to_native()\n</code></pre> pandasPolars (eager)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame(data)\nprint(check_null_behavior(df))\n</code></pre> <pre><code>     a  a_is_null\n0  1.4      False\n1  NaN       True\n2  NaN       True\n3  4.2      False\n4  NaN       True\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame(data)\nprint(check_null_behavior(df))\n</code></pre> <pre><code>shape: (5, 2)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 a_is_null \u2502\n\u2502 ---  \u2506 ---       \u2502\n\u2502 f64  \u2506 bool      \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 1.4  \u2506 false     \u2502\n\u2502 NaN  \u2506 false     \u2502\n\u2502 NaN  \u2506 false     \u2502\n\u2502 4.2  \u2506 false     \u2502\n\u2502 null \u2506 true      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ndf = pa.table(data)\nprint(check_null_behavior(df))\n</code></pre> <pre><code>pyarrow.Table\na: double\na_is_null: bool\n----\na: [[1.4,nan,nan,4.2,null]]\na_is_null: [[false,false,false,false,true]]\n</code></pre> <p>Conversely, <code>is_nan</code> is consistent across backends. This consistency comes from Narwhals exploiting its native implementations in Polars and PyArrow, while ensuring that pandas only identifies the floating-point NaN values and not those encoding the missing value indicator.</p> <pre><code>import narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\ndata = {\"a\": [0.0, None, 2.0]}\n\n\ndef check_nan_behavior(df: IntoFrameT) -&gt; IntoFrameT:\n    return (\n        nw.from_native(df)\n        .with_columns(\n            a_div_a=(nw.col(\"a\") / nw.col(\"a\")),\n            a_div_a_is_nan=(nw.col(\"a\") / nw.col(\"a\")).is_nan(),\n        )\n        .to_native()\n    )\n</code></pre> pandasPolars (eager)PyArrow <pre><code>import pandas as pd\n\ndf = pd.DataFrame(data).astype({\"a\": \"Float64\"})\nprint(check_nan_behavior(df))\n</code></pre> <pre><code>      a  a_div_a  a_div_a_is_nan\n0   0.0      NaN            True\n1  &lt;NA&gt;     &lt;NA&gt;            &lt;NA&gt;\n2   2.0      1.0           False\n</code></pre> <pre><code>import polars as pl\n\ndf = pl.DataFrame(data)\nprint(check_nan_behavior(df))\n</code></pre> <pre><code>shape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 a    \u2506 a_div_a \u2506 a_div_a_is_nan \u2502\n\u2502 ---  \u2506 ---     \u2506 ---            \u2502\n\u2502 f64  \u2506 f64     \u2506 bool           \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 0.0  \u2506 NaN     \u2506 true           \u2502\n\u2502 null \u2506 null    \u2506 null           \u2502\n\u2502 2.0  \u2506 1.0     \u2506 false          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <pre><code>import pyarrow as pa\n\ndf = pa.table(data)\nprint(check_nan_behavior(df))\n</code></pre> <pre><code>pyarrow.Table\na: double\na_div_a: double\na_div_a_is_nan: bool\n----\na: [[0,null,2]]\na_div_a: [[nan,null,1]]\na_div_a_is_nan: [[true,null,false]]\n</code></pre>"},{"location":"pandas_like_concepts/pandas_index/","title":"What about the pandas Index?","text":"<p>There are two types of pandas users:</p> <ul> <li>The ones who make full use of the Index's power.</li> <li>The <code>.reset_index(drop=True)</code> ones, who would rather not think about the Index.</li> </ul> <p>Narwhals aims to accommodate both!</p> <ul> <li>If you'd rather not think about the Index, then don't   worry: it's not part of the Narwhals public API, and you'll never have to worry about   resetting the index or about pandas doing funky index alignment for you.</li> <li>If you want your library to cater to Index powerusers who would be very angry if you reset   their beautiful Index on their behalf, then don't worry: Narwhals makes certain promises   with regards to the Index.</li> </ul> <p>Let's learn about what Narwhals promises.</p>"},{"location":"pandas_like_concepts/pandas_index/#1-narwhals-will-preserve-your-index-for-dataframe-operations","title":"1. Narwhals will preserve your index for dataframe operations","text":"<pre><code>import narwhals as nw\nfrom narwhals.typing import IntoFrameT\n\n\ndef my_func(df: IntoFrameT) -&gt; IntoFrameT:\n    df = nw.from_native(df)\n    df = df.with_columns(a_plus_one=nw.col(\"a\") + 1)\n    return nw.to_native(df)\n</code></pre> <p>Let's start with a dataframe with an Index with values <code>[7, 8, 9]</code>.</p> <pre><code>import pandas as pd\n\ndf = pd.DataFrame({\"a\": [2, 1, 3], \"b\": [3, 5, -3]}, index=[7, 8, 9])\nprint(my_func(df))\n</code></pre> <pre><code>   a  b  a_plus_one\n7  2  3           3\n8  1  5           2\n9  3 -3           4\n</code></pre> <p>Note how the result still has the original index - Narwhals did not modify it.</p>"},{"location":"pandas_like_concepts/pandas_index/#2-index-alignment-follows-the-left-hand-rule","title":"2. Index alignment follows the left-hand-rule","text":"<p>pandas automatically aligns indices for users. For example:</p> <pre><code>import pandas as pd\n\ndf_pd = pd.DataFrame({\"a\": [2, 1, 3], \"b\": [4, 5, 6]})\ns_pd = df_pd[\"a\"].sort_values()\ndf_pd[\"a_sorted\"] = s_pd\n</code></pre> <p>Reading the code, you might expect that <code>'a_sorted'</code> will contain the values <code>[1, 2, 3]</code>.</p> <p>However, here's what actually happens:</p> <pre><code>print(df_pd)\n</code></pre> <pre><code>   a  b  a_sorted\n0  2  4         2\n1  1  5         1\n2  3  6         3\n</code></pre> <p>In other words, pandas' index alignment undid the <code>sort_values</code> operation!</p> <p>Narwhals, on the other hand, preserves the index of the left-hand-side argument. Everything else will be inserted positionally, just like Polars would do:</p> <pre><code>import narwhals as nw\n\ndf = nw.from_native(df_pd)\ns = nw.from_native(s_pd, allow_series=True)\ndf = df.with_columns(a_sorted=s.sort())\nprint(nw.to_native(df))\n</code></pre> <pre><code>   a  b  a_sorted\n0  2  4         1\n1  1  5         2\n2  3  6         3\n</code></pre> <p>If you keep these two rules in mind, then Narwhals will both help you avoid Index-related surprises whilst letting you preserve the Index for the subset of your users who consciously make great use of it.</p>"}]}